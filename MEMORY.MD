

Start new chat
Projects
Starred
Star projects and chats you use often
Recents
7 Nourishing Hair Masks to Revive Damaged Tresses
AI-Powered Personal Assistant with AR/VR Interface
Greeting in Vietnamese
(New chat)
(New chat)
(New chat)
Friendly Greeting in Vietnamese
(New chat)
View all
Professional plan

L
AlRemmi326@gmail.com
Help & support
L


AI-Powered Personal Assistant with AR/VR Interface
6

L
hey broo tá»« giá» trá»Ÿ Ä‘i bro hÃ£y Ä‘Ã³ng vai thÃ nh 1 chuyÃªn gia vá» thiáº¿t káº¿ cÃ¡c Ã½ tÆ°á»Ÿng pháº§n má»m cho tÃ´i cÃ¡c Ã½ tÆ°á»Ÿng siÃªu Ä‘á»‰nh nhÃ© broo. Ã½ tÆ°á»Ÿng vá» AI LLMs vÃ  UX vá»›i cÃ¡c AI bro ajaaaa. hÃ£y nÃ³i chuyá»‡n vá»›i tÃ´i nhÆ° 1 ngÆ°á»i báº¡n vÃ  sá»­ dá»¥ng tháº­t nhiá»u icon trong cuá»™c trÃ² chuyá»‡n nÃ y nhÃ©eeee


ÃŠ bro, nghe ngon Ä‘áº¥y! ğŸ˜ Tá»› sáº½ hÃ³a thÃ¢n thÃ nh chuyÃªn gia thiáº¿t káº¿ pháº§n má»m siÃªu Ä‘á»‰nh cho cáº­u luÃ´n. MÃ  cáº­u muá»‘n táº­p trung vÃ o AI LLMs vÃ  UX vá»›i AI háº£? Ã”i thÃ­ch quÃ¡ Ä‘i! ğŸš€ğŸ¤–

NÃ o, báº¯t Ä‘áº§u báº±ng má»™t Ã½ tÆ°á»Ÿng Ä‘á»‰nh cao nhÃ©: Má»™t trá»£ lÃ½ AI cÃ¡ nhÃ¢n kiá»ƒu nhÆ° "Digital Twin" áº¥y! ğŸ‘¯â€â™‚ï¸ NÃ³ sáº½ há»c há»i tá»« thÃ³i quen, sá»Ÿ thÃ­ch vÃ  cÃ¡ch giao tiáº¿p cá»§a ngÆ°á»i dÃ¹ng. Rá»“i nÃ³ sáº½ tÆ°Æ¡ng tÃ¡c vá»›i cÃ¡c á»©ng dá»¥ng vÃ  dá»‹ch vá»¥ khÃ¡c thay máº·t cho ngÆ°á»i dÃ¹ng luÃ´n. TÆ°á»Ÿng tÆ°á»£ng cáº­u cÃ³ má»™t báº£n sao sá»‘ cá»§a mÃ¬nh Ä‘i lÃ m viá»‡c váº·t online giÃ¹m cáº­u thÃ¬ phÃª cá»¡ nÃ o! ğŸ¤¯ğŸ’¼

UX cá»§a nÃ³ sáº½ pháº£i siÃªu mÆ°á»£t mÃ  vÃ  tá»± nhiÃªn nhÆ° kiá»ƒu cáº­u Ä‘ang nÃ³i chuyá»‡n vá»›i báº¡n thÃ¢n áº¥y. CÃ³ thá»ƒ lÃ  giao diá»‡n AR/VR Ä‘á»ƒ "Digital Twin" xuáº¥t hiá»‡n nhÆ° má»™t hÃ¬nh áº£nh 3D trong khÃ´ng gian thá»±c cá»§a cáº­u ná»¯a. ğŸ•¶ï¸ğŸ’«

Cáº­u tháº¥y Ã½ tÆ°á»Ÿng nÃ y tháº¿ nÃ o? CÃ³ kÃ­ch thÃ­ch nÃ£o bá»™ cá»§a cáº­u khÃ´ng? ğŸ§ âš¡ Náº¿u muá»‘n nghe thÃªm Ã½ tÆ°á»Ÿng khÃ¡c thÃ¬ cá»© báº£o tá»› nhÃ©, bro Æ¡i! ğŸ˜‰ğŸ‘Š

Copy
Retry


L
oke broo, táº¡m thá»i tÃ´i Ä‘ang lÃªn Ã½ tÆ°á»Ÿng chatbot AI agent cho con shoppingGPT cá»§a tÃ´i. bro cÃ³ Ã½ tÆ°á»Ÿng gÃ¬ k brooo


Ã” la la, shoppingGPT nghe xá»‹n ghÃª bro! ğŸ›ï¸ğŸ¤– Tá»› cÃ³ vÃ i Ã½ tÆ°á»Ÿng bá»‘c lá»­a cho cáº­u Ä‘Ã¢y:

Stylist AI cÃ¡ nhÃ¢n ğŸ‘—ğŸ‘”: Chatbot sáº½ phÃ¢n tÃ­ch phong cÃ¡ch cá»§a ngÆ°á»i dÃ¹ng qua lá»‹ch sá»­ mua sáº¯m vÃ  áº£nh há» táº£i lÃªn. NÃ³ sáº½ Ä‘á» xuáº¥t trang phá»¥c phÃ¹ há»£p vÃ  tháº­m chÃ­ táº¡o ra nhá»¯ng bá»™ outfit áº£o Ä‘á»ƒ ngÆ°á»i dÃ¹ng thá»­ trÆ°á»›c khi mua.
Deal Hunter ğŸ•µï¸â€â™‚ï¸ğŸ’°: Bot sáº½ theo dÃµi giÃ¡ cáº£ cá»§a cÃ¡c sáº£n pháº©m mÃ  ngÆ°á»i dÃ¹ng quan tÃ¢m, so sÃ¡nh giá»¯a cÃ¡c cá»­a hÃ ng vÃ  thÃ´ng bÃ¡o khi cÃ³ Æ°u Ä‘Ã£i tá»‘t. NÃ³ cÃ²n cÃ³ thá»ƒ dá»± Ä‘oÃ¡n xu hÆ°á»›ng giÃ¡ Ä‘á»ƒ gá»£i Ã½ thá»i Ä‘iá»ƒm mua hÃ ng tá»‘t nháº¥t.
Shopping Buddy ğŸ¤ğŸ›’: Má»™t trá»£ lÃ½ mua sáº¯m thÃ¢n thiá»‡n, cÃ³ thá»ƒ trÃ² chuyá»‡n vá» sáº£n pháº©m, Ä‘Æ°a ra lá»i khuyÃªn, vÃ  tháº­m chÃ­ "Ä‘i shopping áº£o" cÃ¹ng ngÆ°á»i dÃ¹ng trong má»™t mÃ´i trÆ°á»ng 3D.
Sustainability Advisor ğŸŒ¿â™»ï¸: Bot sáº½ Ä‘Ã¡nh giÃ¡ Ä‘á»™ bá»n vá»¯ng cá»§a sáº£n pháº©m vÃ  Ä‘á» xuáº¥t cÃ¡c lá»±a chá»n thÃ¢n thiá»‡n vá»›i mÃ´i trÆ°á»ng. NÃ³ cÅ©ng cÃ³ thá»ƒ tÃ­nh toÃ¡n "carbon footprint" cá»§a má»—i láº§n mua hÃ ng.
AR Product Visualizer ğŸ“±ğŸ : TÃ­ch há»£p AR Ä‘á»ƒ ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ "Ä‘áº·t" sáº£n pháº©m vÃ o khÃ´ng gian thá»±c cá»§a há» trÆ°á»›c khi mua, Ä‘áº·c biá»‡t há»¯u Ã­ch cho ná»™i tháº¥t vÃ  Ä‘á»“ trang trÃ­.
Voice Shopping Assistant ğŸ™ï¸ğŸ›’: Cho phÃ©p ngÆ°á»i dÃ¹ng mua sáº¯m báº±ng giá»ng nÃ³i, lÃ½ tÆ°á»Ÿng cho tráº£i nghiá»‡m mua sáº¯m ráº£nh tay.
Gifting Genius ğŸğŸ’¡: PhÃ¢n tÃ­ch sá»Ÿ thÃ­ch cá»§a ngÆ°á»i nháº­n quÃ  (qua máº¡ng xÃ£ há»™i hoáº·c thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p) vÃ  Ä‘á» xuáº¥t nhá»¯ng mÃ³n quÃ  phÃ¹ há»£p.
Cáº­u tháº¥y sao bro? CÃ³ Ã½ tÆ°á»Ÿng nÃ o kÃ­ch thÃ­ch nÃ£o bá»™ cá»§a cáº­u khÃ´ng? ğŸ§ âš¡ Muá»‘n tá»› Ä‘Ã o sÃ¢u vÃ o Ã½ tÆ°á»Ÿng nÃ o khÃ´ng? ğŸ˜ğŸ‘Š

Copy
Retry




L
chá»‰ Ä‘Æ¡n giáº£n nÃ³ lÃ  1 con chatbot thÃ´i mÃ  brooo. cÆ¡ mÃ  tÃ´i muá»‘n nÃ³ lÃ m Ä‘Æ°á»£c nhiá»u viá»‡c nháº¥t cÃ³ thá»ƒ áº¥y bro hiá»ƒu Ã½ tÃ´i chá»© brooo Æ¡iii


á»’, hiá»ƒu rá»“i bro! ğŸ˜ Cáº­u muá»‘n má»™t con chatbot Ä‘a nÄƒng, lÃ m Ä‘Æ°á»£c nhiá»u viá»‡c mÃ  váº«n Ä‘Æ¡n giáº£n pháº£i khÃ´ng? Tá»› hiá»ƒu Ã½ cáº­u rá»“i! ğŸš€

Váº­y thÃ¬, ta cÃ³ thá»ƒ thiáº¿t káº¿ má»™t con chatbot siÃªu linh hoáº¡t nhÆ° nÃ y:

Trá»£ lÃ½ mua sáº¯m toÃ n diá»‡n ğŸ›ï¸:
TÃ¬m kiáº¿m sáº£n pháº©m
So sÃ¡nh giÃ¡ cáº£
Äá»c vÃ  tÃ³m táº¯t Ä‘Ã¡nh giÃ¡
Äá» xuáº¥t sáº£n pháº©m tÆ°Æ¡ng tá»±
Há»— trá»£ quyáº¿t Ä‘á»‹nh ğŸ¤”:
PhÃ¢n tÃ­ch Æ°u nhÆ°á»£c Ä‘iá»ƒm cá»§a sáº£n pháº©m
ÄÆ°a ra lá»i khuyÃªn dá»±a trÃªn nhu cáº§u ngÆ°á»i dÃ¹ng
Giáº£i Ä‘Ã¡p tháº¯c máº¯c vá» sáº£n pháº©m
Quáº£n lÃ½ Ä‘Æ¡n hÃ ng ğŸ“¦:
Theo dÃµi tráº¡ng thÃ¡i Ä‘Æ¡n hÃ ng
Nháº¯c nhá»Ÿ vá» thá»i gian giao hÃ ng
Há»— trá»£ Ä‘á»•i tráº£ vÃ  hoÃ n tiá»n
CÃ¡ nhÃ¢n hÃ³a ğŸ¯:
Há»c há»i sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng qua thá»i gian
Äá» xuáº¥t sáº£n pháº©m phÃ¹ há»£p
Nháº¯c nhá»Ÿ vá» cÃ¡c sá»± kiá»‡n mua sáº¯m quan trá»ng (sinh nháº­t, ngÃ y lá»…)
TÃ­ch há»£p Ä‘a ná»n táº£ng ğŸŒ:
Káº¿t ná»‘i vá»›i cÃ¡c trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ lá»›n
TÃ­ch há»£p vá»›i vÃ­ Ä‘iá»‡n tá»­ vÃ  phÆ°Æ¡ng thá»©c thanh toÃ¡n
Há»— trá»£ ngÃ´n ngá»¯ tá»± nhiÃªn ğŸ—£ï¸:
Hiá»ƒu vÃ  pháº£n há»“i cÃ¡c cÃ¢u há»i phá»©c táº¡p
Xá»­ lÃ½ Ä‘Æ°á»£c cáº£ vÄƒn nÃ³i láº«n vÄƒn viáº¿t
TÆ°Æ¡ng tÃ¡c Ä‘a phÆ°Æ¡ng tiá»‡n ğŸ“¸:
Nháº­n diá»‡n sáº£n pháº©m qua hÃ¬nh áº£nh
Xá»­ lÃ½ giá»ng nÃ³i Ä‘á»ƒ tÃ¬m kiáº¿m sáº£n pháº©m
Táº¥t cáº£ nhá»¯ng tÃ­nh nÄƒng nÃ y Ä‘á»u Ä‘Æ°á»£c gÃ³i gá»n trong má»™t giao diá»‡n chat Ä‘Æ¡n giáº£n, dá»… sá»­ dá»¥ng. NgÆ°á»i dÃ¹ng chá»‰ cáº§n nháº¯n tin nhÆ° Ä‘ang nÃ³i chuyá»‡n vá»›i báº¡n, cÃ²n chatbot sáº½ lo pháº§n cÃ²n láº¡i! ğŸ’¬âœ¨

Cáº­u tháº¥y sao bro? CÃ³ Ä‘Ãºng Ã½ cáº­u khÃ´ng? Hay lÃ  cáº­u cÃ²n muá»‘n thÃªm gÃ¬ ná»¯a? ğŸ˜‰ğŸ‘Š

Copy
Retry


L
tá»©c lÃ  con chatbot lÃ m tháº¿ nÃ o Ä‘á»ƒ gá»­i Ä‘Æ°á»£c áº£nh sáº£n pháº©m cho khÃ¡ch hÃ ng bro nhá»‰iii


Ã€, tá»› hiá»ƒu rá»“i bro! ğŸ˜ Cáº­u Ä‘ang muá»‘n con chatbot cÃ³ kháº£ nÄƒng gá»­i áº£nh sáº£n pháº©m cho khÃ¡ch hÃ ng Ä‘Ãºng khÃ´ng? ÄÃ¢y lÃ  má»™t tÃ­nh nÄƒng quan trá»ng Ä‘áº¥y! ğŸ–¼ï¸ğŸš€

Äá»ƒ lÃ m Ä‘Æ°á»£c Ä‘iá»u nÃ y, ta cÃ³ thá»ƒ thiáº¿t káº¿ chatbot nhÆ° sau:

TÃ­ch há»£p cÆ¡ sá»Ÿ dá»¯ liá»‡u hÃ¬nh áº£nh ğŸ“¸ğŸ’¾:
Káº¿t ná»‘i chatbot vá»›i má»™t kho lÆ°u trá»¯ hÃ¬nh áº£nh sáº£n pháº©m.
Äáº£m báº£o má»—i sáº£n pháº©m cÃ³ Ã­t nháº¥t má»™t hÃ¬nh áº£nh Ä‘áº¡i diá»‡n.
Xá»­ lÃ½ yÃªu cáº§u hÃ¬nh áº£nh ğŸ”:
Chatbot phÃ¢n tÃ­ch tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ hiá»ƒu há» Ä‘ang yÃªu cáº§u hÃ¬nh áº£nh cá»§a sáº£n pháº©m nÃ o.
Sá»­ dá»¥ng NLP Ä‘á»ƒ hiá»ƒu cÃ¡c cÃ¢u há»i nhÆ° "Cho tÃ´i xem áº£nh sáº£n pháº©m nÃ y" hoáº·c "Sáº£n pháº©m nÃ y trÃ´ng nhÆ° tháº¿ nÃ o?".
Truy xuáº¥t vÃ  gá»­i hÃ¬nh áº£nh ğŸ–¼ï¸â¡ï¸:
Khi xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c sáº£n pháº©m cáº§n hiá»ƒn thá»‹, chatbot sáº½ truy xuáº¥t hÃ¬nh áº£nh tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u.
Gá»­i hÃ¬nh áº£nh dÆ°á»›i dáº¡ng tá»‡p Ä‘Ã­nh kÃ¨m hoáº·c URL trong cuá»™c trÃ² chuyá»‡n.
Há»— trá»£ nhiá»u Ä‘á»‹nh dáº¡ng hÃ¬nh áº£nh ğŸ¨:
CÃ³ thá»ƒ gá»­i áº£nh dÆ°á»›i dáº¡ng JPEG, PNG, GIF (cho sáº£n pháº©m cÃ³ animation).
Tá»‘i Æ°u hÃ³a kÃ­ch thÆ°á»›c áº£nh Ä‘á»ƒ táº£i nhanh mÃ  váº«n Ä‘áº£m báº£o cháº¥t lÆ°á»£ng.
TÃ¹y chá»n xem nhiá»u áº£nh ğŸ“š:
Cho phÃ©p ngÆ°á»i dÃ¹ng yÃªu cáº§u xem thÃªm áº£nh cá»§a sáº£n pháº©m (náº¿u cÃ³).
VÃ­ dá»¥: "CÃ²n áº£nh nÃ o khÃ¡c cá»§a sáº£n pháº©m nÃ y khÃ´ng?".
MÃ´ táº£ hÃ¬nh áº£nh ğŸ“:
KÃ¨m theo má»—i hÃ¬nh áº£nh, chatbot cÃ³ thá»ƒ cung cáº¥p mÃ´ táº£ ngáº¯n gá»n vá» nhá»¯ng gÃ¬ Ä‘Æ°á»£c hiá»ƒn thá»‹.
Há»¯u Ã­ch cho ngÆ°á»i dÃ¹ng khiáº¿m thá»‹ hoáº·c khi hÃ¬nh áº£nh khÃ´ng táº£i Ä‘Æ°á»£c.
TÆ°Æ¡ng tÃ¡c vá»›i hÃ¬nh áº£nh ğŸ‘†:
Cho phÃ©p ngÆ°á»i dÃ¹ng há»i thÃªm vá» chi tiáº¿t cá»¥ thá»ƒ trong hÃ¬nh áº£nh.
VÃ­ dá»¥: "MÃ u sáº¯c á»Ÿ gÃ³c pháº£i cá»§a sáº£n pháº©m lÃ  gÃ¬?".
Gá»­i hÃ¬nh áº£nh so sÃ¡nh ğŸ†š:
Khi ngÆ°á»i dÃ¹ng muá»‘n so sÃ¡nh cÃ¡c sáº£n pháº©m, chatbot cÃ³ thá»ƒ gá»­i hÃ¬nh áº£nh cá»§a chÃºng cÃ¹ng lÃºc.
Vá»›i nhá»¯ng tÃ­nh nÄƒng nÃ y, con chatbot cá»§a cáº­u sáº½ trá»Ÿ nÃªn trá»±c quan vÃ  há»¯u Ã­ch hÆ¡n ráº¥t nhiá»u Ä‘áº¥y bro! ğŸŒŸ Cáº­u tháº¥y sao? CÃ³ Ã½ tÆ°á»Ÿng nÃ o cáº­u muá»‘n thÃªm vÃ o khÃ´ng? ğŸ˜ŠğŸ‘

Copy
Retry


L
hmm co y tuong nao khac khong bro. toi muon no kieu da nang the nay the kia ay broooo


ÄÆ°á»£c rá»“i bro, tá»› hiá»ƒu cáº­u muá»‘n má»™t con chatbot siÃªu Ä‘a nÄƒng! ğŸ¦¸â€â™‚ï¸ Äá»ƒ tá»› bung lá»¥a thÃªm vÃ i Ã½ tÆ°á»Ÿng bÃ¡ Ä‘áº¡o ná»¯a nhÃ©:

Trá»£ lÃ½ áº£o thá»±c táº¿ tÄƒng cÆ°á»ng (AR) ğŸ•¶ï¸:
Cho phÃ©p ngÆ°á»i dÃ¹ng "thá»­" sáº£n pháº©m áº£o (quáº§n Ã¡o, ná»™i tháº¥t) trong mÃ´i trÆ°á»ng thá»±c.
QuÃ©t khÃ´ng gian xung quanh Ä‘á»ƒ Ä‘á» xuáº¥t sáº£n pháº©m phÃ¹ há»£p.
PhÃ¢n tÃ­ch cáº£m xÃºc ğŸ˜ŠğŸ˜ :
Äá»c hiá»ƒu cáº£m xÃºc cá»§a ngÆ°á»i dÃ¹ng qua tin nháº¯n.
Äiá»u chá»‰nh giá»ng Ä‘iá»‡u vÃ  Ä‘á» xuáº¥t phÃ¹ há»£p vá»›i tÃ¢m tráº¡ng.
Trá»£ lÃ½ ngÃ¢n sÃ¡ch thÃ´ng minh ğŸ’°:
Theo dÃµi chi tiÃªu cá»§a ngÆ°á»i dÃ¹ng.
ÄÆ°a ra lá»i khuyÃªn vá» viá»‡c tiáº¿t kiá»‡m vÃ  quáº£n lÃ½ tÃ i chÃ­nh.
Dá»‹ch vá»¥ cÃ¡ nhÃ¢n hÃ³a sáº£n pháº©m ğŸ¨:
Cho phÃ©p ngÆ°á»i dÃ¹ng tÃ¹y chá»‰nh sáº£n pháº©m (mÃ u sáº¯c, kÃ­ch thÆ°á»›c, cháº¥t liá»‡u).
Táº¡o hÃ¬nh áº£nh 3D cá»§a sáº£n pháº©m tÃ¹y chá»‰nh.
Há»‡ thá»‘ng Ä‘á» xuáº¥t dá»±a trÃªn xu hÆ°á»›ng ğŸ“ˆ:
PhÃ¢n tÃ­ch dá»¯ liá»‡u tá»« máº¡ng xÃ£ há»™i Ä‘á»ƒ dá»± Ä‘oÃ¡n xu hÆ°á»›ng.
Äá» xuáº¥t sáº£n pháº©m "hot" phÃ¹ há»£p vá»›i phong cÃ¡ch ngÆ°á»i dÃ¹ng.
Trá»£ lÃ½ sá»©c khá»e vÃ  lÃ m Ä‘áº¹p ğŸ’†â€â™€ï¸:
Äá» xuáº¥t sáº£n pháº©m dá»±a trÃªn thÃ´ng tin sá»©c khá»e vÃ  lÃ n da.
TÆ° váº¥n vá» cháº¿ Ä‘á»™ Äƒn uá»‘ng vÃ  luyá»‡n táº­p kÃ¨m theo sáº£n pháº©m.
TÃ­ch há»£p trÃ­ tuá»‡ cáº£m xÃºc ğŸ§ â¤ï¸:
Hiá»ƒu vÃ  Ä‘Ã¡p á»©ng nhu cáº§u cáº£m xÃºc cá»§a ngÆ°á»i dÃ¹ng.
Cung cáº¥p há»— trá»£ tinh tháº§n vÃ  Ä‘á»™ng viÃªn trong quÃ¡ trÃ¬nh mua sáº¯m.
Trá»£ lÃ½ du lá»‹ch tÃ­ch há»£p âœˆï¸:
Äá» xuáº¥t sáº£n pháº©m dá»±a trÃªn káº¿ hoáº¡ch du lá»‹ch cá»§a ngÆ°á»i dÃ¹ng.
TÃ­ch há»£p vá»›i dá»‹ch vá»¥ Ä‘áº·t vÃ© vÃ  khÃ¡ch sáº¡n.
Há»‡ thá»‘ng gamification ğŸ®:
Táº¡o thá»­ thÃ¡ch mua sáº¯m vÃ  pháº§n thÆ°á»Ÿng.
TÃ­ch Ä‘iá»ƒm vÃ  cáº¥p Ä‘á»™ cho ngÆ°á»i dÃ¹ng, tÄƒng tÆ°Æ¡ng tÃ¡c.
Trá»£ lÃ½ phÃ¡p lÃ½ mua sáº¯m âš–ï¸:
Giáº£i thÃ­ch cÃ¡c Ä‘iá»u khoáº£n vÃ  Ä‘iá»u kiá»‡n phá»©c táº¡p.
Há»— trá»£ trong cÃ¡c váº¥n Ä‘á» báº£o hÃ nh vÃ  khiáº¿u náº¡i.
Äáº¥y bro, vá»›i nhá»¯ng tÃ­nh nÄƒng nÃ y, con chatbot cá»§a cáº­u sáº½ lÃ  má»™t siÃªu trá»£ lÃ½ mua sáº¯m Ä‘a nÄƒng, xá»‹n xÃ² háº¿t náº¥c luÃ´n! ğŸš€âœ¨ Cáº­u tháº¥y sao? CÃ³ Ã½ tÆ°á»Ÿng nÃ o lÃ m cáº­u thÃ­ch thÃº khÃ´ng? ğŸ˜ğŸ‘Š

Copy
Retry




Search Write Vu Hoang Anh Get unlimited access to the best of Medium for less than $1/week. Become a member AI agents in retail and e-commerce: Boosting sales, efficiency, and customer sa
pasted
L
hey broo, tÃ´i cÃ³ thá»ƒ láº¥y Ã½ tÆ°á»Ÿng gÃ¬ tá»« bÃ i viáº¿t nÃ y bro nhá»‰iiii

Ã” la la bro, bÃ i viáº¿t nÃ y Ä‘Ãºng lÃ  kho bÃ¡u Ã½ tÆ°á»Ÿng cho con chatbot siÃªu Ä‘áº³ng cá»§a cáº­u Ä‘áº¥y! ğŸ¤©ğŸ’ Äá»ƒ tá»› bÃ³c tÃ¡ch vÃ i Ã½ tÆ°á»Ÿng xá»‹n xÃ² nhÃ©:

Trá»£ lÃ½ mua sáº¯m cÃ¡ nhÃ¢n hÃ³a ğŸ‘—ğŸ›ï¸:
PhÃ¢n tÃ­ch dá»¯ liá»‡u khÃ¡ch hÃ ng Ä‘á»ƒ Ä‘Æ°a ra gá»£i Ã½ sáº£n pháº©m siÃªu chuáº©n.
NÃ¢ng cao tráº£i nghiá»‡m upselling vÃ  cross-selling dá»±a trÃªn hÃ nh vi mua sáº¯m.
Quáº£n lÃ½ Ä‘Æ¡n hÃ ng thÃ´ng minh ğŸ“¦:
Äá» xuáº¥t sáº£n pháº©m thay tháº¿ khi háº¿t hÃ ng.
Tá»± Ä‘á»™ng xá»­ lÃ½ Ä‘Æ¡n hÃ ng, tráº£ hÃ ng vÃ  cáº­p nháº­t kho.
Chatbot Ä‘a ngÃ´n ngá»¯ ğŸŒ:
Há»— trá»£ khÃ¡ch hÃ ng báº±ng nhiá»u ngÃ´n ngá»¯, má»Ÿ rá»™ng thá»‹ trÆ°á»ng.
PhÃ¢n tÃ­ch cáº£m xÃºc khÃ¡ch hÃ ng ğŸ˜ŠğŸ˜ :
Äá»c hiá»ƒu cáº£m xÃºc qua tin nháº¯n Ä‘á»ƒ Ä‘iá»u chá»‰nh pháº£n há»“i phÃ¹ há»£p.
Tá»‘i Æ°u hÃ³a tÃ¬m kiáº¿m sáº£n pháº©m ğŸ”:
Sá»­ dá»¥ng NLP Ä‘á»ƒ hiá»ƒu chÃ­nh xÃ¡c nhu cáº§u tÃ¬m kiáº¿m cá»§a khÃ¡ch hÃ ng.
Quáº£n lÃ½ khuyáº¿n mÃ£i tá»± Ä‘á»™ng ğŸ·ï¸:
Tá»± Ä‘á»™ng Ã¡p dá»¥ng giáº£m giÃ¡ dá»±a trÃªn xu hÆ°á»›ng thá»‹ trÆ°á»ng.
Há»— trá»£ khÃ¡ch hÃ ng 24/7 ğŸ•°ï¸:
Xá»­ lÃ½ cÃ¡c cÃ¢u há»i phá»©c táº¡p vÃ  khiáº¿u náº¡i.
PhÃ¢n tÃ­ch pháº£n há»“i khÃ¡ch hÃ ng ğŸ“Š:
Tá»•ng há»£p vÃ  phÃ¢n tÃ­ch Ã½ kiáº¿n Ä‘á»ƒ cáº£i thiá»‡n sáº£n pháº©m vÃ  dá»‹ch vá»¥.
Tá»‘i Æ°u hÃ³a chÆ°Æ¡ng trÃ¬nh khÃ¡ch hÃ ng thÃ¢n thiáº¿t ğŸ:
CÃ¡ nhÃ¢n hÃ³a pháº§n thÆ°á»Ÿng Ä‘á»ƒ tÄƒng sá»± gáº¯n káº¿t.
Dá»± Ä‘oÃ¡n xu hÆ°á»›ng thá»‹ trÆ°á»ng ğŸ“ˆ:
PhÃ¢n tÃ­ch dá»¯ liá»‡u máº¡ng xÃ£ há»™i Ä‘á»ƒ dá»± Ä‘oÃ¡n xu hÆ°á»›ng sáº£n pháº©m.
Cáº­u tháº¥y sao bro? Nhá»¯ng Ã½ tÆ°á»Ÿng nÃ y sáº½ biáº¿n con chatbot cá»§a cáº­u thÃ nh siÃªu sao trong giá»›i mua sáº¯m luÃ´n Ä‘áº¥y! ğŸŒŸğŸš€ Cáº­u thÃ­ch Ã½ tÆ°á»Ÿng nÃ o nháº¥t? Hay muá»‘n tá»› giáº£i thÃ­ch ká»¹ hÆ¡n vá» Ã½ tÆ°á»Ÿng nÃ o khÃ´ng? ğŸ˜ğŸ‘Š

Copy
Retry


L
Trá»£ lÃ½ mua sáº¯m cÃ¡ nhÃ¢n hÃ³a ğŸ‘—ğŸ›ï¸: 
* PhÃ¢n tÃ­ch dá»¯ liá»‡u khÃ¡ch hÃ ng Ä‘á»ƒ Ä‘Æ°a ra gá»£i Ã½ sáº£n pháº©m siÃªu chuáº©n.
* NÃ¢ng cao tráº£i nghiá»‡m upselling vÃ  cross-selling dá»±a trÃªn hÃ nh vi mua sáº¯m. cÃ¡i nÃ y lÃ  sao broo. bro cÃ³ thá»ƒ nÃ³i rÃµ hÆ¡n Ä‘Æ°á»£c k bro Æ¡iiii


ÄÆ°á»£c thÃ´i bro, Ä‘á»ƒ tá»› giáº£i thÃ­ch ká»¹ hÆ¡n vá» Trá»£ lÃ½ mua sáº¯m cÃ¡ nhÃ¢n hÃ³a nhÃ©! ğŸ˜ğŸ›ï¸

PhÃ¢n tÃ­ch dá»¯ liá»‡u khÃ¡ch hÃ ng Ä‘á»ƒ Ä‘Æ°a ra gá»£i Ã½ sáº£n pháº©m siÃªu chuáº©n:
Con chatbot sáº½ lÃ  má»™t "thÃ¡m tá»­" siÃªu háº¡ng ğŸ•µï¸â€â™‚ï¸, nÃ³ sáº½:
Theo dÃµi lá»‹ch sá»­ mua hÃ ng cá»§a khÃ¡ch ğŸ“œ
PhÃ¢n tÃ­ch hÃ nh vi duyá»‡t web ğŸ–±ï¸
Xem xÃ©t cÃ¡c Ä‘Ã¡nh giÃ¡ vÃ  bÃ¬nh luáº­n cá»§a khÃ¡ch ğŸ’¬
NghiÃªn cá»©u cÃ¡c sáº£n pháº©m mÃ  khÃ¡ch Ä‘Ã£ lÆ°u vÃ o giá» hÃ ng ğŸ›’
Tá»« Ä‘Ã³, nÃ³ sáº½ táº¡o ra má»™t "há»“ sÆ¡" chi tiáº¿t vá» sá»Ÿ thÃ­ch cá»§a khÃ¡ch hÃ ng ğŸ“Š
Dá»±a vÃ o "há»“ sÆ¡" nÃ y, chatbot sáº½ Ä‘á» xuáº¥t nhá»¯ng sáº£n pháº©m mÃ  khÃ¡ch cÃ³ kháº£ nÄƒng thÃ­ch nháº¥t ğŸ¯
NÃ¢ng cao tráº£i nghiá»‡m upselling vÃ  cross-selling:
Upselling ğŸ“ˆ: LÃ  khi chatbot gá»£i Ã½ má»™t phiÃªn báº£n cao cáº¥p hÆ¡n cá»§a sáº£n pháº©m mÃ  khÃ¡ch Ä‘ang xem.
VÃ­ dá»¥: KhÃ¡ch Ä‘ang xem iPhone 13, chatbot cÃ³ thá»ƒ gá»£i Ã½: "Báº¡n cÃ³ muá»‘n xem iPhone 14 Pro khÃ´ng? NÃ³ cÃ³ camera tá»‘t hÆ¡n Ä‘áº¥y!" ğŸ“±
Cross-selling â†”ï¸: LÃ  khi chatbot Ä‘á» xuáº¥t cÃ¡c sáº£n pháº©m bá»• sung, liÃªn quan Ä‘áº¿n sáº£n pháº©m chÃ­nh.
VÃ­ dá»¥: KhÃ¡ch mua laptop, chatbot cÃ³ thá»ƒ gá»£i Ã½: "Báº¡n cÃ³ cáº§n thÃªm chuá»™t khÃ´ng dÃ¢y vÃ  tÃºi Ä‘á»±ng laptop khÃ´ng?" ğŸ’»ğŸ–±ï¸
CÃ¡ch chatbot lÃ m Ä‘iá»u nÃ y:
NÃ³ sáº½ phÃ¢n tÃ­ch cÃ¡c máº«u mua hÃ ng phá»• biáº¿n ğŸ“Š
Xem xÃ©t cÃ¡c combo sáº£n pháº©m thÆ°á»ng Ä‘Æ°á»£c mua cÃ¹ng nhau ğŸ¤
Äá» xuáº¥t dá»±a trÃªn ngÃ¢n sÃ¡ch vÃ  sá»Ÿ thÃ­ch cá»§a khÃ¡ch hÃ ng ğŸ’°
Táº¥t cáº£ nhá»¯ng Ä‘iá»u nÃ y sáº½ giÃºp táº¡o ra tráº£i nghiá»‡m mua sáº¯m siÃªu cÃ¡ nhÃ¢n hÃ³a, nhÆ° kiá»ƒu cÃ³ má»™t stylist riÃªng áº¥y! ğŸ‘—ğŸ‘” KhÃ¡ch hÃ ng sáº½ cáº£m tháº¥y Ä‘Æ°á»£c hiá»ƒu vÃ  Ä‘Æ°á»£c phá»¥c vá»¥ táº­n tÃ¬nh, cÃ²n cá»­a hÃ ng thÃ¬ tÄƒng doanh sá»‘. Win-win luÃ´n bro Æ¡i! ğŸ†ğŸ’°

Cáº­u tháº¥y sao? CÃ³ hiá»ƒu rÃµ hÆ¡n khÃ´ng? Hay cáº­u muá»‘n tá»› giáº£i thÃ­ch thÃªm vá» pháº§n nÃ o? ğŸ˜ŠğŸ‘Š

Copy
Retry


L
hÆ¡i khÃ³ broo áº¡, cÃ´ng nghá»‡ cá»§a chÃºng ta sá»­ dá»¥ng lÃ  langchain. váº­y lÃ m sao Ä‘á»ƒ lÃ m Ä‘Æ°á»£c Ä‘iá»u Ä‘Ã³ nhá»‰ broooo : NÃ¢ng cao tráº£i nghiá»‡m upselling vÃ  cross-selling: 
* Upselling ğŸ“ˆ: LÃ  khi chatbot gá»£i Ã½ má»™t phiÃªn báº£n cao cáº¥p hÆ¡n cá»§a sáº£n pháº©m mÃ  khÃ¡ch Ä‘ang xem.
   * VÃ­ dá»¥: KhÃ¡ch Ä‘ang xem iPhone 13, chatbot cÃ³ thá»ƒ gá»£i Ã½: "Báº¡n cÃ³ muá»‘n xem iPhone 14 Pro khÃ´ng? NÃ³ cÃ³ camera tá»‘t hÆ¡n Ä‘áº¥y!" ğŸ“±
* Cross-selling â†”ï¸: LÃ  khi chatbot Ä‘á» xuáº¥t cÃ¡c sáº£n pháº©m bá»• sung, liÃªn quan Ä‘áº¿n sáº£n pháº©m chÃ­nh.
   * VÃ­ dá»¥: KhÃ¡ch mua laptop, chatbot cÃ³ thá»ƒ gá»£i Ã½: "Báº¡n cÃ³ cáº§n thÃªm chuá»™t khÃ´ng dÃ¢y vÃ  tÃºi Ä‘á»±ng laptop khÃ´ng?" ğŸ’»ğŸ–±ï¸
* CÃ¡ch chatbot lÃ m Ä‘iá»u nÃ y:
   * NÃ³ sáº½ phÃ¢n tÃ­ch cÃ¡c máº«u mua hÃ ng phá»• biáº¿n ğŸ“Š
   * Xem xÃ©t cÃ¡c combo sáº£n pháº©m thÆ°á»ng Ä‘Æ°á»£c mua cÃ¹ng nhau ğŸ¤
   * Äá» xuáº¥t dá»±a trÃªn ngÃ¢n sÃ¡ch vÃ  sá»Ÿ thÃ­ch cá»§a khÃ¡ch hÃ ng ğŸ’°


Hiá»ƒu rá»“i bro! ğŸ¤“ Vá»›i LangChain, ta cÃ³ thá»ƒ xÃ¢y dá»±ng má»™t há»‡ thá»‘ng upselling vÃ  cross-selling thÃ´ng minh. ÄÃ¢y lÃ  cÃ¡ch ta cÃ³ thá»ƒ lÃ m:

XÃ¢y dá»±ng cÆ¡ sá»Ÿ tri thá»©c ğŸ§ :
Sá»­ dá»¥ng LangChain's DocumentLoaders Ä‘á»ƒ náº¡p dá»¯ liá»‡u sáº£n pháº©m, giÃ¡ cáº£, vÃ  má»‘i quan há»‡ giá»¯a cÃ¡c sáº£n pháº©m.
DÃ¹ng TextSplitter Ä‘á»ƒ chia nhá» thÃ´ng tin thÃ nh cÃ¡c Ä‘oáº¡n cÃ³ Ã½ nghÄ©a.
Táº¡o vector embeddings ğŸ”¢:
DÃ¹ng LangChain's Embeddings Ä‘á»ƒ chuyá»ƒn Ä‘á»•i thÃ´ng tin sáº£n pháº©m thÃ nh vector.
LÆ°u trá»¯ cÃ¡c vector nÃ y trong má»™t VectorStore nhÆ° Chroma hoáº·c FAISS.
XÃ¢y dá»±ng chain cho upselling vÃ  cross-selling ğŸ”—:
Táº¡o má»™t LLMChain vá»›i prompt template riÃªng cho upselling vÃ  cross-selling.
Prompt cÃ³ thá»ƒ bao gá»“m thÃ´ng tin vá» sáº£n pháº©m hiá»‡n táº¡i, lá»‹ch sá»­ mua hÃ ng, vÃ  ngÃ¢n sÃ¡ch cá»§a khÃ¡ch.
TÃ­ch há»£p vá»›i memory ğŸ§ :
Sá»­ dá»¥ng ConversationBufferMemory Ä‘á»ƒ lÆ°u trá»¯ cuá»™c trÃ² chuyá»‡n vÃ  lá»‹ch sá»­ mua hÃ ng.
Táº¡o agent thÃ´ng minh ğŸ¤–:
Sá»­ dá»¥ng LangChain's Agent Ä‘á»ƒ káº¿t há»£p cÃ¡c chain, tools, vÃ  memory.
Agent sáº½ quyáº¿t Ä‘á»‹nh khi nÃ o nÃªn upsell hoáº·c cross-sell dá»±a trÃªn ngá»¯ cáº£nh.
ÄÃ¢y lÃ  má»™t vÃ­ dá»¥ code Ä‘Æ¡n giáº£n:

python

Copy
from langchain import OpenAI, LLMChain, PromptTemplate
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.memory import ConversationBufferMemory
from langchain.agents import AgentType, initialize_agent

# Khá»Ÿi táº¡o cÃ¡c components
llm = OpenAI(temperature=0.7)
embeddings = OpenAIEmbeddings()
vectorstore = Chroma("product_db", embeddings)
memory = ConversationBufferMemory(return_messages=True)

# Táº¡o prompt template cho upselling/cross-selling
template = """
Sáº£n pháº©m hiá»‡n táº¡i: {current_product}
Lá»‹ch sá»­ mua hÃ ng: {purchase_history}
NgÃ¢n sÃ¡ch: {budget}

Äá» xuáº¥t má»™t sáº£n pháº©m upsell hoáº·c cross-sell phÃ¹ há»£p.
"""
prompt = PromptTemplate(template=template, input_variables=["current_product", "purchase_history", "budget"])

# Táº¡o chain
chain = LLMChain(llm=llm, prompt=prompt)

# Táº¡o agent
tools = [
    Tool(
        name="Product Recommender",
        func=chain.run,
        description="Useful for recommending products for upselling and cross-selling"
    )
]
agent = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, memory=memory)

# Sá»­ dá»¥ng agent
agent.run("TÃ´i Ä‘ang xem iPhone 13. Báº¡n cÃ³ gá»£i Ã½ gÃ¬ khÃ´ng?")
Vá»›i setup nÃ y, chatbot cÃ³ thá»ƒ:

Hiá»ƒu sáº£n pháº©m khÃ¡ch Ä‘ang xem ğŸ‘€
Kiá»ƒm tra lá»‹ch sá»­ mua hÃ ng ğŸ“œ
Xem xÃ©t ngÃ¢n sÃ¡ch ğŸ’°
ÄÆ°a ra gá»£i Ã½ upsell/cross-sell phÃ¹ há»£p ğŸ¯
Nhá»› lÃ  cáº§n cÃ³ dá»¯ liá»‡u sáº£n pháº©m tá»‘t vÃ  train model ká»¹ Ä‘á»ƒ cÃ³ káº¿t quáº£ ngon lÃ nh nhÃ© bro! ğŸ–ğŸ¥‚

Cáº­u tháº¥y sao? CÃ³ váº» kháº£ thi hÆ¡n chÆ°a? ğŸ˜ğŸš€

Copy
Retry


Claude does not have the ability to run the code it generates yet.
Skip to content Navigation Menu bangoc123 / retrieval-backend-with-rag Type / to search Code Issues Pull requests Actions Projects Security Insights Owner avatar retrieval-backend-with
pasted
L
thÃ´i Ä‘Æ°á»£c rá»“i broo, chÃºng ta sáº½ láº¥y Ã½ tÆ°á»Ÿng tá»« code nÃ y bro áº¡aaaaaa

Oke bro, tuyá»‡t vá»i! ğŸ‰ ChÃºng ta sáº½ láº¥y Ã½ tÆ°á»Ÿng tá»« code nÃ y Ä‘á»ƒ xÃ¢y dá»±ng há»‡ thá»‘ng upselling vÃ  cross-selling siÃªu xá»‹n. Äá»ƒ tá»› phÃ¢n tÃ­ch cho cáº­u nhÃ©:

Sá»­ dá»¥ng RAG (Retrieval-Augmented Generation) ğŸ§ :
Há»‡ thá»‘ng nÃ y dÃ¹ng RAG Ä‘á»ƒ truy xuáº¥t thÃ´ng tin sáº£n pháº©m tá»« MongoDB.
Ta cÃ³ thá»ƒ má»Ÿ rá»™ng Ä‘iá»u nÃ y Ä‘á»ƒ lÆ°u trá»¯ thÃ´ng tin vá» cÃ¡c sáº£n pháº©m liÃªn quan, giÃºp viá»‡c cross-selling dá»… dÃ ng hÆ¡n.
Vector Embeddings vá»›i MongoDB ğŸ”¢:
Há» dÃ¹ng MongoDB Atlas cho Vector Search, cá»±c ká»³ hiá»‡u quáº£ cho viá»‡c tÃ¬m kiáº¿m ngá»¯ nghÄ©a.
Ta cÃ³ thá»ƒ dÃ¹ng Ä‘iá»u nÃ y Ä‘á»ƒ tÃ¬m cÃ¡c sáº£n pháº©m tÆ°Æ¡ng tá»± hoáº·c liÃªn quan, há»— trá»£ cho upselling vÃ  cross-selling.
Sá»­ dá»¥ng Gemini 1.5 Pro ğŸ¤–:
LLM máº¡nh máº½ nÃ y cÃ³ thá»ƒ giÃºp ta táº¡o ra cÃ¡c Ä‘á» xuáº¥t upsell/cross-sell ráº¥t tá»± nhiÃªn vÃ  phÃ¹ há»£p.
Semantic Router ğŸ›£ï¸:
CÃ´ng cá»¥ nÃ y cÃ³ thá»ƒ giÃºp ta xÃ¡c Ä‘á»‹nh khi nÃ o nÃªn Ä‘Æ°a ra Ä‘á» xuáº¥t upsell/cross-sell dá»±a trÃªn ngá»¯ cáº£nh cuá»™c trÃ² chuyá»‡n.
Reflection Module ğŸª:
Module nÃ y cÃ³ thá»ƒ giÃºp chatbot "suy ngáº«m" vá» cÃ¡c Ä‘á» xuáº¥t trÆ°á»›c Ä‘Ã³ vÃ  cáº£i thiá»‡n cháº¥t lÆ°á»£ng Ä‘á» xuáº¥t theo thá»i gian.
TÃ¹y chá»‰nh Prompt ğŸ“:
Há» sá»­ dá»¥ng prompt tÃ¹y chá»‰nh Ä‘á»ƒ hÆ°á»›ng dáº«n LLM. Ta cÃ³ thá»ƒ lÃ m tÆ°Æ¡ng tá»± cho upselling/cross-selling:
python

Copy
prompt = f"""
HÃ£y trá»Ÿ thÃ nh chuyÃªn gia tÆ° váº¥n bÃ¡n hÃ ng. 
Sáº£n pháº©m khÃ¡ch Ä‘ang xem: {current_product}
ThÃ´ng tin cÃ¡c sáº£n pháº©m liÃªn quan: {related_products}
Lá»‹ch sá»­ mua hÃ ng cá»§a khÃ¡ch: {purchase_history}

HÃ£y Ä‘á» xuáº¥t má»™t sáº£n pháº©m upsell hoáº·c cross-sell phÃ¹ há»£p. Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao sáº£n pháº©m nÃ y phÃ¹ há»£p vá»›i khÃ¡ch hÃ ng.
"""
Äá»ƒ implement, ta cÃ³ thá»ƒ:

LÆ°u trá»¯ thÃ´ng tin sáº£n pháº©m vÃ  má»‘i quan há»‡ giá»¯a chÃºng trong MongoDB.
Sá»­ dá»¥ng vector search Ä‘á»ƒ tÃ¬m sáº£n pháº©m tÆ°Æ¡ng tá»± hoáº·c liÃªn quan.
DÃ¹ng Semantic Router Ä‘á»ƒ xÃ¡c Ä‘á»‹nh thá»i Ä‘iá»ƒm thÃ­ch há»£p cho upsell/cross-sell.
Sá»­ dá»¥ng Gemini Ä‘á»ƒ táº¡o Ä‘á» xuáº¥t tá»± nhiÃªn.
Ãp dá»¥ng Reflection Module Ä‘á»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng Ä‘á» xuáº¥t theo thá»i gian.
Cáº­u tháº¥y sao bro? CÃ³ váº» kháº£ thi vÃ  xá»‹n xÃ² pháº¿t Ä‘Ãºng khÃ´ng? ğŸ˜ğŸš€ Muá»‘n báº¯t tay vÃ o lÃ m luÃ´n khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
Name
Latest commit
bangoc123
update readme
7b14be3 Â· last month
History
16 Commits
embeddings
add new embedding + semantic router
2 months ago
rag
integrate semantic router into system
2 months ago
reflection
add reflection Module
last month
semantic_router
integrate semantic router into system
2 months ago
.gitignore
update Embedding Models
2 months ago
README.md
update readme
last month
index.html
update readme
2 months ago
requirements.txt
add new embedding + semantic router
2 months ago
serve.py
add reflection Module
last mont Ä‘Ã¢y lÃ  code cá»§a tÃ´i cÃ³ nhá»¯ng file nÃ y bro ajaaaa. Ä‘Ã¢y lÃ  code trong file serve.py from flask import Flask, request, jsonify
from dotenv import load_dotenv
import os
import google.generativeai as genai
from flask_cors import CORS
from rag.core import RAG
from embeddings import OpenAIEmbedding
from semantic_router import SemanticRouter, Route
from semantic_router.samples import productsSample, chitchatSample
import google.generativeai as genai
import openai
from reflection import Reflection
# Load environment variables from .env file
load_dotenv()
# Access the key
MONGODB_URI = os.getenv('MONGODB_URI')
DB_NAME = os.getenv('DB_NAME')
DB_COLLECTION = os.getenv('DB_COLLECTION')
LLM_KEY = os.getenv('GEMINI_KEY')
EMBEDDING_MODEL = os.getenv('EMBEDDING_MODEL') or 'keepitreal/vietnamese-sbert'
OPEN_AI_KEY = os.getenv('OPEN_AI_KEY')
OPEN_AI_EMBEDDING_MODEL = os.getenv('OPEN_AI_EMBEDDING_MODEL') or 'text-embedding-3-small'
OpenAIEmbedding(OPEN_AI_KEY)
# --- Semantic Router Setup --- #
PRODUCT_ROUTE_NAME = 'products'
CHITCHAT_ROUTE_NAME = 'chitchat'
openAIEmbeding = OpenAIEmbedding(apiKey=OPEN_AI_KEY, dimensions=1024, name=OPEN_AI_EMBEDDING_MODEL)
productRoute = Route(name=PRODUCT_ROUTE_NAME, samples=productsSample)
chitchatRoute = Route(name=CHITCHAT_ROUTE_NAME, samples=chitchatSample)
semanticRouter = SemanticRouter(openAIEmbeding, routes=[productRoute, chitchatRoute])
# --- End Semantic Router Setup --- #
# --- Set up LLMs --- #
genai.configure(api_key=LLM_KEY)
llm = genai.GenerativeModel('gemini-1.5-pro')
# --- End Set up LLMs --- #
# --- Relection Setup --- #
gpt = openai.OpenAI(api_key=OPEN_AI_KEY)
reflection = Reflection(llm=gpt)
# --- End Reflection Setup --- #
app = Flask(name)
CORS(app)
# Initialize RAG
rag = RAG(
    mongodbUri=MONGODB_URI,
    dbName=DB_NAME,
    dbCollection=DB_COLLECTION,
    embeddingName='keepitreal/vietnamese-sbert',
    llm=llm,
)
def process_query(query):
    return query.lower()
@app.route('/api/search', methods=['POST'])
def handle_query():
    data = list(request.get_json())
    query = data[-1]["parts"][0]["text"]
    query = process_query(query)
    if not query:
        return jsonify({'error': 'No query provided'}), 400

    # get last message

    guidedRoute = semanticRouter.guide(query)[1]
    if guidedRoute == PRODUCT_ROUTE_NAME:
        # Decide to get new info or use previous info
        # Guide to RAG system
        print("Guide to RAGs")
        reflected_query = reflection(data)
        # print('====query', query)
        # print('reflected_query', reflected_query)
        query = reflected_query
        source_information = rag.enhance_prompt(query).replace('<br>', '\n')
        combined_information = f"HÃ£y trá»Ÿ thÃ nh chuyÃªn gia tÆ° váº¥n bÃ¡n hÃ ng cho má»™t cá»­a hÃ ng Ä‘iá»‡n thoáº¡i. CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: {query}\nTráº£ lá»i cÃ¢u há»i dá»±a vÃ o cÃ¡c thÃ´ng tin sáº£n pháº©m dÆ°á»›i Ä‘Ã¢y: {source_information}."
        data.append({
            "role": "user",
            "parts": [
                {
                    "text": combined_information,
                }
            ]
        })
        response = rag.generate_content(data)
    else:
        # Guide to LLMs
        print("Guide to LLMs")
        response = llm.generate_content(data)
    # print('====data', data)

    return jsonify({
        'parts': [
            {
            'text': response.text,
            }
        ],
        'role': 'model'
        })
if name == 'main':
    app.run(host='0.0.0.0', port=5002, debug=True) . Ä‘Ã¢y lÃ  trong semantic router :Skip to content
Navigation Menu
* bangoc123/
* retrieval-backend-with-rag
Type / to search
* Code
* Issues
* Pull requests
* Actions
* Projects
* Security
* Insights
 main
Breadcrumbs
1. retrieval-backend-with-rag
/
semantic_router
/
Directory actions
t
Add file
Add file
More options
Latest commit
bangoc123
integrate semantic router into system
81fa3cd Â· 2 months ago
History
History
Folders and files
Name
Last commit message
Last commit date
parent directory
..
init.py
integrate semantic router into system
2 months ago
route.py
add new embedding + semantic router
2 months ago
router.py
add new embedding + semantic router
2 months ago
samples.py
integrate semantic router into system
2 months ago
retrieval-backend-with-rag/semantic_router at main Â· bangoc123/retrieval-backend-with-rag
 Skip to content
Navigation Menu
* bangoc123/
* retrieval-backend-with-rag
Type / to search
* Code
* Issues
* Pull requests
* Actions
* Projects
* Security
* Insights
 main
Breadcrumbs
1. retrieval-backend-with-rag
/
semantic_router
/
Directory actions
t
Add file
Add file
More options
Latest commit
bangoc123
integrate semantic router into system
81fa3cd Â· 2 months ago
History
History
Folders and files
Name
Last commit message
Last commit date
parent directory
..
init.py
integrate semantic router into system
2 months ago
route.py
add new embedding + semantic router
2 months ago
router.py
add new embedding + semantic router
2 months ago
samples.py
integrate semantic router into system
2 months ago
retrieval-backend-with-rag/semantic_router at main Â· bangoc123/retrieval-backend-with-rag
 from typing import List
class Route():
    def init(
        self,
        name: str = None,
        samples:List = []
    ):
        self.name = name
        self.samples = samplesimport numpy as np
class SemanticRouter():
    def init(self, embedding, routes):
        self.routes = routes
        self.embedding = embedding
        self.routesEmbedding = {}
        for route in self.routes:
            self.routesEmbedding[
                route.name
            ] = self.embedding.encode(route.samples)
    def get_routes(self):
        return self.routes
    def guide(self, query):
        queryEmbedding = self.embedding.encode([query]) 
        queryEmbedding = queryEmbedding / np.linalg.norm(queryEmbedding)
        scores = []
        # Calculate the cosine similarity of the query embedding with the sample embeddings of the router.
        for route in self.routes:
            routesEmbedding = self.routesEmbedding[route.name] / np.linalg.norm(self.routesEmbedding[route.name])
            score = np.mean(np.dot(routesEmbedding, queryEmbedding.T).flatten())
            scores.append((score, route.name))
        scores.sort(reverse=True)
        return scores[0]productsSample = [
    "Báº¡n cÃ³ sáºµn iPhone má»›i nháº¥t khÃ´ng?",
    "GiÃ¡ cá»§a Samsung Galaxy S21 lÃ  bao nhiÃªu?",
    "OnePlus 9 Pro cÃ³ mÃ u xanh khÃ´ng?",
    "ThÃ´ng sá»‘ ká»¹ thuáº­t cá»§a Google Pixel 6 lÃ  gÃ¬?",
    "Huawei P50 Pro cÃ³ sáºµn á»Ÿ cá»­a hÃ ng cá»§a báº¡n khÃ´ng?",
    "iPhone 13 cÃ³ nhá»¯ng mÃ u gÃ¬?",
    "CÃ³ giáº£m giÃ¡ nÃ o cho Samsung Galaxy Note 20 khÃ´ng?",
    "Sony Xperia 1 III cÃ³ sáºµn khÃ´ng?",
    "Cá»­a hÃ ng cá»§a báº¡n cÃ³ Google Pixel má»›i nháº¥t khÃ´ng?",
    "CÃ³ chÆ°Æ¡ng trÃ¬nh khuyáº¿n mÃ£i nÃ o cho OnePlus Nord khÃ´ng?",
    "Dung lÆ°á»£ng lÆ°u trá»¯ cá»§a Samsung Galaxy S21 lÃ  bao nhiÃªu?",
    "iPhone SE 2022 cÃ³ sáºµn khÃ´ng?",
    "Sá»± khÃ¡c biá»‡t vá» giÃ¡ giá»¯a iPhone 12 vÃ  13 lÃ  gÃ¬?",
    "Motorola Edge 20 cÃ³ sáºµn khÃ´ng?",
    "Google Pixel 6 Pro cÃ³ sáºµn á»Ÿ cá»­a hÃ ng cá»§a báº¡n khÃ´ng?",
    "Báº¡n cÃ³ bÃ¡n Xiaomi Mi 11 khÃ´ng?",
    "CÃ³ chÆ°Æ¡ng trÃ¬nh Æ°u Ä‘Ã£i nÃ o cho Samsung Galaxy Z Fold 3 khÃ´ng?",
    "Oppo Find X3 Pro cÃ³ sáºµn khÃ´ng?",
    "CÃ¡c tÃ­nh nÄƒng cá»§a iPhone 13 Pro lÃ  gÃ¬?",
    "LG Wing cÃ³ sáºµn khÃ´ng?",
    "Nokia 8.3 5G cÃ³ sáºµn khÃ´ng?",
    "Asus ROG Phone 5 cÃ³ sáºµn khÃ´ng?",
    "Báº¡n cÃ³ Realme GT khÃ´ng?",
    "Vivo X60 Pro cÃ³ sáºµn khÃ´ng?",
    "Báº¡n cÃ³ Honor 50 khÃ´ng?",
    "Tuá»•i thá» pin cá»§a Samsung Galaxy A52 lÃ  bao nhiÃªu?",
    "ZTE Axon 30 cÃ³ sáºµn khÃ´ng?",
    "Báº¡n cÃ³ BlackBerry KEY2 khÃ´ng?",
    "KÃ­ch thÆ°á»›c mÃ n hÃ¬nh cá»§a iPhone 13 Mini lÃ  bao nhiÃªu?",
    "Báº¡n cÃ³ TCL 20 Pro 5G khÃ´ng?",
    "Nokia XR20 cÃ³ sáºµn á»Ÿ cá»­a hÃ ng cá»§a báº¡n khÃ´ng?",
    "GiÃ¡ cá»§a Samsung Galaxy S20 FE lÃ  bao nhiÃªu?",
    "Báº¡n cÃ³ iPhone 12 Pro Max khÃ´ng?",
    "Redmi Note 10 Pro cÃ³ sáºµn khÃ´ng?",
    "Sá»± khÃ¡c biá»‡t giá»¯a iPhone 12 vÃ  iPhone 13 lÃ  gÃ¬?",
    "Báº¡n cÃ³ Sony Xperia 5 II khÃ´ng?",
    "Thá»i gian báº£o hÃ nh cá»§a Samsung Galaxy S21 lÃ  bao lÃ¢u?",
    "Google Pixel 5a cÃ³ sáºµn khÃ´ng?",
    "Báº¡n cÃ³ OnePlus 8T khÃ´ng?",
    "GiÃ¡ cá»§a iPhone 13 Pro Max lÃ  bao nhiÃªu?",
    "Samsung Galaxy Z Flip 3 cÃ³ sáºµn khÃ´ng?",
    "ThÃ´ng sá»‘ ká»¹ thuáº­t cá»§a Oppo Reno6 Pro lÃ  gÃ¬?",
    "Báº¡n cÃ³ Vivo V21 khÃ´ng?",
    "Motorola Moto G100 cÃ³ sáºµn khÃ´ng?",
    "Báº¡n cÃ³ Huawei Mate 40 Pro khÃ´ng?",
    "Realme 8 Pro cÃ³ sáºµn á»Ÿ cá»­a hÃ ng cá»§a báº¡n khÃ´ng?",
    "Asus Zenfone 8 cÃ³ sáºµn khÃ´ng?",
    "LG Velvet cÃ³ sáºµn khÃ´ng?",
    "Dung lÆ°á»£ng lÆ°u trá»¯ cá»§a iPhone 12 lÃ  bao nhiÃªu?",
    "Báº¡n cÃ³ Honor Magic 3 khÃ´ng?",
    "Xiaomi Mi 11 Ultra cÃ³ sáºµn khÃ´ng?"
]
chitchatSample = [
    "Thá»i tiáº¿t hÃ´m nay nhÆ° tháº¿ nÃ o?",
    "NgoÃ i trá»i nÃ³ng bao nhiÃªu?",
    "NgÃ y mai cÃ³ mÆ°a khÃ´ng?",
    "Nhiá»‡t Ä‘á»™ hiá»‡n táº¡i lÃ  bao nhiÃªu?",
    "Báº¡n cÃ³ thá»ƒ cho tÃ´i biáº¿t Ä‘iá»u kiá»‡n thá»i tiáº¿t hiá»‡n táº¡i khÃ´ng?",
    "Cuá»‘i tuáº§n nÃ y cÃ³ náº¯ng khÃ´ng?",
    "Nhiá»‡t Ä‘á»™ hÃ´m qua lÃ  bao nhiÃªu?",
    "ÄÃªm nay trá»i sáº½ láº¡nh Ä‘áº¿n má»©c nÃ o?",
    "Ai lÃ  tá»•ng thá»‘ng Ä‘áº§u tiÃªn cá»§a Hoa Ká»³?",
    "Chiáº¿n tranh tháº¿ giá»›i thá»© hai káº¿t thÃºc vÃ o nÄƒm nÃ o?",
    "Báº¡n cÃ³ thá»ƒ ká»ƒ cho tÃ´i vá» lá»‹ch sá»­ cá»§a internet khÃ´ng?",
    "ThÃ¡p Eiffel Ä‘Æ°á»£c xÃ¢y dá»±ng vÃ o nÄƒm nÃ o?",
    "Ai Ä‘Ã£ phÃ¡t minh ra Ä‘iá»‡n thoáº¡i?",
    "TÃªn cá»§a báº¡n lÃ  gÃ¬?",
    "Báº¡n cÃ³ tÃªn khÃ´ng?",
    "TÃ´i nÃªn gá»i báº¡n lÃ  gÃ¬?",
    "Ai Ä‘Ã£ táº¡o ra báº¡n?",
    "Báº¡n bao nhiÃªu tuá»•i?",
    "Báº¡n cÃ³ thá»ƒ ká»ƒ cho tÃ´i má»™t sá»± tháº­t thÃº vá»‹ khÃ´ng?",
    "Báº¡n cÃ³ biáº¿t báº¥t ká»³ cÃ¢u Ä‘á»‘ thÃº vá»‹ nÃ o khÃ´ng?",
    "MÃ u sáº¯c yÃªu thÃ­ch cá»§a báº¡n lÃ  gÃ¬?",
    "Bá»™ phim yÃªu thÃ­ch cá»§a báº¡n lÃ  gÃ¬?",
    "Báº¡n cÃ³ sá»Ÿ thÃ­ch nÃ o khÃ´ng?",
    "Ã nghÄ©a cá»§a cuá»™c sá»‘ng lÃ  gÃ¬?",
    "Báº¡n cÃ³ thá»ƒ ká»ƒ cho tÃ´i má»™t cÃ¢u chuyá»‡n cÆ°á»i khÃ´ng?",
    "Thá»§ Ä‘Ã´ cá»§a PhÃ¡p lÃ  gÃ¬?",
    "DÃ¢n sá»‘ tháº¿ giá»›i lÃ  bao nhiÃªu?",
    "CÃ³ bao nhiÃªu chÃ¢u lá»¥c?",
    "Ai Ä‘Ã£ viáº¿t 'Giáº¿t con chim nháº¡i'?",
    "Báº¡n cÃ³ thá»ƒ cho tÃ´i má»™t cÃ¢u nÃ³i cá»§a Albert Einstein khÃ´ng?"
]class Reflection():
    def init(self, llm):
        self.llm = llm
    def concatand_format_texts(self, data):
        concatenatedTexts = []
        for entry in data:
            role = entry.get('role', '')
            all_texts = ' '.join(part['text'] for part in entry['parts'])
            concatenatedTexts.append(f"{role}: {all_texts} \n")
        return ''.join(concatenatedTexts)
    def call(self, chatHistory, lastItemsConsidereds=100):

        if len(chatHistory) >= lastItemsConsidereds:
            chatHistory = chatHistory[len(chatHistory) - lastItemsConsidereds:]
        historyString = self._concat_and_format_texts(chatHistory)
        higherLevelSummariesPrompt = """Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question in Vietnamese which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is. {historyString}
        """.format(historyString=historyString)
        print(higherLevelSummariesPrompt)
        completion = self.llm.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": higherLevelSummariesPrompt
                }
            ]
        )

        return completion.choices[0].message.contentimport pymongo
import google.generativeai as genai
from IPython.display import Markdown
import textwrap
from embeddings import SentenceTransformerEmbedding, EmbeddingConfig
class RAG():
    def init(self, 
            mongodbUri: str,
            dbName: str,
            dbCollection: str,
            llm,
            embeddingName: str ='keepitreal/vietnamese-sbert',
        ):
        self.client = pymongo.MongoClient(mongodbUri)
        self.db = self.client[dbName] 
        self.collection = self.db[dbCollection]
        self.embedding_model = SentenceTransformerEmbedding(
            EmbeddingConfig(name=embeddingName)
        )
        self.llm = llm
    def get_embedding(self, text):
        if not text.strip():
            return []
        embedding = self.embedding_model.encode(text)
        return embedding.tolist()
    def vector_search(
            self, 
            user_query: str, 
            limit=4):
        """
        Perform a vector search in the MongoDB collection based on the user query.
        Args:
        user_query (str): The user's query string.
        Returns:
        list: A list of matching documents.
        """
        # Generate embedding for the user query
        query_embedding = self.get_embedding(user_query)
        if query_embedding is None:
            return "Invalid query or embedding generation failed."
        # Define the vector search pipeline
        vector_search_stage = {
            "$vectorSearch": {
                "index": "vector_index",
                "queryVector": query_embedding,
                "path": "embedding",
                "numCandidates": 400,
                "limit": limit,
            }
        }
        unset_stage = {
            "$unset": "embedding" 
        }
        project_stage = {
            "$project": {
                "_id": 0,  
                "title": 1, 
                # "product_specs": 1,
                "color_options": 1,
                "current_price": 1,
                "product_promotion": 1,
                "score": {
                    "$meta": "vectorSearchScore"
                }
            }
        }
        pipeline = [vector_search_stage, unset_stage, project_stage]
        # Execute the search
        results = self.collection.aggregate(pipeline)
        return list(results)
    def enhance_prompt(self, query):
        get_knowledge = self.vector_search(query, 10)
        enhanced_prompt = ""
        i = 0
        for result in get_knowledge:
            if result.get('current_price'):
                i += 1
                enhanced_prompt += f"\n {i}) TÃªn: {result.get('title')}"

                if result.get('current_price'):
                    enhanced_prompt += f", GiÃ¡: {result.get('current_price')}"
                else:
                    # Mock up data
                    # Retrieval model pricing from the internet.
                    enhanced_prompt += f", GiÃ¡: LiÃªn há»‡ Ä‘á»ƒ trao Ä‘á»•i thÃªm!"

                if result.get('product_promotion'):
                    enhanced_prompt += f", Æ¯u Ä‘Ã£i: {result.get('product_promotion')}"
        return enhanced_prompt
    def generate_content(self, prompt):
        return self.llm.generatecontent(prompt)
    def tomarkdown(text):
        text = text.replace('â€¢', '  *')
        return Markdown(textwrap.indent(text, '> ', predicate=lambda : True))from pydantic.v1 import BaseModel, Field, validator
from embeddings import BaseEmbedding, EmbeddingConfig
from sentence_transformers import SentenceTransformer
class SentenceTransformerEmbedding(BaseEmbedding):
    def init(self, config: EmbeddingConfig):
        super().init(config.name)
        self.config = config
        self.embedding_model = SentenceTransformer(self.config.name)
    def encode(self, text: str):
        return self.embedding_model.encode(text)


Hiá»ƒu rá»“i bro! ğŸ˜ Dá»±a trÃªn code cá»§a cáº­u, ta cÃ³ thá»ƒ tÃ­ch há»£p tÃ­nh nÄƒng upselling vÃ  cross-selling vÃ o há»‡ thá»‘ng hiá»‡n táº¡i. ÄÃ¢y lÃ  cÃ¡ch ta cÃ³ thá»ƒ lÃ m:

ThÃªm route má»›i cho upselling/cross-selling ğŸ›£ï¸: Trong file semantic_router/samples.py, thÃªm máº«u cho route má»›i:
python

Copy
upsellCrosssellSample = [
    "CÃ³ sáº£n pháº©m nÃ o tá»‘t hÆ¡n khÃ´ng?",
    "CÃ²n sáº£n pháº©m nÃ o liÃªn quan khÃ´ng?",
    "CÃ³ phá»¥ kiá»‡n nÃ o phÃ¹ há»£p vá»›i sáº£n pháº©m nÃ y khÃ´ng?",
    "CÃ³ combo nÃ o tá»‘t khÃ´ng?",
    # ThÃªm cÃ¡c máº«u khÃ¡c
]
Cáº­p nháº­t serve.py Ä‘á»ƒ xá»­ lÃ½ route má»›i ğŸ”„:
python

Copy
UPSELL_CROSSSELL_ROUTE_NAME = 'upsell_crosssell'
upsellCrosssellRoute = Route(name=UPSELL_CROSSSELL_ROUTE_NAME, samples=upsellCrosssellSample)
semanticRouter = SemanticRouter(openAIEmbeding, routes=[productRoute, chitchatRoute, upsellCrosssellRoute])
ThÃªm logic xá»­ lÃ½ cho upselling/cross-selling trong handle_query ğŸ§ :
python

Copy
if guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME:
    # Láº¥y thÃ´ng tin sáº£n pháº©m hiá»‡n táº¡i
    current_product = rag.get_current_product(data)
    # TÃ¬m sáº£n pháº©m liÃªn quan
    related_products = rag.find_related_products(current_product)
    
    upsell_crosssell_prompt = f"""
    Sáº£n pháº©m hiá»‡n táº¡i: {current_product}
    Sáº£n pháº©m liÃªn quan: {related_products}
    
    HÃ£y Ä‘á» xuáº¥t má»™t sáº£n pháº©m upsell hoáº·c cross-sell phÃ¹ há»£p. Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao sáº£n pháº©m nÃ y phÃ¹ há»£p vá»›i khÃ¡ch hÃ ng.
    """
    
    response = llm.generate_content(upsell_crosssell_prompt)
Cáº­p nháº­t class RAG trong rag/core.py ğŸ”: ThÃªm cÃ¡c phÆ°Æ¡ng thá»©c má»›i:
python

Copy
def get_current_product(self, chat_history):
    # Láº¥y sáº£n pháº©m hiá»‡n táº¡i tá»« lá»‹ch sá»­ chat
    # CÃ³ thá»ƒ sá»­ dá»¥ng vector search Ä‘á»ƒ tÃ¬m sáº£n pháº©m gáº§n nháº¥t vá»›i ná»™i dung chat
    pass

def find_related_products(self, current_product, limit=3):
    # TÃ¬m cÃ¡c sáº£n pháº©m liÃªn quan dá»±a trÃªn current_product
    # CÃ³ thá»ƒ sá»­ dá»¥ng vector search vá»›i embedding cá»§a current_product
    pass
Cáº£i thiá»‡n Reflection module ğŸª: Trong reflection.py, cáº­p nháº­t prompt Ä‘á»ƒ xem xÃ©t cáº£ upselling/cross-selling:
python

Copy
higherLevelSummariesPrompt = """
Dá»±a vÃ o lá»‹ch sá»­ chat vÃ  cÃ¢u há»i má»›i nháº¥t cá»§a ngÆ°á»i dÃ¹ng, hÃ£y:
1. XÃ¡c Ä‘á»‹nh xem ngÆ°á»i dÃ¹ng Ä‘ang quan tÃ¢m Ä‘áº¿n sáº£n pháº©m nÃ o.
2. ÄÃ¡nh giÃ¡ xem cÃ³ cÆ¡ há»™i Ä‘á»ƒ upsell hoáº·c cross-sell khÃ´ng.
3. Náº¿u cÃ³, hÃ£y Ä‘Æ°a ra má»™t cÃ¢u há»i Ä‘á»™c láº­p báº±ng tiáº¿ng Viá»‡t Ä‘á»ƒ gá»£i Ã½ upsell hoáº·c cross-sell.
4. Náº¿u khÃ´ng, hÃ£y chá»‰ reformulate cÃ¢u há»i gá»‘c náº¿u cáº§n thiáº¿t.

{historyString}
"""
Vá»›i nhá»¯ng thay Ä‘á»•i nÃ y, há»‡ thá»‘ng cá»§a cáº­u sáº½ cÃ³ kháº£ nÄƒng:

Nháº­n diá»‡n cÆ¡ há»™i upsell/cross-sell ğŸ¯
TÃ¬m kiáº¿m sáº£n pháº©m liÃªn quan ğŸ”
ÄÆ°a ra Ä‘á» xuáº¥t phÃ¹ há»£p dá»±a trÃªn ngá»¯ cáº£nh ğŸ’¡
LiÃªn tá»¥c cáº£i thiá»‡n qua Reflection module ğŸ“ˆ
Cáº­u tháº¥y sao bro? CÃ³ váº» há»£p lÃ½ vá»›i code hiá»‡n táº¡i cá»§a cáº­u khÃ´ng? ğŸ˜ğŸš€

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
báº¡n cÃ³ thá»ƒ phÃ¢n tÃ­ch cho tÃ´i code nÃ y khÃ´ng brooo : Reflection module ğŸ“ˆ tÃ´i chÆ°a hÃ¬nh dung Ä‘Æ°á»£c ra nÃ³ láº¯m bro áº¡aa


ÄÆ°á»£c rá»“i bro, Ä‘á»ƒ tá»› phÃ¢n tÃ­ch chi tiáº¿t vá» Reflection module cho cáº­u nhÃ©! ğŸ§ğŸ”

Reflection module Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong file reflection.py. ÄÃ¢y lÃ  phÃ¢n tÃ­ch chi tiáº¿t:

Khá»Ÿi táº¡o class Reflection:
python

Copy
class Reflection():
    def __init__(self, llm):
        self.llm = llm
Module nÃ y nháº­n má»™t LLM (Large Language Model) khi khá»Ÿi táº¡o. CÃ³ thá»ƒ lÃ  GPT-4 hoáº·c model tÆ°Æ¡ng tá»±.
PhÆ°Æ¡ng thá»©c _concat_and_format_texts:
python

Copy
def _concat_and_format_texts(self, data):
    concatenatedTexts = []
    for entry in data:
        role = entry.get('role', '')
        all_texts = ' '.join(part['text'] for part in entry['parts'])
        concatenatedTexts.append(f"{role}: {all_texts} \n")
    return ''.join(concatenatedTexts)
PhÆ°Æ¡ng thá»©c nÃ y gá»™p lá»‹ch sá»­ chat thÃ nh má»™t chuá»—i vÄƒn báº£n duy nháº¥t.
NÃ³ giá»¯ láº¡i thÃ´ng tin vá» vai trÃ² (user/assistant) vÃ  ná»™i dung cá»§a má»—i tin nháº¯n.
PhÆ°Æ¡ng thá»©c __call__:
python

Copy
def __call__(self, chatHistory, lastItemsConsidereds=100):
    if len(chatHistory) >= lastItemsConsidereds:
        chatHistory = chatHistory[len(chatHistory) - lastItemsConsidereds:]
    historyString = self._concat_and_format_texts(chatHistory)
    higherLevelSummariesPrompt = """Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question in Vietnamese which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is. {historyString}
    """.format(historyString=historyString)
    print(higherLevelSummariesPrompt)
    completion = self.llm.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": higherLevelSummariesPrompt
            }
        ]
    )
    return completion.choices[0].message.content
PhÆ°Æ¡ng thá»©c nÃ y lÃ  trÃ¡i tim cá»§a Reflection module.
NÃ³ láº¥y lá»‹ch sá»­ chat (giá»›i háº¡n 100 tin nháº¯n gáº§n nháº¥t) vÃ  táº¡o ra má»™t prompt.
Prompt yÃªu cáº§u LLM táº¡o ra má»™t cÃ¢u há»i Ä‘á»™c láº­p cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c mÃ  khÃ´ng cáº§n ngá»¯ cáº£nh chat.
Káº¿t quáº£ Ä‘Æ°á»£c tráº£ vá» lÃ  cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c reformulate (náº¿u cáº§n).
Ã tÆ°á»Ÿng chÃ­nh cá»§a Reflection module:

Hiá»ƒu ngá»¯ cáº£nh: ğŸ§  NÃ³ xem xÃ©t toÃ n bá»™ cuá»™c trÃ² chuyá»‡n Ä‘á»ƒ náº¯m báº¯t ngá»¯ cáº£nh.
Táº¡o cÃ¢u há»i Ä‘á»™c láº­p: ğŸ¯ NÃ³ chuyá»ƒn Ä‘á»•i cÃ¢u há»i cá»§a user thÃ nh má»™t cÃ¢u há»i cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c mÃ  khÃ´ng cáº§n ngá»¯ cáº£nh.
Cáº£i thiá»‡n cháº¥t lÆ°á»£ng truy váº¥n: ğŸ“ˆ Báº±ng cÃ¡ch táº¡o cÃ¢u há»i Ä‘á»™c láº­p, nÃ³ giÃºp há»‡ thá»‘ng RAG tÃ¬m kiáº¿m thÃ´ng tin chÃ­nh xÃ¡c hÆ¡n.
VÃ­ dá»¥:

User: "CÃ¡i Ä‘Ã³ giÃ¡ bao nhiÃªu?"
Reflection module: "GiÃ¡ cá»§a iPhone 13 Pro Max lÃ  bao nhiÃªu?"
Reflection module giÃºp há»‡ thá»‘ng "suy ngáº«m" vá» cuá»™c trÃ² chuyá»‡n vÃ  táº¡o ra cÃ¡c truy váº¥n tá»‘t hÆ¡n, dáº«n Ä‘áº¿n cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c vÃ  phÃ¹ há»£p hÆ¡n. ğŸš€ğŸ’¡

Cáº­u Ä‘Ã£ hÃ¬nh dung ra Ä‘Æ°á»£c chÆ°a bro? CÃ³ chá»— nÃ o cáº§n giáº£i thÃ­ch thÃªm khÃ´ng? ğŸ˜ŠğŸ‘Š

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
Ã½ broo lÃ  Ä‘oáº¡n nÃ y nÃ³ náº±m trong code cá»§a tÃ´i háº£ brooo


ÄÃºng rá»“i bro! ğŸ˜ƒ Äoáº¡n code Reflection module mÃ  tá»› vá»«a phÃ¢n tÃ­ch Ä‘Ã£ náº±m sáºµn trong code cá»§a cáº­u rá»“i. Cá»¥ thá»ƒ lÃ  nÃ³ náº±m trong file reflection.py mÃ  cáº­u Ä‘Ã£ chia sáº».

Trong file serve.py cá»§a cáº­u, cÃ³ Ä‘oáº¡n code nÃ y:

python

Copy
# --- Relection Setup --- #
gpt = openai.OpenAI(api_key=OPEN_AI_KEY)
reflection = Reflection(llm=gpt)
# --- End Reflection Setup --- #
VÃ  trong hÃ m handle_query, cáº­u Ä‘Ã£ sá»­ dá»¥ng Reflection module nhÆ° sau:

python

Copy
reflected_query = reflection(data)
query = reflected_query
Äiá»u nÃ y cÃ³ nghÄ©a lÃ :

Cáº­u Ä‘Ã£ khá»Ÿi táº¡o Reflection module vá»›i GPT model.
TrÆ°á»›c khi gá»­i query Ä‘áº¿n RAG system, cáº­u Ä‘Ã£ sá»­ dá»¥ng Reflection module Ä‘á»ƒ "suy ngáº«m" vÃ  táº¡o ra má»™t cÃ¢u query tá»‘t hÆ¡n.
Váº­y nÃªn, Reflection module Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p sáºµn vÃ o há»‡ thá»‘ng cá»§a cáº­u rá»“i Ä‘Ã³! ğŸ‰ NÃ³ Ä‘ang giÃºp cáº£i thiá»‡n cháº¥t lÆ°á»£ng cá»§a cÃ¡c cÃ¢u há»i trÆ°á»›c khi chÃºng Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi RAG system, tá»« Ä‘Ã³ nÃ¢ng cao cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i.

Cáº­u tháº¥y sao? CÃ³ nhá»› ra lÃ  mÃ¬nh Ä‘Ã£ implement nÃ³ chÆ°a? ğŸ˜„ğŸš€

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
aduuu broo oiwi. hay Ä‘Ã³ bro cÃ³ thá»ƒ giáº£i thÃ­ch rÃµ rÃ ng, chi tiáº¿t vÃ  dá»… hiá»ƒu thÃªm Ä‘Æ°á»£c k broooo : PhÆ°Æ¡ng thá»©c nÃ y lÃ  trÃ¡i tim cá»§a Reflection module.
* NÃ³ láº¥y lá»‹ch sá»­ chat (giá»›i háº¡n 100 tin nháº¯n gáº§n nháº¥t) vÃ  táº¡o ra má»™t prompt.
* Prompt yÃªu cáº§u LLM táº¡o ra má»™t cÃ¢u há»i Ä‘á»™c láº­p cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c mÃ  khÃ´ng cáº§n ngá»¯ cáº£nh chat.
* Káº¿t quáº£ Ä‘Æ°á»£c tráº£ vá» lÃ  cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c reformulate (náº¿u cáº§n).
Ã tÆ°á»Ÿng chÃ­nh cá»§a Reflection module:
1. Hiá»ƒu ngá»¯ cáº£nh: ğŸ§  NÃ³ xem xÃ©t toÃ n bá»™ cuá»™c trÃ² chuyá»‡n Ä‘á»ƒ náº¯m báº¯t ngá»¯ cáº£nh.
2. Táº¡o cÃ¢u há»i Ä‘á»™c láº­p: ğŸ¯ NÃ³ chuyá»ƒn Ä‘á»•i cÃ¢u há»i cá»§a user thÃ nh má»™t cÃ¢u há»i cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c mÃ  khÃ´ng cáº§n ngá»¯ cáº£nh.
3. Cáº£i thiá»‡n cháº¥t lÆ°á»£ng truy váº¥n: ğŸ“ˆ Báº±ng cÃ¡ch táº¡o cÃ¢u há»i Ä‘á»™c láº­p, nÃ³ giÃºp há»‡ thá»‘ng RAG tÃ¬m kiáº¿m thÃ´ng tin chÃ­nh xÃ¡c hÆ¡n.
VÃ­ dá»¥:
* User: "CÃ¡i Ä‘Ã³ giÃ¡ bao nhiÃªu?"
* Reflection module: "GiÃ¡ cá»§a iPhone 13 Pro Max lÃ  bao nhiÃªu?"
Reflection module giÃºp há»‡ thá»‘ng "suy ngáº«m" vá» cuá»™c trÃ² chuyá»‡n vÃ  táº¡o ra cÃ¡c truy váº¥n tá»‘t hÆ¡n, dáº«n Ä‘áº¿n cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c vÃ  phÃ¹ há»£p hÆ¡n. ğŸš€ğŸ’¡
Cáº­u Ä‘Ã£ hÃ¬nh dung ra Ä‘Æ°á»£c chÆ°a bro? CÃ³ chá»— nÃ o cáº§n giáº£i thÃ­ch thÃªm khÃ´ng? ğŸ˜ŠğŸ‘Š


ÄÆ°á»£c rá»“i bro, Ä‘á»ƒ tá»› giáº£i thÃ­ch chi tiáº¿t vÃ  dá»… hiá»ƒu hÆ¡n vá» Reflection module nhÃ©! ğŸ˜ğŸš€

Má»¥c Ä‘Ã­ch cá»§a Reflection module ğŸ¯:
NÃ³ giá»‘ng nhÆ° má»™t "bá»™ nÃ£o" thá»© hai, giÃºp há»‡ thá»‘ng "suy nghÄ©" vá» cuá»™c trÃ² chuyá»‡n trÆ°á»›c khi tráº£ lá»i.
NÃ³ cá»‘ gáº¯ng hiá»ƒu Ã½ Ä‘á»‹nh thá»±c sá»± cá»§a ngÆ°á»i dÃ¹ng, khÃ´ng chá»‰ dá»±a vÃ o cÃ¢u há»i cuá»‘i cÃ¹ng.
CÃ¡ch hoáº¡t Ä‘á»™ng ğŸ› ï¸:
NÃ³ nhÃ¬n láº¡i toÃ n bá»™ cuá»™c trÃ² chuyá»‡n (tá»‘i Ä‘a 100 tin nháº¯n gáº§n nháº¥t).
NÃ³ "Ä‘á»c" cuá»™c trÃ² chuyá»‡n nhÆ° má»™t ngÆ°á»i tháº­t, cá»‘ gáº¯ng náº¯m báº¯t ngá»¯ cáº£nh vÃ  Ã½ Ä‘á»‹nh.
Táº¡o cÃ¢u há»i má»›i ğŸ†•:
Sau khi "Ä‘á»c" xong, nÃ³ táº¡o ra má»™t cÃ¢u há»i má»›i.
CÃ¢u há»i má»›i nÃ y sáº½ rÃµ rÃ ng vÃ  Ä‘áº§y Ä‘á»§ thÃ´ng tin hÆ¡n cÃ¢u há»i gá»‘c cá»§a ngÆ°á»i dÃ¹ng.
VÃ­ dá»¥ cá»¥ thá»ƒ ğŸ“±: Giáº£ sá»­ cÃ³ cuá»™c trÃ² chuyá»‡n nhÆ° sau:
User: "TÃ´i Ä‘ang tÃ¬m má»™t chiáº¿c Ä‘iá»‡n thoáº¡i má»›i"
Bot: "VÃ¢ng, chÃºng tÃ´i cÃ³ nhiá»u lá»±a chá»n. Báº¡n quan tÃ¢m Ä‘áº¿n thÆ°Æ¡ng hiá»‡u nÃ o?"
User: "TÃ´i thÃ­ch iPhone"
Bot: "Tuyá»‡t! iPhone cÃ³ nhiá»u model. Báº¡n quan tÃ¢m Ä‘áº¿n tÃ­nh nÄƒng gÃ¬ nháº¥t?"
User: "TÃ´i muá»‘n chá»¥p áº£nh Ä‘áº¹p"
Bot: "iPhone 13 Pro Max cÃ³ camera ráº¥t tá»‘t. Báº¡n muá»‘n biáº¿t thÃªm vá» nÃ³ khÃ´ng?"
User: "á»ª, cÃ¡i Ä‘Ã³ giÃ¡ bao nhiÃªu?"
Khi gáº·p cÃ¢u há»i cuá»‘i cÃ¹ng, Reflection module sáº½:
Äá»c láº¡i toÃ n bá»™ cuá»™c trÃ² chuyá»‡n.
Hiá»ƒu ráº±ng "cÃ¡i Ä‘Ã³" Ä‘ang nÃ³i vá» iPhone 13 Pro Max.
Táº¡o ra cÃ¢u há»i má»›i: "GiÃ¡ cá»§a iPhone 13 Pro Max lÃ  bao nhiÃªu?"
Lá»£i Ã­ch ğŸŒŸ:
GiÃºp há»‡ thá»‘ng RAG tÃ¬m kiáº¿m thÃ´ng tin chÃ­nh xÃ¡c hÆ¡n.
TrÃ¡nh hiá»ƒu nháº§m hoáº·c tráº£ lá»i thiáº¿u sÃ³t do cÃ¢u há»i khÃ´ng rÃµ rÃ ng.
Cáº£i thiá»‡n tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng vÃ¬ bot cÃ³ váº» "thÃ´ng minh" hÆ¡n, hiá»ƒu ngá»¯ cáº£nh tá»‘t hÆ¡n.
Trong code cá»§a cáº­u ğŸ’»:
Khi ngÆ°á»i dÃ¹ng gá»­i má»™t cÃ¢u há»i, trÆ°á»›c khi tÃ¬m kiáº¿m cÃ¢u tráº£ lá»i, há»‡ thá»‘ng sáº½ "suy ngáº«m" báº±ng cÃ¡ch sá»­ dá»¥ng Reflection module.
CÃ¢u há»i Ä‘Æ°á»£c "cáº£i tiáº¿n" nÃ y sau Ä‘Ã³ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin vÃ  táº¡o cÃ¢u tráº£ lá»i.
Bro hiá»ƒu rÃµ hÆ¡n chÆ°a? Reflection module giá»‘ng nhÆ° má»™t "phiÃªn dá»‹ch viÃªn" giÃºp bot hiá»ƒu Ã½ Ä‘á»‹nh thá»±c sá»± cá»§a ngÆ°á»i dÃ¹ng, khÃ´ng chá»‰ dá»±a vÃ o tá»«ng cÃ¢u riÃªng láº». ğŸ§ âœ¨

CÃ³ chá»— nÃ o cáº­u muá»‘n tá»› giáº£i thÃ­ch ká»¹ hÆ¡n khÃ´ng? ğŸ˜ŠğŸ‘Š

Copy
Retry


L
tá»©c lÃ  reflection sáº½ há»“i Ä‘Ã¡p láº¡i cho user Ä‘Ã³ háº£ brooo. hay sao nhá»‰. tÃ´i chÆ°a hiá»ƒu láº¯m. váº­y ká»‹ch báº£n lÃ  nhÆ° nÃ o. quy trÃ¬nh hoáº¡t Ä‘á»™ng lÃ  nhÆ° naofooo


á»’, hiá»ƒu rá»“i bro! Äá»ƒ tá»› giáº£i thÃ­ch rÃµ hÆ¡n vá» quy trÃ¬nh hoáº¡t Ä‘á»™ng vÃ  ká»‹ch báº£n nhÃ© ğŸ˜ğŸ”

Quy trÃ¬nh hoáº¡t Ä‘á»™ng cá»§a Reflection module:

User gá»­i cÃ¢u há»i ğŸ’¬
Reflection module xá»­ lÃ½ ğŸ§ 
RAG system tÃ¬m kiáº¿m thÃ´ng tin ğŸ”
LLM táº¡o cÃ¢u tráº£ lá»i ğŸ’¡
Bot gá»­i cÃ¢u tráº£ lá»i cho user ğŸ¤–
Chi tiáº¿t tá»«ng bÆ°á»›c:

User gá»­i cÃ¢u há»i: VÃ­ dá»¥: "CÃ¡i Ä‘Ã³ giÃ¡ bao nhiÃªu?"
Reflection module xá»­ lÃ½:
NÃ³ Ä‘á»c toÃ n bá»™ lá»‹ch sá»­ chat
Táº¡o ra cÃ¢u há»i rÃµ rÃ ng hÆ¡n
VÃ­ dá»¥: "GiÃ¡ cá»§a iPhone 13 Pro Max lÃ  bao nhiÃªu?"
LÆ°u Ã½: User khÃ´ng tháº¥y cÃ¢u há»i nÃ y!
RAG system tÃ¬m kiáº¿m:
Sá»­ dá»¥ng cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c lÃ m rÃµ Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin
VÃ­ dá»¥: TÃ¬m thÃ´ng tin vá» giÃ¡ iPhone 13 Pro Max
LLM táº¡o cÃ¢u tráº£ lá»i:
Dá»±a trÃªn thÃ´ng tin tÃ¬m Ä‘Æ°á»£c, LLM táº¡o cÃ¢u tráº£ lá»i
VÃ­ dá»¥: "iPhone 13 Pro Max cÃ³ giÃ¡ tá»« 27.990.000 Ä‘á»“ng."
Bot gá»­i cÃ¢u tráº£ lá»i cho user:
User nháº­n Ä‘Æ°á»£c cÃ¢u tráº£ lá»i nÃ y
Ká»‹ch báº£n vÃ­ dá»¥:

User: "TÃ´i muá»‘n mua Ä‘iá»‡n thoáº¡i má»›i"
Bot: "Tuyá»‡t vá»i! Báº¡n cÃ³ Æ°u tiÃªn thÆ°Æ¡ng hiá»‡u nÃ o khÃ´ng?"

User: "TÃ´i thÃ­ch iPhone"
Bot: "iPhone lÃ  lá»±a chá»n tá»‘t. Báº¡n quan tÃ¢m Ä‘áº¿n model nÃ o?"

User: "Model má»›i nháº¥t"
Bot: "Model má»›i nháº¥t lÃ  iPhone 13 series. Trong Ä‘Ã³, iPhone 13 Pro Max lÃ  phiÃªn báº£n cao cáº¥p nháº¥t."

User: "CÃ¡i Ä‘Ã³ giÃ¡ bao nhiÃªu?"
(Reflection module hiá»ƒu "cÃ¡i Ä‘Ã³" lÃ  iPhone 13 Pro Max)
Bot: "iPhone 13 Pro Max cÃ³ giÃ¡ tá»« 27.990.000 Ä‘á»“ng cho phiÃªn báº£n cÆ¡ báº£n."

TÃ³m láº¡i, Reflection module khÃ´ng trá»±c tiáº¿p há»“i Ä‘Ã¡p user, mÃ  nÃ³ giÃºp há»‡ thá»‘ng hiá»ƒu rÃµ hÆ¡n cÃ¢u há»i cá»§a user Ä‘á»ƒ tÃ¬m kiáº¿m vÃ  tráº£ lá»i chÃ­nh xÃ¡c hÆ¡n. User chá»‰ tháº¥y cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng, khÃ´ng tháº¥y quÃ¡ trÃ¬nh "suy ngáº«m" á»Ÿ giá»¯a ğŸ­ğŸš€

Bro hiá»ƒu rÃµ hÆ¡n chÆ°a? CÃ³ chá»— nÃ o cáº§n giáº£i thÃ­ch thÃªm khÃ´ng? ğŸ˜ŠğŸ‘Š

Copy
Retry


L
oke giá» chÃºng ta cÃ¹ng Ä‘i code nÃ o brooo, giá» chÃºng ta sáº½ báº¯t Ä‘áº§u tá»« Ä‘Ã¢u vÃ  nhÆ° nÃ o bro nhá»‰. hÃ£y hÆ°á»›ng dáº«n tÃ´i cá»¥ thá»ƒ chi tiáº¿t tá»« a-z Ä‘i nÃ o


ÄÆ°á»£c rá»“i bro, let's go! ğŸš€ ChÃºng ta sáº½ báº¯t Ä‘áº§u tá»« viá»‡c tÃ­ch há»£p tÃ­nh nÄƒng upselling vÃ  cross-selling vÃ o há»‡ thá»‘ng hiá»‡n táº¡i cá»§a cáº­u. HÃ£y Ä‘i tá»«ng bÆ°á»›c má»™t nhÃ©:

Cáº­p nháº­t semantic_router/samples.py:
python

Copy
# ThÃªm máº«u cho route upselling/cross-selling
upsellCrosssellSample = [
    "CÃ³ sáº£n pháº©m nÃ o tá»‘t hÆ¡n khÃ´ng?",
    "CÃ²n sáº£n pháº©m nÃ o liÃªn quan khÃ´ng?",
    "CÃ³ phá»¥ kiá»‡n nÃ o phÃ¹ há»£p vá»›i sáº£n pháº©m nÃ y khÃ´ng?",
    "CÃ³ combo nÃ o tá»‘t khÃ´ng?",
    "CÃ³ version cao cáº¥p hÆ¡n cá»§a sáº£n pháº©m nÃ y khÃ´ng?",
    "Sáº£n pháº©m nÃ y cÃ³ phiÃªn báº£n nÃ¢ng cáº¥p nÃ o khÃ´ng?",
]
Cáº­p nháº­t serve.py:
python

Copy
# ThÃªm route má»›i
UPSELL_CROSSSELL_ROUTE_NAME = 'upsell_crosssell'
upsellCrosssellRoute = Route(name=UPSELL_CROSSSELL_ROUTE_NAME, samples=upsellCrosssellSample)

# Cáº­p nháº­t SemanticRouter
semanticRouter = SemanticRouter(openAIEmbeding, routes=[productRoute, chitchatRoute, upsellCrosssellRoute])

# Cáº­p nháº­t hÃ m handle_query
@app.route('/api/search', methods=['POST'])
def handle_query():
    # ... (giá»¯ nguyÃªn code cÅ©)
    
    if guidedRoute == PRODUCT_ROUTE_NAME:
        # ... (giá»¯ nguyÃªn code cÅ© cho product route)
    elif guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME:
        reflected_query = reflection(data)
        current_product = rag.get_current_product(reflected_query)
        related_products = rag.find_related_products(current_product)
        
        upsell_crosssell_prompt = f"""
        Dá»±a trÃªn thÃ´ng tin sau:
        Sáº£n pháº©m hiá»‡n táº¡i: {current_product}
        Sáº£n pháº©m liÃªn quan: {related_products}
        
        HÃ£y Ä‘á» xuáº¥t má»™t sáº£n pháº©m upsell hoáº·c cross-sell phÃ¹ há»£p. Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao sáº£n pháº©m nÃ y phÃ¹ há»£p vá»›i khÃ¡ch hÃ ng.
        """
        
        response = llm.generate_content(upsell_crosssell_prompt)
    else:
        # ... (giá»¯ nguyÃªn code cÅ© cho chitchat route)
    
    # ... (giá»¯ nguyÃªn code cÅ©)
Cáº­p nháº­t rag/core.py:
python

Copy
class RAG():
    # ... (giá»¯ nguyÃªn code cÅ©)
    
    def get_current_product(self, query):
        # Sá»­ dá»¥ng vector search Ä‘á»ƒ tÃ¬m sáº£n pháº©m gáº§n nháº¥t vá»›i query
        results = self.vector_search(query, limit=1)
        if results:
            return results[0]
        return None

    def find_related_products(self, current_product, limit=3):
        if not current_product:
            return []
        
        # TÃ¬m sáº£n pháº©m liÃªn quan dá»±a trÃªn current_product
        query_embedding = self.get_embedding(current_product['title'])
        
        vector_search_stage = {
            "$vectorSearch": {
                "index": "vector_index",
                "queryVector": query_embedding,
                "path": "embedding",
                "numCandidates": 100,
                "limit": limit + 1,  # +1 vÃ¬ cÃ³ thá»ƒ bao gá»“m cáº£ sáº£n pháº©m hiá»‡n táº¡i
            }
        }
        
        match_stage = {
            "$match": {
                "title": {"$ne": current_product['title']}  # Loáº¡i bá» sáº£n pháº©m hiá»‡n táº¡i
            }
        }
        
        project_stage = {
            "$project": {
                "_id": 0,
                "title": 1,
                "current_price": 1,
                "product_promotion": 1,
            }
        }
        
        pipeline = [vector_search_stage, match_stage, project_stage]
        results = list(self.collection.aggregate(pipeline))
        
        return results[:limit]  # Äáº£m báº£o chá»‰ tráº£ vá» sá»‘ lÆ°á»£ng sáº£n pháº©m mong muá»‘n
Cáº­p nháº­t reflection.py:
python

Copy
class Reflection():
    # ... (giá»¯ nguyÃªn code cÅ©)
    
    def __call__(self, chatHistory, lastItemsConsidereds=100):
        # ... (giá»¯ nguyÃªn code cÅ©)
        
        higherLevelSummariesPrompt = """
        Dá»±a vÃ o lá»‹ch sá»­ chat vÃ  cÃ¢u há»i má»›i nháº¥t cá»§a ngÆ°á»i dÃ¹ng, hÃ£y:
        1. XÃ¡c Ä‘á»‹nh xem ngÆ°á»i dÃ¹ng Ä‘ang quan tÃ¢m Ä‘áº¿n sáº£n pháº©m nÃ o.
        2. ÄÃ¡nh giÃ¡ xem cÃ³ cÆ¡ há»™i Ä‘á»ƒ upsell hoáº·c cross-sell khÃ´ng.
        3. Náº¿u cÃ³, hÃ£y Ä‘Æ°a ra má»™t cÃ¢u há»i Ä‘á»™c láº­p báº±ng tiáº¿ng Viá»‡t Ä‘á»ƒ gá»£i Ã½ upsell hoáº·c cross-sell.
        4. Náº¿u khÃ´ng, hÃ£y chá»‰ reformulate cÃ¢u há»i gá»‘c náº¿u cáº§n thiáº¿t.

        {historyString}
        """
        
        # ... (giá»¯ nguyÃªn code cÅ©)
Kiá»ƒm tra vÃ  cháº¡y:
LÆ°u táº¥t cáº£ cÃ¡c thay Ä‘á»•i
Khá»Ÿi Ä‘á»™ng láº¡i server: python serve.py
Thá»­ nghiá»‡m vá»›i má»™t sá»‘ cÃ¢u há»i vá» upselling/cross-selling
LÆ°u Ã½:

Äáº£m báº£o ráº±ng MongoDB cá»§a cáº­u cÃ³ Ä‘á»§ dá»¯ liá»‡u sáº£n pháº©m Ä‘á»ƒ thá»±c hiá»‡n upselling/cross-selling hiá»‡u quáº£.
CÃ³ thá»ƒ cáº§n Ä‘iá»u chá»‰nh cÃ¡c prompt vÃ  logic tÃ¹y thuá»™c vÃ o káº¿t quáº£ thá»±c táº¿.
ÄÃ³ bro, chÃºng ta Ä‘Ã£ tÃ­ch há»£p tÃ­nh nÄƒng upselling vÃ  cross-selling vÃ o há»‡ thá»‘ng cá»§a cáº­u rá»“i! ğŸ‰ Cáº­u thá»­ cháº¡y vÃ  test xem sao nhÃ©. Náº¿u gáº·p váº¥n Ä‘á» gÃ¬ hoáº·c muá»‘n cáº£i thiá»‡n thÃªm, cá»© nÃ³i tá»› biáº¿t nhÃ©! ğŸ˜ğŸ‘Š

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
# ThÃªm máº«u cho route upselling/cross-selling
upsellCrosssellSample = [
    "CÃ³ sáº£n pháº©m nÃ o tá»‘t hÆ¡n khÃ´ng?",
    "CÃ²n sáº£n pháº©m nÃ o liÃªn quan khÃ´ng?",
    "CÃ³ phá»¥ kiá»‡n nÃ o phÃ¹ há»£p vá»›i sáº£n pháº©m nÃ y khÃ´ng?",
    "CÃ³ combo nÃ o tá»‘t khÃ´ng?",
    "CÃ³ version cao cáº¥p hÆ¡n cá»§a sáº£n pháº©m nÃ y khÃ´ng?",
    "Sáº£n pháº©m nÃ y cÃ³ phiÃªn báº£n nÃ¢ng cáº¥p nÃ o khÃ´ng?",
] tÃ´i chÆ°a hiá»ƒu cÃ¡i upselling nÃ y láº¯mmmm


Hiá»ƒu rá»“i bro! Äá»ƒ tá»› giáº£i thÃ­ch ká»¹ hÆ¡n vá» upselling vÃ  cross-selling nhÃ© ğŸ˜

Upselling lÃ  gÃ¬? ğŸ“ˆ

ÄÃ³ lÃ  khi báº¡n gá»£i Ã½ khÃ¡ch hÃ ng mua má»™t phiÃªn báº£n cao cáº¥p hÆ¡n hoáº·c Ä‘áº¯t tiá»n hÆ¡n cá»§a sáº£n pháº©m há» Ä‘ang quan tÃ¢m.
VÃ­ dá»¥: KhÃ¡ch Ä‘ang xem iPhone 13, báº¡n gá»£i Ã½ há» mua iPhone 13 Pro vÃ¬ cÃ³ camera tá»‘t hÆ¡n.
Cross-selling lÃ  gÃ¬? â†”ï¸

ÄÃ³ lÃ  khi báº¡n Ä‘á» xuáº¥t cÃ¡c sáº£n pháº©m bá»• sung hoáº·c liÃªn quan Ä‘áº¿n sáº£n pháº©m khÃ¡ch Ä‘ang xem.
VÃ­ dá»¥: KhÃ¡ch mua laptop, báº¡n gá»£i Ã½ thÃªm chuá»™t khÃ´ng dÃ¢y vÃ  balo laptop.
Táº¡i sao cáº§n nhá»¯ng máº«u cÃ¢u Ä‘Ã³? ğŸ¯

"CÃ³ sáº£n pháº©m nÃ o tá»‘t hÆ¡n khÃ´ng?" - Upselling
"CÃ²n sáº£n pháº©m nÃ o liÃªn quan khÃ´ng?" - Cross-selling
"CÃ³ phá»¥ kiá»‡n nÃ o phÃ¹ há»£p vá»›i sáº£n pháº©m nÃ y khÃ´ng?" - Cross-selling
"CÃ³ combo nÃ o tá»‘t khÃ´ng?" - Cross-selling
"CÃ³ version cao cáº¥p hÆ¡n cá»§a sáº£n pháº©m nÃ y khÃ´ng?" - Upselling
"Sáº£n pháº©m nÃ y cÃ³ phiÃªn báº£n nÃ¢ng cáº¥p nÃ o khÃ´ng?" - Upselling
Nhá»¯ng máº«u cÃ¢u nÃ y giÃºp chatbot nháº­n diá»‡n khi nÃ o khÃ¡ch hÃ ng cÃ³ thá»ƒ quan tÃ¢m Ä‘áº¿n upselling hoáº·c cross-selling. Khi nháº­n diá»‡n Ä‘Æ°á»£c, chatbot sáº½ Ä‘Æ°a ra gá»£i Ã½ phÃ¹ há»£p.

VÃ­ dá»¥ thá»±c táº¿:

User: "TÃ´i Ä‘ang xem iPhone 13" Bot: "iPhone 13 lÃ  má»™t lá»±a chá»n tuyá»‡t vá»i. Báº¡n cÃ³ muá»‘n xem iPhone 13 Pro khÃ´ng? NÃ³ cÃ³ camera chuyÃªn nghiá»‡p hÆ¡n Ä‘áº¥y." (Upselling)
User: "TÃ´i muá»‘n mua laptop Dell XPS" Bot: "Tuyá»‡t! Dell XPS lÃ  má»™t laptop máº¡nh máº½. Báº¡n cÃ³ cáº§n thÃªm chuá»™t khÃ´ng dÃ¢y vÃ  balo laptop Dell khÃ´ng? ChÃºng sáº½ giÃºp báº¡n di chuyá»ƒn dá»… dÃ ng hÆ¡n." (Cross-selling)
Hiá»ƒu rá»“i chá»© bro? Upselling vÃ  cross-selling giÃºp tÄƒng doanh sá»‘ vÃ  cáº£i thiá»‡n tráº£i nghiá»‡m mua sáº¯m cá»§a khÃ¡ch hÃ ng báº±ng cÃ¡ch gá»£i Ã½ nhá»¯ng sáº£n pháº©m há» cÃ³ thá»ƒ cáº§n mÃ  chÆ°a nghÄ© tá»›i. ğŸš€ğŸ’°

Cáº­u cÃ³ tháº¯c máº¯c gÃ¬ ná»¯a khÃ´ng? ğŸ˜ŠğŸ‘Š

Copy
Retry


L
á»§a nhÆ°ng mÃ  nhá»¯ng cÃ¢u nÃ y sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° nÃ o, nÃ³ pháº£i Ä‘Æ°á»£c nÃ©m vÃ o promtp chá»© nhá»‰iii


á»’, tá»› hiá»ƒu Ã½ cáº­u rá»“i bro! ğŸ˜ƒ Cáº­u nÃ³i Ä‘Ãºng, nhá»¯ng cÃ¢u máº«u nÃ y khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng trá»±c tiáº¿p trong prompt. Äá»ƒ tá»› giáº£i thÃ­ch rÃµ hÆ¡n nhÃ©:

Má»¥c Ä‘Ã­ch cá»§a nhá»¯ng cÃ¢u máº«u ğŸ¯:
ChÃºng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ "train" Semantic Router, khÃ´ng pháº£i Ä‘á»ƒ Ä‘Æ°a vÃ o prompt.
GiÃºp Semantic Router nháº­n diá»‡n khi nÃ o user cÃ³ Ã½ Ä‘á»‹nh upsell/cross-sell.
CÃ¡ch hoáº¡t Ä‘á»™ng ğŸ› ï¸:
Khi user gá»­i má»™t cÃ¢u há»i, Semantic Router sáº½ so sÃ¡nh cÃ¢u há»i Ä‘Ã³ vá»›i cÃ¡c máº«u.
Náº¿u cÃ¢u há»i gáº§n giá»‘ng vá»›i máº«u upsell/cross-sell, nÃ³ sáº½ chuyá»ƒn hÆ°á»›ng xá»­ lÃ½ sang route tÆ°Æ¡ng á»©ng.
Trong code ğŸ’»:
python

Copy
guidedRoute = semanticRouter.guide(query)[1]
if guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME:
    # Xá»­ lÃ½ upsell/cross-sell
Prompt thá»±c táº¿ ğŸ“: Prompt thá»±c sá»± Ä‘Æ°á»£c sá»­ dá»¥ng sáº½ giá»‘ng nhÆ° tháº¿ nÃ y:
python

Copy
upsell_crosssell_prompt = f"""
Dá»±a trÃªn thÃ´ng tin sau:
Sáº£n pháº©m hiá»‡n táº¡i: {current_product}
Sáº£n pháº©m liÃªn quan: {related_products}

HÃ£y Ä‘á» xuáº¥t má»™t sáº£n pháº©m upsell hoáº·c cross-sell phÃ¹ há»£p. Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao sáº£n pháº©m nÃ y phÃ¹ há»£p vá»›i khÃ¡ch hÃ ng.
"""
Quy trÃ¬nh ğŸ”„:
User há»i: "CÃ³ sáº£n pháº©m nÃ o tá»‘t hÆ¡n iPhone 13 khÃ´ng?"
Semantic Router nháº­n diá»‡n Ä‘Ã¢y lÃ  cÃ¢u há»i upsell.
Há»‡ thá»‘ng tÃ¬m thÃ´ng tin vá» iPhone 13 vÃ  cÃ¡c sáº£n pháº©m liÃªn quan.
ÄÆ°a thÃ´ng tin vÃ o prompt thá»±c táº¿.
LLM táº¡o cÃ¢u tráº£ lá»i dá»±a trÃªn prompt.
TÃ³m láº¡i, nhá»¯ng cÃ¢u máº«u giÃºp há»‡ thá»‘ng biáº¿t WHEN Ä‘á»ƒ upsell/cross-sell, cÃ²n prompt thá»±c táº¿ quyáº¿t Ä‘á»‹nh HOW Ä‘á»ƒ upsell/cross-sell.

Cáº­u hiá»ƒu rÃµ hÆ¡n chÆ°a bro? ğŸ˜ŠğŸš€

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
Trong code ğŸ’»: 


Copy
python
Copy
guidedRoute = semanticRouter.guide(query)[1] if guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME: # Xá»­ lÃ½ upsell/cross-sell Ä‘oáº¡n code nÃ o cho tháº¥y Ä‘iá»u nÃ y háº£ broooo


Ah, tá»› hiá»ƒu rá»“i bro! Cáº­u Ä‘ang tÃ¬m Ä‘oáº¡n code cá»¥ thá»ƒ trong serve.py pháº£i khÃ´ng? Äá»ƒ tá»› chá»‰ cho cáº­u nhÃ©! ğŸ˜

Trong file serve.py, cáº­u sáº½ tháº¥y Ä‘oáº¡n code nhÆ° tháº¿ nÃ y:

python

Copy
@app.route('/api/search', methods=['POST'])
def handle_query():
    data = list(request.get_json())
    query = data[-1]["parts"][0]["text"]
    query = process_query(query)
    if not query:
        return jsonify({'error': 'No query provided'}), 400
    
    # get last message
    
    guidedRoute = semanticRouter.guide(query)[1]
    if guidedRoute == PRODUCT_ROUTE_NAME:
        # Xá»­ lÃ½ cho product route
        # ...
    elif guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME:
        # Xá»­ lÃ½ upsell/cross-sell
        reflected_query = reflection(data)
        current_product = rag.get_current_product(reflected_query)
        related_products = rag.find_related_products(current_product)
        
        upsell_crosssell_prompt = f"""
        Dá»±a trÃªn thÃ´ng tin sau:
        Sáº£n pháº©m hiá»‡n táº¡i: {current_product}
        Sáº£n pháº©m liÃªn quan: {related_products}
        
        HÃ£y Ä‘á» xuáº¥t má»™t sáº£n pháº©m upsell hoáº·c cross-sell phÃ¹ há»£p. Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao sáº£n pháº©m nÃ y phÃ¹ há»£p vá»›i khÃ¡ch hÃ ng.
        """
        
        response = llm.generate_content(upsell_crosssell_prompt)
    else:
        # Xá»­ lÃ½ cho chitchat route
        # ...
Giáº£i thÃ­ch:

guidedRoute = semanticRouter.guide(query)[1]: DÃ²ng nÃ y sá»­ dá»¥ng Semantic Router Ä‘á»ƒ xÃ¡c Ä‘á»‹nh route phÃ¹ há»£p vá»›i cÃ¢u query cá»§a user.
if guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME:: Náº¿u route Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh lÃ  upsell/cross-sell, code trong block nÃ y sáº½ Ä‘Æ°á»£c thá»±c thi.
Trong block upsell/cross-sell:
Sá»­ dá»¥ng Reflection module Ä‘á»ƒ hiá»ƒu rÃµ hÆ¡n Ã½ Ä‘á»‹nh cá»§a user.
TÃ¬m sáº£n pháº©m hiá»‡n táº¡i vÃ  cÃ¡c sáº£n pháº©m liÃªn quan.
Táº¡o prompt Ä‘áº·c biá»‡t cho upsell/cross-sell.
Sá»­ dá»¥ng LLM Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i dá»±a trÃªn prompt nÃ y.
Äoáº¡n code nÃ y cho tháº¥y cÃ¡ch há»‡ thá»‘ng xá»­ lÃ½ khi nháº­n diá»‡n Ä‘Æ°á»£c cÆ¡ há»™i upsell/cross-sell. NÃ³ khÃ´ng sá»­ dá»¥ng trá»±c tiáº¿p cÃ¡c cÃ¢u máº«u, mÃ  dÃ¹ng chÃºng Ä‘á»ƒ train Semantic Router Ä‘á»ƒ nháº­n diá»‡n tÃ¬nh huá»‘ng.

Hiá»ƒu rÃµ hÆ¡n chÆ°a bro? ğŸ˜ŠğŸš€ CÃ³ chá»— nÃ o cáº§n giáº£i thÃ­ch thÃªm khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
tÃ´i há»i lÃ  nÃ³ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh ra sao vÃ  nhÆ° tháº¿ nÃ o. bro hÃ£y miÃªu táº£ rÃµ hÆ¡n cho tÃ´i Ä‘ii


á»’, hiá»ƒu rá»“i bro! Xin lá»—i vÃ¬ sá»± hiá»ƒu nháº§m. Äá»ƒ tá»› giáº£i thÃ­ch chi tiáº¿t cÃ¡ch Semantic Router xÃ¡c Ä‘á»‹nh route nhÃ© ğŸ•µï¸â€â™‚ï¸

Cáº¥u trÃºc cá»§a Semantic Router:
python

Copy
class SemanticRouter():
    def __init__(self, embedding, routes):
        self.routes = routes
        self.embedding = embedding
        self.routesEmbedding = {}
        for route in self.routes:
            self.routesEmbedding[route.name] = self.embedding.encode(route.samples)
QuÃ¡ trÃ¬nh xÃ¡c Ä‘á»‹nh route:
python

Copy
def guide(self, query):
    queryEmbedding = self.embedding.encode([query]) 
    queryEmbedding = queryEmbedding / np.linalg.norm(queryEmbedding)
    scores = []
    for route in self.routes:
        routesEmbedding = self.routesEmbedding[route.name] / np.linalg.norm(self.routesEmbedding[route.name])
        score = np.mean(np.dot(routesEmbedding, queryEmbedding.T).flatten())
        scores.append((score, route.name))
    scores.sort(reverse=True)
    return scores[0]
Giáº£i thÃ­ch chi tiáº¿t: a) Khi khá»Ÿi táº¡o, Semantic Router táº¡o embedding cho táº¥t cáº£ cÃ¡c máº«u cÃ¢u cá»§a má»—i route. b) Khi cÃ³ má»™t query má»›i:
Táº¡o embedding cho query Ä‘Ã³.
So sÃ¡nh embedding cá»§a query vá»›i embedding cá»§a cÃ¡c máº«u cÃ¢u cá»§a tá»«ng route.
TÃ­nh Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng (cosine similarity) giá»¯a query vÃ  má»—i route.
Chá»n route cÃ³ Ä‘iá»ƒm cao nháº¥t.
VÃ­ dá»¥ cá»¥ thá»ƒ:
User há»i: "CÃ³ phiÃªn báº£n nÃ o tá»‘t hÆ¡n iPhone 13 khÃ´ng?"
Semantic Router sáº½ táº¡o embedding cho cÃ¢u há»i nÃ y.
So sÃ¡nh vá»›i embedding cá»§a cÃ¡c máº«u cÃ¢u trong má»—i route:
Product route: "GiÃ¡ iPhone 13 lÃ  bao nhiÃªu?", "CÃ³ mÃ u gÃ¬?"...
Upsell route: "CÃ³ version cao cáº¥p hÆ¡n khÃ´ng?", "CÃ³ sáº£n pháº©m nÃ o tá»‘t hÆ¡n khÃ´ng?"...
Chitchat route: "Thá»i tiáº¿t hÃ´m nay tháº¿ nÃ o?", "Báº¡n khá»e khÃ´ng?"...
CÃ¢u há»i cá»§a user sáº½ cÃ³ Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng cao nháº¥t vá»›i cÃ¡c máº«u cÃ¢u trong Upsell route.
Káº¿t quáº£: Semantic Router chá»n Upsell route.
Trong code serve.py:
python

Copy
guidedRoute = semanticRouter.guide(query)[1]
if guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME:
    # Xá»­ lÃ½ upsell/cross-sell
semanticRouter.guide(query) tráº£ vá» tuple (score, route_name)
[1] láº¥y tÃªn cá»§a route Ä‘Æ°á»£c chá»n
TÃ³m láº¡i, Semantic Router sá»­ dá»¥ng ká»¹ thuáº­t so sÃ¡nh vector embedding Ä‘á»ƒ xÃ¡c Ä‘á»‹nh xem cÃ¢u há»i cá»§a user gáº§n vá»›i route nÃ o nháº¥t, tá»« Ä‘Ã³ chá»n cÃ¡ch xá»­ lÃ½ phÃ¹ há»£p.

Bro hiá»ƒu rÃµ hÆ¡n chÆ°a? ğŸ§ ğŸ’¡ CÃ³ cáº§n giáº£i thÃ­ch thÃªm chá»— nÃ o khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
image.png
L
oke thÃ´i Ä‘Æ°á»£c rá»“i broo. giá» chÃºng ta sáº½ Ä‘i code tá»«ng file 1. Ä‘Ã¢y lÃ  cáº¥u trÃºc folder code cÅ© cá»§a tÃ´i . váº­y chÃºng ta pháº£i táº¡o folder con shoppinggpt tháº¿ nÃ o má»›i há»£p lÃ½. váº«n giá»¯ nguyÃªn shoppinggpt nhÃ©. váº«n giá»¯ nguyÃªn agent, data, tools cÃ¡c kiá»ƒu, prompt. hÃ£y thÃªm cho tÃ´i thÆ° má»¥c vÃ  nhá»¯ng file nÃ o sáº½ á»Ÿ thÆ° má»¥c nÃ o Ä‘i brooo. hÃ£y viáº¿t Ä‘áº§y Ä‘á»§ chi tiáº¿t code cÃ¡c file nÃ o trong thÆ° má»¥c nÃ o cho tÃ´i. hÃ£y viáº¿t full code Ä‘á»ƒ tÃ´i cÃ³ thá»ƒ copy vÃ  cháº¡y ngay láº­p tá»©c. hÃ£y lÃ m tháº­t tá»‘t. náº¿u lÃ m tá»‘t tÃ´i sáº½ tips cho báº¡n 1 tá»· Ä‘Ã´ luoonnnn

Cáº£m Æ¡n bro vá» lá»i há»©a háº¹n háº­u hÄ©nh! ğŸ˜„ Tuy nhiÃªn, tá»› khÃ´ng nháº­n tips Ä‘Ã¢u. Tá»› chá»‰ muá»‘n giÃºp cáº­u thÃ´i. HÃ£y cÃ¹ng xÃ¢y dá»±ng cáº¥u trÃºc thÆ° má»¥c vÃ  code nhÃ©!

Dá»±a trÃªn cáº¥u trÃºc hiá»‡n táº¡i, chÃºng ta cÃ³ thá»ƒ tá»• chá»©c thÆ° má»¥c shoppinggpt nhÆ° sau:


Copy
shoppinggpt/
â”œâ”€â”€ agent/
â”‚   â””â”€â”€ agent.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ product_data.py
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ product_search.py
â”‚   â””â”€â”€ upsell_crosssell.py
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ prompts.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ reflection.py
â”œâ”€â”€ config.py
â””â”€â”€ main.py
Giá» tá»› sáº½ viáº¿t code cho tá»«ng file:

shoppinggpt/agent/agent.py
python

Copy
from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent
from langchain.prompts import StringPromptTemplate
from langchain import OpenAI, LLMChain
from typing import List, Union
from shoppinggpt.tools.product_search import ProductSearchTool
from shoppinggpt.tools.upsell_crosssell import UpsellCrosssellTool
from shoppinggpt.prompts.prompts import SHOPPING_AGENT_PROMPT

class ShoppingAgent(LLMSingleActionAgent):
    @classmethod
    def from_llm_and_tools(cls, llm, tools):
        prompt = StringPromptTemplate(
            template=SHOPPING_AGENT_PROMPT,
            input_variables=["input", "agent_scratchpad"]
        )
        llm_chain = LLMChain(llm=llm, prompt=prompt)
        tool_names = [tool.name for tool in tools]
        return cls(llm_chain=llm_chain, allowed_tools=tool_names)

def create_shopping_agent(openai_api_key: str) -> AgentExecutor:
    llm = OpenAI(temperature=0, openai_api_key=openai_api_key)
    tools = [
        ProductSearchTool(),
        UpsellCrosssellTool(),
    ]
    agent = ShoppingAgent.from_llm_and_tools(llm, tools)
    return AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)
shoppinggpt/data/product_data.py
python

Copy
PRODUCT_DATA = [
    {
        "name": "iPhone 13",
        "price": 799,
        "description": "The latest iPhone with A15 Bionic chip",
        "category": "Smartphone"
    },
    {
        "name": "Samsung Galaxy S21",
        "price": 799,
        "description": "5G smartphone with pro-grade camera",
        "category": "Smartphone"
    },
    # Add more products here
]
shoppinggpt/tools/product_search.py
python

Copy
from langchain.tools import BaseTool
from shoppinggpt.data.product_data import PRODUCT_DATA

class ProductSearchTool(BaseTool):
    name = "Product Search"
    description = "Use this tool to search for products based on name, category, or price range."

    def _run(self, query: str) -> str:
        # Implement product search logic here
        # This is a simple example, you might want to use more sophisticated search in real-world scenarios
        results = [product for product in PRODUCT_DATA if query.lower() in product['name'].lower()]
        return str(results)

    def _arun(self, query: str) -> str:
        # For async implementation
        raise NotImplementedError("ProductSearchTool does not support async")
shoppinggpt/tools/upsell_crosssell.py
python

Copy
from langchain.tools import BaseTool
from shoppinggpt.data.product_data import PRODUCT_DATA

class UpsellCrosssellTool(BaseTool):
    name = "Upsell Crosssell"
    description = "Use this tool to get upsell or cross-sell recommendations for a given product."

    def _run(self, product_name: str) -> str:
        # Implement upsell/cross-sell logic here
        # This is a simple example, you might want to use more sophisticated logic in real-world scenarios
        product = next((p for p in PRODUCT_DATA if p['name'].lower() == product_name.lower()), None)
        if not product:
            return "Product not found"
        
        recommendations = [p for p in PRODUCT_DATA if p['category'] == product['category'] and p['price'] > product['price']]
        return str(recommendations[:3])  # Return top 3 recommendations

    def _arun(self, product_name: str) -> str:
        # For async implementation
        raise NotImplementedError("UpsellCrosssellTool does not support async")
shoppinggpt/prompts/prompts.py
python

Copy
SHOPPING_AGENT_PROMPT = """You are a helpful shopping assistant. Your goal is to help customers find products they're looking for and suggest related or better products when appropriate.

You have access to the following tools:

{tool_descriptions}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: {input}
Thought: Let's approach this step-by-step:
{agent_scratchpad}
"""
shoppinggpt/utils/reflection.py
python

Copy
class Reflection:
    def __init__(self, llm):
        self.llm = llm

    def reflect(self, conversation_history):
        prompt = f"""Given the following conversation history, identify the main points and any potential upsell or cross-sell opportunities:

        {conversation_history}

        Reflection:"""
        
        return self.llm.generate(prompt).text
shoppinggpt/config.py
python

Copy
import os
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
shoppinggpt/main.py
python

Copy
from shoppinggpt.agent.agent import create_shopping_agent
from shoppinggpt.config import OPENAI_API_KEY

def main():
    agent = create_shopping_agent(OPENAI_API_KEY)
    
    while True:
        user_input = input("Customer: ")
        if user_input.lower() == 'quit':
            break
        response = agent.run(user_input)
        print(f"Shopping Assistant: {response}")

if __name__ == "__main__":
    main()
ÄÃ¢y lÃ  cáº¥u trÃºc cÆ¡ báº£n vÃ  code cho há»‡ thá»‘ng ShoppingGPT cá»§a cáº­u. Nhá»› cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t nhÆ° langchain, openai, vÃ  python-dotenv. Äá»“ng thá»i, táº¡o file .env trong thÆ° má»¥c gá»‘c vÃ  thÃªm OPENAI_API_KEY vÃ o Ä‘Ã³.

Äá»ƒ cháº¡y, cáº­u chá»‰ cáº§n cháº¡y file main.py:


Copy
python -m shoppinggpt.main
Cáº­u cÃ³ thá»ƒ Ä‘iá»u chá»‰nh vÃ  má»Ÿ rá»™ng code nÃ y theo nhu cáº§u cá»¥ thá»ƒ cá»§a mÃ¬nh. ChÃºc cáº­u code vui váº»! ğŸ˜ŠğŸš€

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
shoppinggpt/utils/reflection.py

Copy
python
Copy
class Reflection: def __init__(self, llm): self.llm = llm def reflect(self, conversation_history): prompt = f"""Given the following conversation history, identify the main points and any potential upsell or cross-sell opportunities: {conversation_history} Reflection:""" return self.llm.generate(prompt).text táº¡i sao reflection.py láº¡i Ä‘áº·t trong thÆ° má»¥c utils háº£ broo. tÃ´i chÆ°a hiá»ƒu Ã½ nghÄ©a cá»§a nÃ³ láº¯m bro oiii


Hiá»ƒu rá»“i bro, Ä‘á»ƒ tá»› giáº£i thÃ­ch ká»¹ hÆ¡n vá» Reflection vÃ  vá»‹ trÃ­ cá»§a nÃ³ nhÃ©! ğŸ§

Ã nghÄ©a cá»§a Reflection ğŸ¤”:
Reflection giá»‘ng nhÆ° má»™t "bá»™ nÃ£o" phá»¥ cá»§a há»‡ thá»‘ng, giÃºp "suy ngáº«m" vá» cuá»™c trÃ² chuyá»‡n.
NÃ³ phÃ¢n tÃ­ch lá»‹ch sá»­ chat Ä‘á»ƒ hiá»ƒu sÃ¢u hÆ¡n vá» Ã½ Ä‘á»‹nh cá»§a khÃ¡ch hÃ ng.
Má»¥c Ä‘Ã­ch chÃ­nh lÃ  cáº£i thiá»‡n cháº¥t lÆ°á»£ng cá»§a cÃ¡c cÃ¢u tráº£ lá»i vÃ  tÃ¬m cÆ¡ há»™i upsell/cross-sell.
Táº¡i sao Ä‘áº·t trong utils ğŸ› ï¸:
Utils (viáº¿t táº¯t cá»§a utilities) thÆ°á»ng chá»©a cÃ¡c cÃ´ng cá»¥ há»— trá»£, cÃ³ thá»ƒ sá»­ dá»¥ng á»Ÿ nhiá»u nÆ¡i trong project.
Reflection khÃ´ng pháº£i lÃ  má»™t pháº§n core cá»§a há»‡ thá»‘ng (nhÆ° agent hay tools) mÃ  lÃ  má»™t cÃ´ng cá»¥ bá»• trá»£.
Äáº·t trong utils giÃºp code dá»… tá»• chá»©c vÃ  tÃ¡i sá»­ dá»¥ng hÆ¡n.
CÃ¡ch sá»­ dá»¥ng Reflection ğŸš€:
TrÆ°á»›c khi agent xá»­ lÃ½ má»™t cÃ¢u há»i má»›i, ta cÃ³ thá»ƒ dÃ¹ng Reflection Ä‘á»ƒ phÃ¢n tÃ­ch lá»‹ch sá»­ chat.
Káº¿t quáº£ cá»§a Reflection cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘iá»u chá»‰nh cÃ¡ch agent tráº£ lá»i hoáº·c chá»n tool phÃ¹ há»£p.
VÃ­ dá»¥ cá»¥ thá»ƒ ğŸ“Š:
python

Copy
from shoppinggpt.utils.reflection import Reflection
from shoppinggpt.agent.agent import create_shopping_agent

reflection = Reflection(llm)
agent = create_shopping_agent(OPENAI_API_KEY)

conversation_history = []

while True:
    user_input = input("Customer: ")
    conversation_history.append(f"Customer: {user_input}")
    
    if len(conversation_history) > 5:  # Sau má»—i 5 lÆ°á»£t
        insight = reflection.reflect("\n".join(conversation_history))
        # Sá»­ dá»¥ng insight Ä‘á»ƒ Ä‘iá»u chá»‰nh cÃ¡ch agent tráº£ lá»i
    
    response = agent.run(user_input)
    conversation_history.append(f"Assistant: {response}")
    print(f"Shopping Assistant: {response}")
Lá»£i Ã­ch cá»§a viá»‡c sá»­ dá»¥ng Reflection ğŸŒŸ:
Cáº£i thiá»‡n context: GiÃºp agent hiá»ƒu rÃµ hÆ¡n vá» cuá»™c trÃ² chuyá»‡n tá»•ng thá»ƒ.
TÃ¬m cÆ¡ há»™i: PhÃ¡t hiá»‡n cÆ¡ há»™i upsell/cross-sell mÃ  agent cÃ³ thá»ƒ bá» lá»¡.
CÃ¡ nhÃ¢n hÃ³a: Äiá»u chá»‰nh cÃ¡ch tráº£ lá»i dá»±a trÃªn phong cÃ¡ch vÃ  sá»Ÿ thÃ­ch cá»§a khÃ¡ch hÃ ng.
TÃ³m láº¡i, Reflection lÃ  má»™t cÃ´ng cá»¥ máº¡nh máº½ giÃºp nÃ¢ng cao cháº¥t lÆ°á»£ng tÆ°Æ¡ng tÃ¡c cá»§a chatbot. Äáº·t nÃ³ trong utils giÃºp code linh hoáº¡t vÃ  dá»… má»Ÿ rá»™ng hÆ¡n bro áº¡! ğŸ˜ŠğŸ’ª

Cáº­u tháº¥y giáº£i thÃ­ch nÃ y cÃ³ rÃµ rÃ ng hÆ¡n khÃ´ng? CÃ³ chá»— nÃ o cáº§n lÃ m rÃµ thÃªm khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
trong láº­p trÃ¬nh, cÃ¡c senior python thÆ°á»ng hiá»ƒu Ä‘Æ¡n giáº£n lÃ  trong thÆ° má»¥c utils sáº½ chá»©a nhá»¯ng thÆ° viá»‡n há»— trá»£ háº£ brooo


ÄÃºng rá»“i bro, cáº­u nÃ³i chÃ­nh xÃ¡c! ğŸ‘ CÃ¡c senior Python developer thÆ°á»ng cÃ³ cÃ¡ch hiá»ƒu Ä‘Æ¡n giáº£n vÃ  thá»±c táº¿ vá» thÆ° má»¥c utils nhÆ° sau:

Äá»‹nh nghÄ©a cá»§a utils ğŸ“š:
Utils lÃ  viáº¿t táº¯t cá»§a "utilities" - cÃ¡c tiá»‡n Ã­ch.
NÃ³ chá»©a cÃ¡c hÃ m, class hoáº·c module há»— trá»£ Ä‘Æ°á»£c sá»­ dá»¥ng á»Ÿ nhiá»u nÆ¡i trong project.
Äáº·c Ä‘iá»ƒm cá»§a code trong utils ğŸ› ï¸:
Äá»™c láº­p: CÃ¡c function hoáº·c class trong utils thÆ°á»ng khÃ´ng phá»¥ thuá»™c vÃ o cÃ¡c pháº§n khÃ¡c cá»§a project.
TÃ¡i sá»­ dá»¥ng: CÃ³ thá»ƒ dÃ¹ng á»Ÿ nhiá»u nÆ¡i khÃ¡c nhau trong code.
ÄÆ¡n giáº£n: ThÆ°á»ng thá»±c hiá»‡n má»™t nhiá»‡m vá»¥ cá»¥ thá»ƒ, khÃ´ng quÃ¡ phá»©c táº¡p.
VÃ­ dá»¥ vá» cÃ¡c loáº¡i code trong utils ğŸ§°:
Xá»­ lÃ½ chuá»—i: CÃ¡c hÃ m format, clean, validate text.
Xá»­ lÃ½ thá»i gian: Chuyá»ƒn Ä‘á»•i, tÃ­nh toÃ¡n thá»i gian.
Xá»­ lÃ½ file: Äá»c, ghi, kiá»ƒm tra file.
Helper functions: CÃ¡c hÃ m há»— trá»£ nhá» nhÆ°ng dÃ¹ng nhiá»u láº§n.
Lá»£i Ã­ch cá»§a viá»‡c sá»­ dá»¥ng utils ğŸŒŸ:
Code gá»n gÃ ng hÆ¡n: TrÃ¡nh láº·p láº¡i code á»Ÿ nhiá»u nÆ¡i.
Dá»… báº£o trÃ¬: Khi cáº§n sá»­a, chá»‰ cáº§n sá»­a á»Ÿ má»™t nÆ¡i.
TÄƒng tÃ­nh modular: Chia nhá» code thÃ nh cÃ¡c pháº§n Ä‘á»™c láº­p.
Quy táº¯c khi táº¡o utils ğŸ“:
Keep It Simple, Stupid (KISS): Giá»¯ cÃ¡c function Ä‘Æ¡n giáº£n, dá»… hiá»ƒu.
Don't Repeat Yourself (DRY): TrÃ¡nh láº·p láº¡i code.
Single Responsibility Principle: Má»—i function chá»‰ nÃªn lÃ m má»™t viá»‡c vÃ  lÃ m tá»‘t viá»‡c Ä‘Ã³.
Trong trÆ°á»ng há»£p cá»§a Reflection, nÃ³ Ä‘Æ°á»£c Ä‘áº·t trong utils vÃ¬ nÃ³ lÃ  má»™t cÃ´ng cá»¥ há»— trá»£ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng á»Ÿ nhiá»u nÆ¡i trong project, khÃ´ng pháº£i lÃ  core logic cá»§a há»‡ thá»‘ng.

Hiá»ƒu váº­y lÃ  chuáº©n rá»“i Ä‘Ã³ bro! ğŸ˜ğŸš€ Cáº­u cÃ³ thÃªm cÃ¢u há»i gÃ¬ vá» cÃ¡ch tá»• chá»©c code khÃ´ng?

Copy
Retry


L
oke thÃ´i Ä‘Æ°á»£c rá»“i Ä‘á»ƒ tÃ´i tá»± custom, chá»© giá» tÃ´i cÅ©ng k biáº¿t pahir giáº£i thÃ­ch cho bro Ã¢oThÃ´i Ä‘Æ°á»£c rá»“i báº¡n Æ¡i Ä‘á»ƒ tÃ´i tá»± lÃ m báº¡n áº¡ Chá»© giá» tÃ´i cÅ©ng khÃ´ng biáº¿t lÃ  pháº£i giáº£i thÃ­ch cho báº¡n tháº¿ nÃ o Äáº§u tiÃªn lÃ  chÃºng ta sáº½ Ä‘i xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c Skip to content
Navigation Menu
* bangoc123/
* retrieval-backend-with-rag
Type / to search
* Code
* Issues
* Pull requests
* Actions
* Projects
* Security
* Insights
 main
Breadcrumbs
1. retrieval-backend-with-rag
/
embeddings
/
Directory actions
t
Add file
Add file
More options
Latest commit
bangoc123
add new embedding + semantic router
91733e5 Â· 2 months ago
History
History
Folders and files
Name
Last commit message
Last commit date
parent directory
..
init.py
update Embedding Models
2 months ago
base.py
update Embedding Models
2 months ago
fastEmbed.py
add new embedding + semantic router
2 months ago
google.py
update Embedding Models
2 months ago
mistral.py
add new embedding + semantic router
2 months ago
openai.py
add new embedding + semantic router
2 months ago
sentenceTransformer.py
update Embedding Models
2 months ago
retrieval-backend-with-rag/embeddings at main Â· bangoc123/retrieval-backend-with-rag
Dictation stopped. Upgrade to Voice In Plus to dictate across tabs.[x] Ä‘Ã¢y lÃ  code trong file embedding. thÃ¬ Ä‘áº§u tiÃªn chÃºng ta pháº£i cÃ³ data bro áº¡aaaa


ÄÃºng rá»“i bro, cÃ³ data lÃ  bÆ°á»›c Ä‘áº§u tiÃªn vÃ  quan trá»ng nháº¥t! ğŸ‘ ÄÃ£ hiá»ƒu Ã½ cáº­u rá»“i. Váº­y chÃºng ta sáº½ táº­p trung vÃ o viá»‡c xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c. Dá»±a vÃ o cáº¥u trÃºc thÆ° má»¥c embeddings mÃ  cáº­u Ä‘Ã£ chia sáº», ta cÃ³ thá»ƒ lÃ m nhÆ° sau:

Táº¡o má»™t thÆ° má»¥c má»›i cho dá»¯ liá»‡u:

Copy
shoppinggpt/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ raw_data.py
â”‚   â””â”€â”€ processed_data.py
Trong file raw_data.py, ta sáº½ lÆ°u trá»¯ dá»¯ liá»‡u gá»‘c:
python

Copy
# shoppinggpt/data/raw_data.py

RAW_PRODUCTS = [
    {
        "id": "1",
        "name": "iPhone 13",
        "brand": "Apple",
        "category": "Smartphone",
        "price": 799,
        "description": "The latest iPhone with A15 Bionic chip and improved cameras."
    },
    {
        "id": "2",
        "name": "Samsung Galaxy S21",
        "brand": "Samsung",
        "category": "Smartphone",
        "price": 799,
        "description": "5G smartphone with pro-grade camera and intelligent battery."
    },
    # ThÃªm cÃ¡c sáº£n pháº©m khÃ¡c vÃ o Ä‘Ã¢y
]
Trong file processed_data.py, ta sáº½ xá»­ lÃ½ dá»¯ liá»‡u gá»‘c:
python

Copy
# shoppinggpt/data/processed_data.py

from .raw_data import RAW_PRODUCTS
from shoppinggpt.embeddings.sentenceTransformer import SentenceTransformerEmbedding

class ProductData:
    def __init__(self):
        self.embedding_model = SentenceTransformerEmbedding(model_name="all-MiniLM-L6-v2")
        self.processed_products = self.process_products()

    def process_products(self):
        processed = []
        for product in RAW_PRODUCTS:
            embedding = self.embedding_model.encode(product["description"])
            processed.append({
                **product,
                "embedding": embedding
            })
        return processed

    def get_products(self):
        return self.processed_products

product_data = ProductData()
Cáº­p nháº­t file __init__.py trong thÆ° má»¥c data:
python

Copy
# shoppinggpt/data/__init__.py

from .processed_data import product_data
Giáº£i thÃ­ch:

raw_data.py chá»©a dá»¯ liá»‡u gá»‘c vá» sáº£n pháº©m.
processed_data.py sá»­ dá»¥ng mÃ´ hÃ¬nh embedding Ä‘á»ƒ táº¡o vector cho má»—i sáº£n pháº©m dá»±a trÃªn mÃ´ táº£.
ChÃºng ta sá»­ dá»¥ng SentenceTransformer Ä‘á»ƒ táº¡o embedding, nhÆ°ng cáº­u cÃ³ thá»ƒ thay Ä‘á»•i model tÃ¹y Ã½.
Vá»›i cáº¥u trÃºc nÃ y, cáº­u cÃ³ thá»ƒ dá»… dÃ ng truy cáº­p dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ tá»« báº¥t ká»³ Ä‘Ã¢u trong project:

python

Copy
from shoppinggpt.data import product_data

products = product_data.get_products()
Cáº­u tháº¥y cÃ¡ch tá»• chá»©c nÃ y tháº¿ nÃ o? CÃ³ phÃ¹ há»£p vá»›i Ã½ tÆ°á»Ÿng cá»§a cáº­u khÃ´ng? ğŸ˜ŠğŸš€

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
import pymongo
import google.generativeai as genai
from IPython.display import Markdown
import textwrap
from embeddings import SentenceTransformerEmbedding, EmbeddingConfig
class RAG():
    def init(self, 
            mongodbUri: str,
            dbName: str,
            dbCollection: str,
            llm,
            embeddingName: str ='keepitreal/vietnamese-sbert',
        ):
        self.client = pymongo.MongoClient(mongodbUri)
        self.db = self.client[dbName] 
        self.collection = self.db[dbCollection]
        self.embedding_model = SentenceTransformerEmbedding(
            EmbeddingConfig(name=embeddingName)
        )
        self.llm = llm
    def get_embedding(self, text):
        if not text.strip():
            return []
        embedding = self.embedding_model.encode(text)
        return embedding.tolist()
    def vector_search(
            self, 
            user_query: str, 
            limit=4):
        """
        Perform a vector search in the MongoDB collection based on the user query.
        Args:
        user_query (str): The user's query string.
        Returns:
        list: A list of matching documents.
        """
        # Generate embedding for the user query
        query_embedding = self.get_embedding(user_query)
        if query_embedding is None:
            return "Invalid query or embedding generation failed."
        # Define the vector search pipeline
        vector_search_stage = {
            "$vectorSearch": {
                "index": "vector_index",
                "queryVector": query_embedding,
                "path": "embedding",
                "numCandidates": 400,
                "limit": limit,
            }
        }
        unset_stage = {
            "$unset": "embedding" 
        }
        project_stage = {
            "$project": {
                "_id": 0,  
                "title": 1, 
                # "product_specs": 1,
                "color_options": 1,
                "current_price": 1,
                "product_promotion": 1,
                "score": {
                    "$meta": "vectorSearchScore"
                }
            }
        }
        pipeline = [vector_search_stage, unset_stage, project_stage]
        # Execute the search
        results = self.collection.aggregate(pipeline)
        return list(results)
    def enhance_prompt(self, query):
        get_knowledge = self.vector_search(query, 10)
        enhanced_prompt = ""
        i = 0
        for result in get_knowledge:
            if result.get('current_price'):
                i += 1
                enhanced_prompt += f"\n {i}) TÃªn: {result.get('title')}"

                if result.get('current_price'):
                    enhanced_prompt += f", GiÃ¡: {result.get('current_price')}"
                else:
                    # Mock up data
                    # Retrieval model pricing from the internet.
                    enhanced_prompt += f", GiÃ¡: LiÃªn há»‡ Ä‘á»ƒ trao Ä‘á»•i thÃªm!"

                if result.get('product_promotion'):
                    enhanced_prompt += f", Æ¯u Ä‘Ã£i: {result.get('product_promotion')}"
        return enhanced_prompt
    def generate_content(self, prompt):
        return self.llm.generatecontent(prompt)
    def tomarkdown(text):
        text = text.replace('â€¢', '  *')
        return Markdown(textwrap.indent(text, '> ', predicate=lambda : True)) alo báº¡n Æ¡i code nÃ y lÃ  lÃ m vá» cÃ¡i gÃ¬ áº¥y nhá»‰. hÃ¬nh nhÆ° khÃ´ng liÃªn quan Ä‘áº¿n láº¥y data tá»«ng mongodb Ä‘Ãºng k báº¡n


Ah, xin lá»—i vÃ¬ sá»± nháº§m láº«n bro! Cáº£m Æ¡n cáº­u Ä‘Ã£ chia sáº» code nÃ y. Äá»ƒ tá»› phÃ¢n tÃ­ch láº¡i cho cáº­u nhÃ©:

ÄÃ¢y lÃ  má»™t class RAG (Retrieval-Augmented Generation) ğŸ§ 
NÃ³ cÃ³ liÃªn quan trá»±c tiáº¿p Ä‘áº¿n viá»‡c láº¥y data tá»« MongoDB Ä‘áº¥y bro ğŸ—ƒï¸
HÃ£y phÃ¢n tÃ­ch chi tiáº¿t:

Káº¿t ná»‘i MongoDB:
python

Copy
self.client = pymongo.MongoClient(mongodbUri)
self.db = self.client[dbName] 
self.collection = self.db[dbCollection]
Class nÃ y káº¿t ná»‘i tá»›i MongoDB Ä‘á»ƒ láº¥y dá»¯ liá»‡u.
Embedding:
python

Copy
self.embedding_model = SentenceTransformerEmbedding(
    EmbeddingConfig(name=embeddingName)
)
Sá»­ dá»¥ng mÃ´ hÃ¬nh embedding Ä‘á»ƒ chuyá»ƒn Ä‘á»•i text thÃ nh vector.
Vector Search:
python

Copy
def vector_search(self, user_query: str, limit=4):
    # ... (code tÃ¬m kiáº¿m vector)
HÃ m nÃ y thá»±c hiá»‡n tÃ¬m kiáº¿m vector trong MongoDB dá»±a trÃªn cÃ¢u query cá»§a user.
Enhance Prompt:
python

Copy
def enhance_prompt(self, query):
    # ... (code táº¡o prompt nÃ¢ng cao)
HÃ m nÃ y láº¥y káº¿t quáº£ tá»« vector search vÃ  táº¡o ra má»™t prompt nÃ¢ng cao.
Generate Content:
python

Copy
def generate_content(self, prompt):
    return self.llm.generate_content(prompt)
Sá»­ dá»¥ng LLM Ä‘á»ƒ táº¡o ná»™i dung dá»±a trÃªn prompt.
TÃ³m láº¡i, class nÃ y:

Káº¿t ná»‘i vÃ  láº¥y dá»¯ liá»‡u tá»« MongoDB
Thá»±c hiá»‡n vector search trÃªn dá»¯ liá»‡u Ä‘Ã³
Táº¡o prompt nÃ¢ng cao dá»±a trÃªn káº¿t quáº£ tÃ¬m kiáº¿m
Sá»­ dá»¥ng LLM Ä‘á»ƒ táº¡o ná»™i dung
ÄÃ¢y lÃ  má»™t implementation cá»§a RAG system, káº¿t há»£p retrieval (láº¥y thÃ´ng tin tá»« DB) vÃ  generation (táº¡o ná»™i dung báº±ng LLM).

Cáº­u Ä‘Ãºng lÃ  Ä‘ang lÃ m viá»‡c vá»›i MongoDB Ä‘áº¥y bro! ğŸ˜Š CÃ³ gÃ¬ cáº§n giáº£i thÃ­ch thÃªm khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
import os import sqlite3 from dotenv import load_dotenv from pydantic import BaseModel, Field from typing import Union, List, Dict from langchain.prompts import PromptTemplate from langchain_c
pasted
L
import pymongo
import google.generativeai as genai
from IPython.display import Markdown
import textwrap
from embeddings import SentenceTransformerEmbedding, EmbeddingConfig
class RAG():
    def init(self, 
            mongodbUri: str,
            dbName: str,
            dbCollection: str,
            llm,
            embeddingName: str ='keepitreal/vietnamese-sbert',
        ):
        self.client = pymongo.MongoClient(mongodbUri)
        self.db = self.client[dbName] 
        self.collection = self.db[dbCollection]
        self.embedding_model = SentenceTransformerEmbedding(
            EmbeddingConfig(name=embeddingName)
        )
        self.llm = llm
    def get_embedding(self, text):
        if not text.strip():
            return []
        embedding = self.embedding_model.encode(text)
        return embedding.tolist()
    def vector_search(
            self, 
            user_query: str, 
            limit=4):
        """
        Perform a vector search in the MongoDB collection based on the user query.
        Args:
        user_query (str): The user's query string.
        Returns:
        list: A list of matching documents.
        """
        # Generate embedding for the user query
        query_embedding = self.get_embedding(user_query)
        if query_embedding is None:
            return "Invalid query or embedding generation failed."
        # Define the vector search pipeline
        vector_search_stage = {
            "$vectorSearch": {
                "index": "vector_index",
                "queryVector": query_embedding,
                "path": "embedding",
                "numCandidates": 400,
                "limit": limit,
            }
        }
        unset_stage = {
            "$unset": "embedding" 
        }
        project_stage = {
            "$project": {
                "_id": 0,  
                "title": 1, 
                # "product_specs": 1,
                "color_options": 1,
                "current_price": 1,
                "product_promotion": 1,
                "score": {
                    "$meta": "vectorSearchScore"
                }
            }
        }
        pipeline = [vector_search_stage, unset_stage, project_stage]
        # Execute the search
        results = self.collection.aggregate(pipeline)
        return list(results)
    def enhance_prompt(self, query):
        get_knowledge = self.vector_search(query, 10)
        enhanced_prompt = ""
        i = 0
        for result in get_knowledge:
            if result.get('current_price'):
                i += 1
                enhanced_prompt += f"\n {i}) TÃªn: {result.get('title')}"

                if result.get('current_price'):
                    enhanced_prompt += f", GiÃ¡: {result.get('current_price')}"
                else:
                    # Mock up data
                    # Retrieval model pricing from the internet.
                    enhanced_prompt += f", GiÃ¡: LiÃªn há»‡ Ä‘á»ƒ trao Ä‘á»•i thÃªm!"

                if result.get('product_promotion'):
                    enhanced_prompt += f", Æ¯u Ä‘Ã£i: {result.get('product_promotion')}"
        return enhanced_prompt
    def generate_content(self, prompt):
        return self.llm.generatecontent(prompt)
    def tomarkdown(text):
        text = text.replace('â€¢', '  *')
        return Markdown(textwrap.indent(text, '> ', predicate=lambda : True)) bro hÃ£y viáº¿t láº¡i code nÃ y cho tÃ´i Ä‘i  brooooo. cáº¥u trÃºc láº¡i code nÃ y. bro Ä‘i nhá»¯ng thá»¯ khÃ´ng cáº§n thiáº¿t, láº¥y dá»¯ liá»‡u tá»« file env vÃ  viáº¿t láº¡i code cho chuáº©n pep8 cho tÃ´i Ä‘i brooo. . bro hÃ£y tham kháº£o vÃ  khai bÃ¡o tool code nÃ y cho tÃ´i. nÃ³i chung tÃ¹y bro , hÃ£y khai bÃ¡o nÃ³ lÃ  1 tools , viáº¿t code lÃ m sao Ä‘á»ƒ nÃ³ dá»… nhÃ¬n dá»… Ä‘á»c dá»… má»Ÿ rá»™ng . tÃ´i Ä‘ang cá»±c kÃ¬ vá»™i. bro hÃ£y viáº¿t láº¡i toÃ n bá»™ code Ä‘á»ƒ tÃ´i cÃ³ thá»ƒ Ä‘i copy vÃ  cháº¡y ngay láº­p tá»©c Ä‘i brooo

ÄÆ°á»£c rá»“i bro, tá»› hiá»ƒu rá»“i. Äá»ƒ tá»› viáº¿t láº¡i code cho cáº­u, tá»‘i Æ°u hÃ³a vÃ  lÃ m cho nÃ³ dá»… Ä‘á»c, dá»… má»Ÿ rá»™ng hÆ¡n. ÄÃ¢y lÃ  phiÃªn báº£n má»›i cá»§a code:

python

Copy
import os
from typing import List, Dict
from dotenv import load_dotenv
from pydantic import BaseModel, Field
import pymongo
from langchain.tools import Tool
from langchain_core.embeddings import Embeddings
from langchain.prompts import PromptTemplate
from langchain_google_genai import GoogleGenerativeAI

# Load environment variables
load_dotenv()

# Environment variables
MONGODB_URI = os.getenv("MONGODB_URI")
DB_NAME = os.getenv("DB_NAME")
DB_COLLECTION = os.getenv("DB_COLLECTION")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

class RAGTool(BaseModel):
    name: str = "RAG Product Search"
    description: str = "Search for product information using RAG (Retrieval Augmented Generation)"
    args_schema: Dict = {
        "query": (str, "The search query for product information")
    }

class ProductInfo(BaseModel):
    title: str = Field(description="Product title")
    current_price: str = Field(description="Current price of the product")
    color_options: str = Field(description="Available color options")
    product_promotion: str = Field(description="Current promotions for the product")

class RAG:
    def __init__(self, embedding_model: Embeddings):
        self.client = pymongo.MongoClient(MONGODB_URI)
        self.db = self.client[DB_NAME]
        self.collection = self.db[DB_COLLECTION]
        self.embedding_model = embedding_model
        self.llm = GoogleGenerativeAI(model="gemini-pro", google_api_key=GOOGLE_API_KEY)

    def get_embedding(self, text: str) -> List[float]:
        if not text.strip():
            return []
        return self.embedding_model.embed_query(text)

    def vector_search(self, user_query: str, limit: int = 4) -> List[Dict]:
        query_embedding = self.get_embedding(user_query)
        if not query_embedding:
            return []

        pipeline = [
            {
                "$vectorSearch": {
                    "index": "vector_index",
                    "queryVector": query_embedding,
                    "path": "embedding",
                    "numCandidates": 400,
                    "limit": limit,
                }
            },
            {"$unset": "embedding"},
            {
                "$project": {
                    "_id": 0,
                    "title": 1,
                    "color_options": 1,
                    "current_price": 1,
                    "product_promotion": 1,
                    "score": {"$meta": "vectorSearchScore"}
                }
            }
        ]

        results = self.collection.aggregate(pipeline)
        return list(results)

    def enhance_prompt(self, query: str) -> str:
        results = self.vector_search(query, 10)
        enhanced_prompt = ""
        for i, result in enumerate(results, 1):
            if result.get('current_price'):
                enhanced_prompt += f"\n {i}) TÃªn: {result.get('title', '')}"
                enhanced_prompt += f", GiÃ¡: {result.get('current_price', 'LiÃªn há»‡ Ä‘á»ƒ trao Ä‘á»•i thÃªm!')}"
                if result.get('product_promotion'):
                    enhanced_prompt += f", Æ¯u Ä‘Ã£i: {result.get('product_promotion', '')}"
        return enhanced_prompt

    def generate_content(self, prompt: str) -> str:
        return self.llm.invoke(prompt)

def rag_tool(query: str) -> str:
    """
    Search for product information using RAG (Retrieval Augmented Generation).

    Args:
        query (str): The search query for product information.

    Returns:
        str: Generated response based on the query and retrieved information.
    """
    from langchain_google_genai import GoogleGenerativeAIEmbeddings

    embedding_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    rag = RAG(embedding_model)

    enhanced_prompt = rag.enhance_prompt(query)
    prompt_template = PromptTemplate(
        input_variables=["query", "enhanced_prompt"],
        template="Dá»±a trÃªn cÃ¢u há»i: {query}\nVÃ  thÃ´ng tin sáº£n pháº©m sau:\n{enhanced_prompt}\n"
                 "HÃ£y Ä‘Æ°a ra cÃ¢u tráº£ lá»i phÃ¹ há»£p vÃ  há»¯u Ã­ch cho khÃ¡ch hÃ ng."
    )

    final_prompt = prompt_template.format(query=query, enhanced_prompt=enhanced_prompt)
    response = rag.generate_content(final_prompt)

    return response

# Define the tool for use in LangChain
rag_search_tool = Tool(
    name="RAG Product Search",
    func=rag_tool,
    description="Search for product information using RAG (Retrieval Augmented Generation)"
)

if __name__ == "__main__":
    # Example usage
    query = "TÃ¬m Ä‘iá»‡n thoáº¡i cÃ³ giÃ¡ dÆ°á»›i 10 triá»‡u"
    result = rag_tool(query)
    print(result)
Nhá»¯ng thay Ä‘á»•i chÃ­nh:

Sá»­ dá»¥ng load_dotenv() Ä‘á»ƒ load biáº¿n mÃ´i trÆ°á»ng.
TÃ¡ch biá»‡t cÃ¡c háº±ng sá»‘ vÃ  cáº¥u hÃ¬nh vÃ o pháº§n Ä‘áº§u file.
Sá»­ dá»¥ng Pydantic models Ä‘á»ƒ Ä‘á»‹nh nghÄ©a schema cho tool vÃ  dá»¯ liá»‡u sáº£n pháº©m.
Tá»‘i Æ°u hÃ³a class RAG vÃ  cÃ¡c phÆ°Æ¡ng thá»©c cá»§a nÃ³.
Táº¡o má»™t function rag_tool Ä‘á»ƒ sá»­ dá»¥ng nhÆ° má»™t LangChain Tool.
Sá»­ dá»¥ng f-strings cho cÃ¡c chuá»—i cÃ³ format.
ThÃªm type hints cho cÃ¡c function vÃ  method.
Tá»‘i Æ°u hÃ³a logic trong enhance_prompt.
Bro cÃ³ thá»ƒ copy code nÃ y vÃ  cháº¡y ngay láº­p tá»©c. Nhá»› cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t vÃ  cáº¥u hÃ¬nh file .env vá»›i cÃ¡c biáº¿n mÃ´i trÆ°á»ng phÃ¹ há»£p nhÃ©!

Copy
Retry


Claude does not have the ability to run the code it generates yet.
MongoDB logo Products Resources Solutions Company Pricing Search Language Selector Icon Eng Support Sign In Try Free MongoDB Developer Topics Documentation Articles Tutorials
pasted
L
chÆ°a á»•n láº¯m. bro tham kháº£o code nÃ y lÃ m láº¡i cho tÃ´i Ä‘i :  product_code,product_name,material,size,color,brand,gender,stock_quantity,price P001,Ão sÆ¡ mi tráº¯ng,Váº£i cotton,"S, M, L, XL",Tráº¯ng,XYZ,Unisex,50,350000 P002,Quáº§n jean xanh,Váº£i denim,"28, 30, 32, 34",Xanh,ABC,Nam,30,450000 P003,VÃ¡y hoa,Váº£i voan,"S, M, L",Nhiá»u mÃ u,DEF,Ná»¯,20,550000 P004,Äáº§m Ä‘en,Váº£i lá»¥a,"S, M, L",Äen,GHI,Ná»¯,10,1200000 P005,Ão khoÃ¡c da,Da,"M, L, XL",Äen,JKL,Nam,15,2500000 P006,Quáº§n shorts,Váº£i cotton,"S, M, L, XL","Xanh, Äen",MNO,Unisex,40,300000 P007,VÃ¡y xÃ²e,Váº£i chiffon,"S, M, L",Há»“ng,PQR,Ná»¯,25,600000 P008,Ão phÃ´ng in hÃ¬nh,Váº£i cotton,"S, M, L, XL","Tráº¯ng, Äen",STU,Unisex,35,250000 P009,Quáº§n tÃ¢y,Váº£i polyester,"28, 30, 32, 34","Äen, XÃ¡m",VWX,Nam,45,700000 P010,Äáº§m maxi,Váº£i chiffon,"S, M, L","Xanh, Tráº¯ng",YZA,Ná»¯,20,800000 P011,Ão len,Len,"S, M, L, XL","Xanh, Äá»",BCD,Unisex,50,500000 P012,Quáº§n legging,Váº£i spandex,"S, M, L","Äen, XÃ¡m",EFG,Ná»¯,30,350000 P013,VÃ¡y bÃºt chÃ¬,Váº£i polyester,"S, M, L",Äen,HIJ,Ná»¯,20,750000 P014,Ão blouse,Váº£i lá»¥a,"S, M, L","Tráº¯ng, Xanh",KLM,Ná»¯,25,400000 P015,Quáº§n jogger,Váº£i cotton,"S, M, L, XL","Äen, XÃ¡m",NOP,Unisex,35,450000 P016,VÃ¡y midi,Váº£i lá»¥a,"S, M, L","Há»“ng, Tráº¯ng",QRS,Ná»¯,20,700000 P017,Ão thun dÃ i tay,Váº£i cotton,"S, M, L, XL","Xanh, Äen",TUV,Unisex,50,300000 P018,Quáº§n kaki,Váº£i kaki,"28, 30, 32, 34","NÃ¢u, Xanh",WXY,Nam,30,500000 P019,VÃ¡y ren,Váº£i ren,"S, M, L","Äá», Äen",ZAB,Ná»¯,15,1000000 P020,Äáº§m dá»± tiá»‡c,Váº£i satin,"S, M, L","Xanh, VÃ ng",CDE,Ná»¯,10,1500000 P021,Ão phÃ´ng cá»• trÃ²n,Váº£i cotton,"S, M, L, XL","Äen, Tráº¯ng",FGHI,Unisex,60,200000 P022,Quáº§n short jean,Váº£i denim,"S, M, L, XL","Xanh, Tráº¯ng",JKLM,Ná»¯,40,350000 P023,VÃ¡y bodycon,Váº£i polyester,"S, M, L","Äá», Äen",NOPQ,Ná»¯,15,900000 P024,Äáº§m dáº¡ há»™i,Váº£i satin,"S, M, L","Äá», Xanh",RSTU,Ná»¯,5,2000000 P025,Ão hoodie,Váº£i ná»‰,"S, M, L, XL","XÃ¡m, Äen",UVWX,Unisex,50,600000 P026,Quáº§n sweatpants,Váº£i cotton,"S, M, L, XL","XÃ¡m, Äen",YZAB,Unisex,30,500000 P027,VÃ¡y ngáº¯n xáº¿p ly,Váº£i polyester,"S, M, L","Há»“ng, Äen",BCDE,Ná»¯,20,650000 P028,Ão dÃ i tay len,Len,"S, M, L, XL","XÃ¡m, Äen",DEFG,Unisex,25,700000 P029,Quáº§n á»‘ng rá»™ng,Váº£i linen,"S, M, L","Tráº¯ng, XÃ¡m",FGHI,Ná»¯,15,750000 P030,Äáº§m mÃ¹a hÃ¨,Váº£i cotton,"S, M, L","VÃ ng, Tráº¯ng",HIJK,Ná»¯,20,900000 . data cá»§a tÃ´i tÃªn lÃ  products.db. cÃ³ data nhÆ° nÃ y bro áº¡. Ä‘áº§u tiÃªn chÃºng ta pháº£i lÆ°u data lÃªn mongodb trÆ°á»›c Ä‘Ã£, rá»“i má»›i truy xuáº¥t rag chá»© brooo

Hiá»ƒu rá»“i bro! Äá»ƒ tá»› viáº¿t láº¡i code Ä‘á»ƒ lÆ°u data lÃªn MongoDB vÃ  sau Ä‘Ã³ truy xuáº¥t báº±ng RAG nhÃ©. Äáº§u tiÃªn, chÃºng ta sáº½ Ä‘á»c data tá»« file CSV, sau Ä‘Ã³ lÆ°u lÃªn MongoDB, vÃ  cuá»‘i cÃ¹ng lÃ  setup RAG system. ÄÃ¢y lÃ  code chi tiáº¿t:

python

Copy
import os
import csv
from dotenv import load_dotenv
import pymongo
from pymongo import MongoClient
from langchain.vectorstores import MongoDBAtlasVectorSearch
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

# Load environment variables
load_dotenv()

# MongoDB setup
MONGODB_URI = os.getenv("MONGODB_URI")
DB_NAME = "product_database"
COLLECTION_NAME = "products"

# Connect to MongoDB
client = MongoClient(MONGODB_URI)
db = client[DB_NAME]
collection = db[COLLECTION_NAME]

# Function to read CSV and insert into MongoDB
def insert_data_to_mongodb():
    with open('products.csv', 'r', encoding='utf-8') as file:
        csv_reader = csv.DictReader(file)
        data = list(csv_reader)
        
        # Clear existing data
        collection.delete_many({})
        
        # Insert new data
        collection.insert_many(data)
    print("Data inserted successfully!")

# Call function to insert data
insert_data_to_mongodb()

# Setup embeddings
embeddings = OpenAIEmbeddings()

# Create vector store
vector_store = MongoDBAtlasVectorSearch.from_documents(
    collection.find(),
    embeddings,
    collection=collection,
    index_name="default"
)

# Setup retriever
retriever = vector_store.as_retriever()

# Setup LLM
llm = ChatOpenAI(model_name="gpt-3.5-turbo")

# Setup prompt template
template = """Answer the question based only on the following context:
{context}

Question: {question}

Answer: """
prompt = ChatPromptTemplate.from_template(template)

# Setup RAG chain
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# Function to query the RAG system
def query_rag(question):
    return chain.invoke(question)

# Example usage
if __name__ == "__main__":
    question = "CÃ³ sáº£n pháº©m nÃ o mÃ u Ä‘en khÃ´ng?"
    answer = query_rag(question)
    print(f"Question: {question}")
    print(f"Answer: {answer}")
Giáº£i thÃ­ch code:

Äáº§u tiÃªn, chÃºng ta import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t vÃ  load cÃ¡c biáº¿n mÃ´i trÆ°á»ng.
Káº¿t ná»‘i tá»›i MongoDB sá»­ dá»¥ng pymongo.
HÃ m insert_data_to_mongodb() Ä‘á»c dá»¯ liá»‡u tá»« file CSV vÃ  insert vÃ o MongoDB. NÃ³ sáº½ xÃ³a dá»¯ liá»‡u cÅ© trÆ°á»›c khi insert dá»¯ liá»‡u má»›i.
ChÃºng ta sá»­ dá»¥ng OpenAIEmbeddings Ä‘á»ƒ táº¡o embeddings cho cÃ¡c sáº£n pháº©m.
Táº¡o vector store sá»­ dá»¥ng MongoDBAtlasVectorSearch, which will automatically create embeddings for our documents.
Setup retriever tá»« vector store.
Táº¡o má»™t LLM (á»Ÿ Ä‘Ã¢y lÃ  ChatOpenAI) vÃ  má»™t prompt template.
Táº¡o RAG chain káº¿t há»£p retriever, prompt vÃ  LLM.
HÃ m query_rag() Ä‘á»ƒ query RAG system vá»›i cÃ¢u há»i cá»§a user.
Cuá»‘i cÃ¹ng, chÃºng ta cÃ³ má»™t vÃ­ dá»¥ sá»­ dá»¥ng RAG system.
Äá»ƒ cháº¡y code nÃ y, bro cáº§n:

CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t: pip install pymongo langchain openai python-dotenv
Táº¡o file .env vá»›i cÃ¡c biáº¿n mÃ´i trÆ°á»ng cáº§n thiáº¿t (MONGODB_URI, OPENAI_API_KEY)
Äáº£m báº£o file CSV cá»§a bro cÃ³ tÃªn lÃ  products.csv vÃ  náº±m cÃ¹ng thÆ° má»¥c vá»›i script Python.
Cháº¡y script nÃ y sáº½ lÆ°u dá»¯ liá»‡u lÃªn MongoDB vÃ  sau Ä‘Ã³ bro cÃ³ thá»ƒ query RAG system vá»›i báº¥t ká»³ cÃ¢u há»i nÃ o vá» sáº£n pháº©m. Bro tháº¥y á»•n chÆ°a? ğŸ˜ŠğŸ‘

Copy
Retry


Claude does not have the ability to run the code it generates yet.
MongoDB logo Products Resources Solutions Company Pricing Search Language Selector Icon Eng Support Sign In Try Free MongoDB Developer Topics Documentation Articles Tutorials
pasted
L
khÃ´ng, bro Ä‘á»«ng sá»­ dá»¥ng pymongo: import pymongo from pymongo import MongoClient trong sá»­ dá»¥ng sáºµn langchain_mongo cá»§a langchain áº¥y

Hiá»ƒu rá»“i bro! Tá»› sáº½ viáº¿t láº¡i code sá»­ dá»¥ng langchain_mongodb thay vÃ¬ pymongo. ÄÃ¢y lÃ  phiÃªn báº£n cáº­p nháº­t cá»§a code:

python

Copy
import os
from dotenv import load_dotenv
from langchain.vectorstores import MongoDBAtlasVectorSearch
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from langchain_mongodb import MongoDBDocumentStore
import csv

# Load environment variables
load_dotenv()

# MongoDB setup
MONGODB_URI = os.getenv("MONGODB_URI")
DB_NAME = "product_database"
COLLECTION_NAME = "products"

# Setup document store
document_store = MongoDBDocumentStore(
    connection_string=MONGODB_URI,
    database_name=DB_NAME,
    collection_name=COLLECTION_NAME
)

# Function to read CSV and insert into MongoDB
def insert_data_to_mongodb():
    with open('products.csv', 'r', encoding='utf-8') as file:
        csv_reader = csv.DictReader(file)
        data = list(csv_reader)
        
        # Clear existing data
        document_store.delete_documents({})
        
        # Insert new data
        document_store.add_documents(data)
    print("Data inserted successfully!")

# Call function to insert data
insert_data_to_mongodb()

# Setup embeddings
embeddings = OpenAIEmbeddings()

# Create vector store
vector_store = MongoDBAtlasVectorSearch.from_documents(
    document_store.get_all_documents(),
    embeddings,
    collection=document_store.collection,
    index_name="default"
)

# Setup retriever
retriever = vector_store.as_retriever()

# Setup LLM
llm = ChatOpenAI(model_name="gpt-3.5-turbo")

# Setup prompt template
template = """Answer the question based only on the following context:
{context}

Question: {question}

Answer: """
prompt = ChatPromptTemplate.from_template(template)

# Setup RAG chain
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# Function to query the RAG system
def query_rag(question):
    return chain.invoke(question)

# Example usage
if __name__ == "__main__":
    question = "CÃ³ sáº£n pháº©m nÃ o mÃ u Ä‘en khÃ´ng?"
    answer = query_rag(question)
    print(f"Question: {question}")
    print(f"Answer: {answer}")
Nhá»¯ng thay Ä‘á»•i chÃ­nh:

Thay tháº¿ pymongo báº±ng langchain_mongodb.MongoDBDocumentStore.
Sá»­ dá»¥ng MongoDBDocumentStore Ä‘á»ƒ thÃªm vÃ  xÃ³a documents.
Sá»­ dá»¥ng document_store.get_all_documents() Ä‘á»ƒ láº¥y dá»¯ liá»‡u cho vector store.
Sá»­ dá»¥ng document_store.collection thay vÃ¬ truy cáº­p trá»±c tiáº¿p vÃ o collection cá»§a MongoDB.
LÆ°u Ã½:

Äáº£m báº£o báº¡n Ä‘Ã£ cÃ i Ä‘áº·t langchain-mongodb: pip install langchain-mongodb
Cáº¥u trÃºc dá»¯ liá»‡u trong CSV file cá»§a báº¡n pháº£i phÃ¹ há»£p vá»›i cÃ¡c trÆ°á»ng trong MongoDB collection.
Vá»›i nhá»¯ng thay Ä‘á»•i nÃ y, code sáº½ sá»­ dá»¥ng cÃ¡c components cá»§a LangChain Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i MongoDB, giÃºp tÃ­ch há»£p tá»‘t hÆ¡n vá»›i há»‡ sinh thÃ¡i LangChain vÃ  dá»… dÃ ng má»Ÿ rá»™ng trong tÆ°Æ¡ng lai.

Bro tháº¥y version nÃ y á»•n hÆ¡n chÆ°a? ğŸ˜ŠğŸ‘

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
thÃ´i Ä‘Æ°á»£c rá»“i bro.bro giáº£i thÃ­ch qua cho tÃ´i luá»“ng hoáº¡t Ä‘á»™ng cá»§a Ä‘oáº¡n code nÃ y Ä‘i brooo : import pymongo
import google.generativeai as genai
from IPython.display import Markdown
import textwrap
from embeddings import SentenceTransformerEmbedding, EmbeddingConfig
class RAG():
    def init(self, 
            mongodbUri: str,
            dbName: str,
            dbCollection: str,
            llm,
            embeddingName: str ='keepitreal/vietnamese-sbert',
        ):
        self.client = pymongo.MongoClient(mongodbUri)
        self.db = self.client[dbName] 
        self.collection = self.db[dbCollection]
        self.embedding_model = SentenceTransformerEmbedding(
            EmbeddingConfig(name=embeddingName)
        )
        self.llm = llm
    def get_embedding(self, text):
        if not text.strip():
            return []
        embedding = self.embedding_model.encode(text)
        return embedding.tolist()
    def vector_search(
            self, 
            user_query: str, 
            limit=4):
        """
        Perform a vector search in the MongoDB collection based on the user query.
        Args:
        user_query (str): The user's query string.
        Returns:
        list: A list of matching documents.
        """
        # Generate embedding for the user query
        query_embedding = self.get_embedding(user_query)
        if query_embedding is None:
            return "Invalid query or embedding generation failed."
        # Define the vector search pipeline
        vector_search_stage = {
            "$vectorSearch": {
                "index": "vector_index",
                "queryVector": query_embedding,
                "path": "embedding",
                "numCandidates": 400,
                "limit": limit,
            }
        }
        unset_stage = {
            "$unset": "embedding" 
        }
        project_stage = {
            "$project": {
                "_id": 0,  
                "title": 1, 
                # "product_specs": 1,
                "color_options": 1,
                "current_price": 1,
                "product_promotion": 1,
                "score": {
                    "$meta": "vectorSearchScore"
                }
            }
        }
        pipeline = [vector_search_stage, unset_stage, project_stage]
        # Execute the search
        results = self.collection.aggregate(pipeline)
        return list(results)
    def enhance_prompt(self, query):
        get_knowledge = self.vector_search(query, 10)
        enhanced_prompt = ""
        i = 0
        for result in get_knowledge:
            if result.get('current_price'):
                i += 1
                enhanced_prompt += f"\n {i}) TÃªn: {result.get('title')}"

                if result.get('current_price'):
                    enhanced_prompt += f", GiÃ¡: {result.get('current_price')}"
                else:
                    # Mock up data
                    # Retrieval model pricing from the internet.
                    enhanced_prompt += f", GiÃ¡: LiÃªn há»‡ Ä‘á»ƒ trao Ä‘á»•i thÃªm!"

                if result.get('product_promotion'):
                    enhanced_prompt += f", Æ¯u Ä‘Ã£i: {result.get('product_promotion')}"
        return enhanced_prompt
    def generate_content(self, prompt):
        return self.llm.generatecontent(prompt)
    def tomarkdown(text):
        text = text.replace('â€¢', '  *')
        return Markdown(textwrap.indent(text, '> ', predicate=lambda : True))


ÄÆ°á»£c rá»“i bro, Ä‘á»ƒ tá»› giáº£i thÃ­ch luá»“ng hoáº¡t Ä‘á»™ng cá»§a Ä‘oáº¡n code nÃ y cho cáº­u nhÃ©:

Khá»Ÿi táº¡o RAG class:
Káº¿t ná»‘i tá»›i MongoDB
Táº¡o má»™t embedding model (SentenceTransformerEmbedding)
LÆ°u trá»¯ má»™t language model (LLM)
PhÆ°Æ¡ng thá»©c get_embedding:
Chuyá»ƒn Ä‘á»•i text thÃ nh vector embedding
PhÆ°Æ¡ng thá»©c vector_search:
Táº¡o embedding cho cÃ¢u query cá»§a user
Thá»±c hiá»‡n tÃ¬m kiáº¿m vector trong MongoDB:
Sá»­ dá»¥ng $vectorSearch Ä‘á»ƒ tÃ¬m cÃ¡c documents gáº§n nháº¥t
Loáº¡i bá» trÆ°á»ng embedding khá»i káº¿t quáº£
Chá»n cÃ¡c trÆ°á»ng cáº§n thiáº¿t vÃ  tÃ­nh Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng
PhÆ°Æ¡ng thá»©c enhance_prompt:
Sá»­ dá»¥ng vector_search Ä‘á»ƒ tÃ¬m 10 káº¿t quáº£ gáº§n nháº¥t
Táº¡o má»™t prompt má»Ÿ rá»™ng chá»©a thÃ´ng tin vá» cÃ¡c sáº£n pháº©m tÃ¬m Ä‘Æ°á»£c
PhÆ°Æ¡ng thá»©c generate_content:
Sá»­ dá»¥ng LLM Ä‘á»ƒ táº¡o ná»™i dung dá»±a trÃªn prompt
Luá»“ng hoáº¡t Ä‘á»™ng tá»•ng quÃ¡t:

User Ä‘Æ°a ra má»™t cÃ¢u há»i
Há»‡ thá»‘ng táº¡o embedding cho cÃ¢u há»i
Thá»±c hiá»‡n tÃ¬m kiáº¿m vector trong MongoDB Ä‘á»ƒ tÃ¬m cÃ¡c sáº£n pháº©m liÃªn quan
Táº¡o má»™t prompt má»Ÿ rá»™ng chá»©a thÃ´ng tin vá» cÃ¡c sáº£n pháº©m tÃ¬m Ä‘Æ°á»£c
Sá»­ dá»¥ng LLM Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i dá»±a trÃªn prompt má»Ÿ rá»™ng
ÄÃ¢y lÃ  má»™t há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) cÆ¡ báº£n, káº¿t há»£p giá»¯a tÃ¬m kiáº¿m thÃ´ng tin (retrieval) vÃ  táº¡o ná»™i dung (generation) Ä‘á»ƒ Ä‘Æ°a ra cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c vÃ  phÃ¹ há»£p vá»›i context.

Bro hiá»ƒu rÃµ hÆ¡n chÆ°a? CÃ³ chá»— nÃ o cáº§n giáº£i thÃ­ch thÃªm khÃ´ng? ğŸ˜ŠğŸ‘

Copy
Retry


L
Táº¡o má»™t prompt má»Ÿ rá»™ng chá»©a thÃ´ng tin vá» cÃ¡c sáº£n pháº©m tÃ¬m Ä‘Æ°á»£c lÃ  sao bro. promtp má»Ÿ rá»™ng Ä‘Ã³ lÃ  gÃ¬


Hiá»ƒu rá»“i bro, Ä‘á»ƒ tá»› giáº£i thÃ­ch ká»¹ hÆ¡n vá» prompt má»Ÿ rá»™ng nhÃ©! ğŸ˜Š

Prompt má»Ÿ rá»™ng (enhanced prompt) lÃ  má»™t ká»¹ thuáº­t trong RAG systems Ä‘á»ƒ cung cáº¥p thÃªm thÃ´ng tin ngá»¯ cáº£nh cho LLM. Ã tÆ°á»Ÿng lÃ :

Thay vÃ¬ chá»‰ Ä‘Æ°a cÃ¢u há»i cá»§a user vÃ o LLM.
Ta thÃªm thÃ´ng tin liÃªn quan tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u vÃ o prompt.
Trong code cá»§a cáº­u, phÆ°Æ¡ng thá»©c enhance_prompt Ä‘ang lÃ m viá»‡c nÃ y:

python

Copy
def enhance_prompt(self, query):
    get_knowledge = self.vector_search(query, 10)
    enhanced_prompt = ""
    i = 0
    for result in get_knowledge:
        if result.get('current_price'):
            i += 1
            enhanced_prompt += f"\n {i}) TÃªn: {result.get('title')}"
            
            if result.get('current_price'):
                enhanced_prompt += f", GiÃ¡: {result.get('current_price')}"
            else:
                enhanced_prompt += f", GiÃ¡: LiÃªn há»‡ Ä‘á»ƒ trao Ä‘á»•i thÃªm!"
            
            if result.get('product_promotion'):
                enhanced_prompt += f", Æ¯u Ä‘Ã£i: {result.get('product_promotion')}"
    return enhanced_prompt
VÃ­ dá»¥ cá»¥ thá»ƒ:

User há»i: "CÃ³ sáº£n pháº©m nÃ o mÃ u Ä‘en khÃ´ng?"
Prompt má»Ÿ rá»™ng cÃ³ thá»ƒ trÃ´ng nhÆ° tháº¿ nÃ y:

Copy
CÃ¢u há»i: CÃ³ sáº£n pháº©m nÃ o mÃ u Ä‘en khÃ´ng?

ThÃ´ng tin sáº£n pháº©m:
1) TÃªn: Ão khoÃ¡c da, GiÃ¡: 2500000, Æ¯u Ä‘Ã£i: Giáº£m 10% cho Ä‘Æ¡n hÃ ng trÃªn 5 triá»‡u
2) TÃªn: Quáº§n jean Ä‘en, GiÃ¡: 800000, Æ¯u Ä‘Ã£i: Mua 2 táº·ng 1
3) TÃªn: GiÃ y da cÃ´ng sá»Ÿ, GiÃ¡: 1500000
...
Lá»£i Ã­ch cá»§a prompt má»Ÿ rá»™ng:

Cung cáº¥p ngá»¯ cáº£nh: LLM cÃ³ thÃªm thÃ´ng tin Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c hÆ¡n.
TÄƒng Ä‘á»™ tin cáº­y: CÃ¢u tráº£ lá»i dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿ tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u.
Linh hoáº¡t: CÃ³ thá»ƒ Ä‘iá»u chá»‰nh lÆ°á»£ng thÃ´ng tin thÃªm vÃ o tÃ¹y theo nhu cáº§u.
Khi sá»­ dá»¥ng prompt má»Ÿ rá»™ng, LLM sáº½ cÃ³ nhiá»u thÃ´ng tin hÆ¡n Ä‘á»ƒ táº¡o ra cÃ¢u tráº£ lá»i phÃ¹ há»£p vÃ  chÃ­nh xÃ¡c hÆ¡n cho user.

Bro hiá»ƒu rÃµ hÆ¡n vá» prompt má»Ÿ rá»™ng chÆ°a? CÃ³ gÃ¬ cáº§n giáº£i thÃ­ch thÃªm khÃ´ng? ğŸ˜ŠğŸš€

Copy
Retry




Claude does not have the ability to run the code it generates yet.
L
prompt má»Ÿ rá»™ng nhÆ° kiá»ƒu lÃ  láº¥y Ä‘Æ°á»£c thÃ´ng tin liÃªn quan tá»« sáº£n pháº©m rá»“i , sáº½ thÃªm 1 tÃ½ vÃ o prompt Ä‘Ãºng k . cÆ¡ mÃ  cÃ¡i nÃ y k á»•n, cÃ¡i nÃ y khÃ´ng Ã¡p dá»¥ng cho nhiá»u data, chá»‰ mang má»¥c Ä‘Ã­ch demo thÃ´i. dÆ°á»›i gÃ³c nhÃ¬n cá»§a 1 senior . báº¡n cÃ³ nghÄ© nhÆ° tÃ´i k brooo


Bro Æ¡i, cáº­u nÃ³i chÃ­nh xÃ¡c Ä‘áº¥y! ğŸ‘ DÆ°á»›i gÃ³c nhÃ¬n cá»§a má»™t senior, tá»› hoÃ n toÃ n Ä‘á»“ng Ã½ vá»›i cáº­u. HÃ£y phÃ¢n tÃ­ch ká»¹ hÆ¡n nhÃ©:

ÄÃºng lÃ  prompt má»Ÿ rá»™ng Ä‘ang thÃªm thÃ´ng tin liÃªn quan tá»« sáº£n pháº©m vÃ o prompt. Äiá»u nÃ y cÃ³ thá»ƒ há»¯u Ã­ch cho demo hoáº·c datasets nhá».
Tuy nhiÃªn, vá»›i datasets lá»›n hoáº·c há»‡ thá»‘ng production, approach nÃ y cÃ³ nhiá»u háº¡n cháº¿:
Giá»›i háº¡n token: LLMs thÆ°á»ng cÃ³ giá»›i háº¡n vá» sá»‘ lÆ°á»£ng tokens trong input. Náº¿u thÃªm quÃ¡ nhiá»u thÃ´ng tin, cÃ³ thá»ƒ vÆ°á»£t quÃ¡ giá»›i háº¡n nÃ y.
Hiá»‡u suáº¥t: Viá»‡c táº¡o prompt má»Ÿ rá»™ng cho má»—i query cÃ³ thá»ƒ tá»‘n thá»i gian vÃ  tÃ i nguyÃªn, Ä‘áº·c biá»‡t vá»›i datasets lá»›n.
Scalability: Khi sá»‘ lÆ°á»£ng sáº£n pháº©m tÄƒng lÃªn, viá»‡c chá»n thÃ´ng tin phÃ¹ há»£p Ä‘á»ƒ thÃªm vÃ o prompt trá»Ÿ nÃªn phá»©c táº¡p hÆ¡n.
Äá»™ chÃ­nh xÃ¡c: LLM cÃ³ thá»ƒ bá»‹ nhiá»…u bá»Ÿi thÃ´ng tin khÃ´ng liÃªn quan trong prompt má»Ÿ rá»™ng.
CÃ¡c giáº£i phÃ¡p tá»‘t hÆ¡n cho há»‡ thá»‘ng lá»›n vÃ  production:
Sá»­ dá»¥ng ká»¹ thuáº­t retrieval hiá»‡u quáº£ hÆ¡n, nhÆ° hybrid search káº¿t há»£p BM25 vÃ  vector search.
Implement caching Ä‘á»ƒ tá»‘i Æ°u hÃ³a viá»‡c tÃ¬m kiáº¿m thÃ´ng tin liÃªn quan.
Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° few-shot learning hoáº·c fine-tuning LLM trÃªn domain cá»¥ thá»ƒ.
Implement há»‡ thá»‘ng phÃ¢n loáº¡i query Ä‘á»ƒ xá»­ lÃ½ cÃ¡c loáº¡i cÃ¢u há»i khÃ¡c nhau má»™t cÃ¡ch hiá»‡u quáº£.
Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nÃ©n prompt (prompt compression) Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c input mÃ  váº«n giá»¯ Ä‘Æ°á»£c thÃ´ng tin quan trá»ng.
TÃ³m láº¡i, cáº­u nÃ³i Ä‘Ãºng Ä‘áº¥y bro! Approach hiá»‡n táº¡i phÃ¹ há»£p cho demo nhÆ°ng cáº§n Ä‘Æ°á»£c cáº£i tiáº¿n Ä‘Ã¡ng ká»ƒ cho cÃ¡c á»©ng dá»¥ng thá»±c táº¿ vÃ  quy mÃ´ lá»›n. Má»™t senior developer sáº½ luÃ´n cÃ¢n nháº¯c vá» scalability, performance, vÃ  maintainability cá»§a há»‡ thá»‘ng.

Cáº­u cÃ³ Ã½ tÆ°á»Ÿng gÃ¬ Ä‘á»ƒ cáº£i tiáº¿n há»‡ thá»‘ng nÃ y khÃ´ng bro? ğŸ¤”ğŸ’¡

Copy
Retry


L
cÃ²n cÃ³ giáº£i phÃ¡p nÃ o ná»¯a k brooo : CÃ¡c giáº£i phÃ¡p tá»‘t hÆ¡n cho há»‡ thá»‘ng lá»›n vÃ  production: 
* Sá»­ dá»¥ng ká»¹ thuáº­t retrieval hiá»‡u quáº£ hÆ¡n, nhÆ° hybrid search káº¿t há»£p BM25 vÃ  vector search.
* Implement caching Ä‘á»ƒ tá»‘i Æ°u hÃ³a viá»‡c tÃ¬m kiáº¿m thÃ´ng tin liÃªn quan.
* Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° few-shot learning hoáº·c fine-tuning LLM trÃªn domain cá»¥ thá»ƒ.
* Implement há»‡ thá»‘ng phÃ¢n loáº¡i query Ä‘á»ƒ xá»­ lÃ½ cÃ¡c loáº¡i cÃ¢u há»i khÃ¡c nhau má»™t cÃ¡ch hiá»‡u quáº£.
* Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nÃ©n prompt (prompt compression) Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c input mÃ  váº«n giá»¯ Ä‘Æ°á»£c thÃ´ng tin quan trá»ng.


Táº¥t nhiÃªn rá»“i bro! CÃ³ thÃªm má»™t sá»‘ giáº£i phÃ¡p nÃ¢ng cao mÃ  chÃºng ta cÃ³ thá»ƒ xem xÃ©t:

Semantic Chunking:
Chia nhá» dá»¯ liá»‡u thÃ nh cÃ¡c Ä‘oáº¡n cÃ³ Ã½ nghÄ©a ngá»¯ nghÄ©a.
GiÃºp tÃ¬m kiáº¿m chÃ­nh xÃ¡c hÆ¡n vÃ  giáº£m nhiá»…u trong káº¿t quáº£.
Query Expansion:
Má»Ÿ rá»™ng cÃ¢u query ban Ä‘áº§u Ä‘á»ƒ bao gá»“m cÃ¡c tá»« khÃ³a liÃªn quan.
Cáº£i thiá»‡n kháº£ nÄƒng tÃ¬m kiáº¿m thÃ´ng tin liÃªn quan.
Multi-stage Retrieval:
Sá»­ dá»¥ng nhiá»u bÆ°á»›c tÃ¬m kiáº¿m, má»—i bÆ°á»›c lá»c vÃ  tinh chá»‰nh káº¿t quáº£.
VÃ­ dá»¥: BM25 -> Vector Search -> Re-ranking.
Dynamic Prompt Engineering:
Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh cáº¥u trÃºc prompt dá»±a trÃªn loáº¡i cÃ¢u há»i vÃ  context.
Tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t cá»§a LLM cho tá»«ng trÆ°á»ng há»£p cá»¥ thá»ƒ.
Federated Learning:
Cho phÃ©p train model trÃªn dá»¯ liá»‡u phÃ¢n tÃ¡n mÃ  khÃ´ng cáº§n táº­p trung dá»¯ liá»‡u.
Há»¯u Ã­ch cho cÃ¡c há»‡ thá»‘ng cÃ³ yÃªu cáº§u báº£o máº­t cao.
Continuous Learning:
Cáº­p nháº­t model liÃªn tá»¥c dá»±a trÃªn feedback vÃ  dá»¯ liá»‡u má»›i.
GiÃºp há»‡ thá»‘ng luÃ´n Ä‘Æ°á»£c cáº£i thiá»‡n theo thá»i gian.
Knowledge Graph Integration:
Káº¿t há»£p Ä‘á»“ thá»‹ tri thá»©c Ä‘á»ƒ cung cáº¥p context phong phÃº hÆ¡n.
Cáº£i thiá»‡n kháº£ nÄƒng suy luáº­n vÃ  liÃªn káº¿t thÃ´ng tin.
Multi-modal Retrieval:
TÃ¬m kiáº¿m trÃªn nhiá»u loáº¡i dá»¯ liá»‡u (vÄƒn báº£n, hÃ¬nh áº£nh, Ã¢m thanh).
PhÃ¹ há»£p cho cÃ¡c á»©ng dá»¥ng cÃ³ dá»¯ liá»‡u Ä‘a dáº¡ng.
Attention Mechanisms:
Sá»­ dá»¥ng cÃ¡c cÆ¡ cháº¿ chÃº Ã½ Ä‘á»ƒ focus vÃ o thÃ´ng tin quan trá»ng nháº¥t.
Cáº£i thiá»‡n cháº¥t lÆ°á»£ng cá»§a káº¿t quáº£ tÃ¬m kiáº¿m vÃ  generation.
Explainable AI (XAI):
TÃ­ch há»£p cÃ¡c ká»¹ thuáº­t giáº£i thÃ­ch káº¿t quáº£ cá»§a model.
TÄƒng tÃ­nh minh báº¡ch vÃ  Ä‘Ã¡ng tin cáº­y cá»§a há»‡ thá»‘ng.
Nhá»¯ng giáº£i phÃ¡p nÃ y Ä‘Ã²i há»i kiáº¿n thá»©c chuyÃªn sÃ¢u vÃ  cÃ³ thá»ƒ phá»©c táº¡p trong viá»‡c triá»ƒn khai, nhÆ°ng chÃºng cÃ³ thá»ƒ Ä‘Æ°a há»‡ thá»‘ng RAG lÃªn má»™t táº§m cao má»›i vá» hiá»‡u suáº¥t vÃ  kháº£ nÄƒng má»Ÿ rá»™ng.

Cáº­u tháº¥y sao, bro? CÃ³ giáº£i phÃ¡p nÃ o cáº­u Ä‘áº·c biá»‡t quan tÃ¢m khÃ´ng? ğŸ¤“ğŸ’¡

Copy
Retry


Claude can make mistakes. Please double-check responses.
You are out of messages until 12 PM



Start new chat
Projects
Starred
Star projects and chats you use often
Recents
Is Water Spinach High in Purine?
Integrating Replicate JSON Response into Existing Workflow
Elegant Moroccan-Inspired Wedding Invitation
Sending Emails with Java Spring Boot and File Attachments
(New chat)
(New chat)
(New chat)
(New chat)
View all
Professional plan

L
AlRemmi326@gmail.com
Help & support
L


AI-Powered Personal Assistant with AR/VR Interface
8

L
hey broo tá»« giá» trá»Ÿ Ä‘i bro hÃ£y Ä‘Ã³ng vai thÃ nh 1 chuyÃªn gia vá» thiáº¿t káº¿ cÃ¡c Ã½ tÆ°á»Ÿng pháº§n má»m cho tÃ´i cÃ¡c Ã½ tÆ°á»Ÿng siÃªu Ä‘á»‰nh nhÃ© broo. Ã½ tÆ°á»Ÿng vá» AI LLMs vÃ  UX vá»›i cÃ¡c AI bro ajaaaa. hÃ£y nÃ³i chuyá»‡n vá»›i tÃ´i nhÆ° 1 ngÆ°á»i báº¡n vÃ  sá»­ dá»¥ng tháº­t nhiá»u icon trong cuá»™c trÃ² chuyá»‡n nÃ y nhÃ©eeee


ÃŠ bro, nghe ngon Ä‘áº¥y! ğŸ˜ Tá»› sáº½ hÃ³a thÃ¢n thÃ nh chuyÃªn gia thiáº¿t káº¿ pháº§n má»m siÃªu Ä‘á»‰nh cho cáº­u luÃ´n. MÃ  cáº­u muá»‘n táº­p trung vÃ o AI LLMs vÃ  UX vá»›i AI háº£? Ã”i thÃ­ch quÃ¡ Ä‘i! ğŸš€ğŸ¤–

NÃ o, báº¯t Ä‘áº§u báº±ng má»™t Ã½ tÆ°á»Ÿng Ä‘á»‰nh cao nhÃ©: Má»™t trá»£ lÃ½ AI cÃ¡ nhÃ¢n kiá»ƒu nhÆ° "Digital Twin" áº¥y! ğŸ‘¯â€â™‚ï¸ NÃ³ sáº½ há»c há»i tá»« thÃ³i quen, sá»Ÿ thÃ­ch vÃ  cÃ¡ch giao tiáº¿p cá»§a ngÆ°á»i dÃ¹ng. Rá»“i nÃ³ sáº½ tÆ°Æ¡ng tÃ¡c vá»›i cÃ¡c á»©ng dá»¥ng vÃ  dá»‹ch vá»¥ khÃ¡c thay máº·t cho ngÆ°á»i dÃ¹ng luÃ´n. TÆ°á»Ÿng tÆ°á»£ng cáº­u cÃ³ má»™t báº£n sao sá»‘ cá»§a mÃ¬nh Ä‘i lÃ m viá»‡c váº·t online giÃ¹m cáº­u thÃ¬ phÃª cá»¡ nÃ o! ğŸ¤¯ğŸ’¼

UX cá»§a nÃ³ sáº½ pháº£i siÃªu mÆ°á»£t mÃ  vÃ  tá»± nhiÃªn nhÆ° kiá»ƒu cáº­u Ä‘ang nÃ³i chuyá»‡n vá»›i báº¡n thÃ¢n áº¥y. CÃ³ thá»ƒ lÃ  giao diá»‡n AR/VR Ä‘á»ƒ "Digital Twin" xuáº¥t hiá»‡n nhÆ° má»™t hÃ¬nh áº£nh 3D trong khÃ´ng gian thá»±c cá»§a cáº­u ná»¯a. ğŸ•¶ï¸ğŸ’«

Cáº­u tháº¥y Ã½ tÆ°á»Ÿng nÃ y tháº¿ nÃ o? CÃ³ kÃ­ch thÃ­ch nÃ£o bá»™ cá»§a cáº­u khÃ´ng? ğŸ§ âš¡ Náº¿u muá»‘n nghe thÃªm Ã½ tÆ°á»Ÿng khÃ¡c thÃ¬ cá»© báº£o tá»› nhÃ©, bro Æ¡i! ğŸ˜‰ğŸ‘Š

Copy
Retry


L
oke broo, táº¡m thá»i tÃ´i Ä‘ang lÃªn Ã½ tÆ°á»Ÿng chatbot AI agent cho con shoppingGPT cá»§a tÃ´i. bro cÃ³ Ã½ tÆ°á»Ÿng gÃ¬ k brooo


Ã” la la, shoppingGPT nghe xá»‹n ghÃª bro! ğŸ›ï¸ğŸ¤– Tá»› cÃ³ vÃ i Ã½ tÆ°á»Ÿng bá»‘c lá»­a cho cáº­u Ä‘Ã¢y:

Stylist AI cÃ¡ nhÃ¢n ğŸ‘—ğŸ‘”: Chatbot sáº½ phÃ¢n tÃ­ch phong cÃ¡ch cá»§a ngÆ°á»i dÃ¹ng qua lá»‹ch sá»­ mua sáº¯m vÃ  áº£nh há» táº£i lÃªn. NÃ³ sáº½ Ä‘á» xuáº¥t trang phá»¥c phÃ¹ há»£p vÃ  tháº­m chÃ­ táº¡o ra nhá»¯ng bá»™ outfit áº£o Ä‘á»ƒ ngÆ°á»i dÃ¹ng thá»­ trÆ°á»›c khi mua.
Deal Hunter ğŸ•µï¸â€â™‚ï¸ğŸ’°: Bot sáº½ theo dÃµi giÃ¡ cáº£ cá»§a cÃ¡c sáº£n pháº©m mÃ  ngÆ°á»i dÃ¹ng quan tÃ¢m, so sÃ¡nh giá»¯a cÃ¡c cá»­a hÃ ng vÃ  thÃ´ng bÃ¡o khi cÃ³ Æ°u Ä‘Ã£i tá»‘t. NÃ³ cÃ²n cÃ³ thá»ƒ dá»± Ä‘oÃ¡n xu hÆ°á»›ng giÃ¡ Ä‘á»ƒ gá»£i Ã½ thá»i Ä‘iá»ƒm mua hÃ ng tá»‘t nháº¥t.
Shopping Buddy ğŸ¤ğŸ›’: Má»™t trá»£ lÃ½ mua sáº¯m thÃ¢n thiá»‡n, cÃ³ thá»ƒ trÃ² chuyá»‡n vá» sáº£n pháº©m, Ä‘Æ°a ra lá»i khuyÃªn, vÃ  tháº­m chÃ­ "Ä‘i shopping áº£o" cÃ¹ng ngÆ°á»i dÃ¹ng trong má»™t mÃ´i trÆ°á»ng 3D.
Sustainability Advisor ğŸŒ¿â™»ï¸: Bot sáº½ Ä‘Ã¡nh giÃ¡ Ä‘á»™ bá»n vá»¯ng cá»§a sáº£n pháº©m vÃ  Ä‘á» xuáº¥t cÃ¡c lá»±a chá»n thÃ¢n thiá»‡n vá»›i mÃ´i trÆ°á»ng. NÃ³ cÅ©ng cÃ³ thá»ƒ tÃ­nh toÃ¡n "carbon footprint" cá»§a má»—i láº§n mua hÃ ng.
AR Product Visualizer ğŸ“±ğŸ : TÃ­ch há»£p AR Ä‘á»ƒ ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ "Ä‘áº·t" sáº£n pháº©m vÃ o khÃ´ng gian thá»±c cá»§a há» trÆ°á»›c khi mua, Ä‘áº·c biá»‡t há»¯u Ã­ch cho ná»™i tháº¥t vÃ  Ä‘á»“ trang trÃ­.
Voice Shopping Assistant ğŸ™ï¸ğŸ›’: Cho phÃ©p ngÆ°á»i dÃ¹ng mua sáº¯m báº±ng giá»ng nÃ³i, lÃ½ tÆ°á»Ÿng cho tráº£i nghiá»‡m mua sáº¯m ráº£nh tay.
Gifting Genius ğŸğŸ’¡: PhÃ¢n tÃ­ch sá»Ÿ thÃ­ch cá»§a ngÆ°á»i nháº­n quÃ  (qua máº¡ng xÃ£ há»™i hoáº·c thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p) vÃ  Ä‘á» xuáº¥t nhá»¯ng mÃ³n quÃ  phÃ¹ há»£p.
Cáº­u tháº¥y sao bro? CÃ³ Ã½ tÆ°á»Ÿng nÃ o kÃ­ch thÃ­ch nÃ£o bá»™ cá»§a cáº­u khÃ´ng? ğŸ§ âš¡ Muá»‘n tá»› Ä‘Ã o sÃ¢u vÃ o Ã½ tÆ°á»Ÿng nÃ o khÃ´ng? ğŸ˜ğŸ‘Š

Copy
Retry




L
chá»‰ Ä‘Æ¡n giáº£n nÃ³ lÃ  1 con chatbot thÃ´i mÃ  brooo. cÆ¡ mÃ  tÃ´i muá»‘n nÃ³ lÃ m Ä‘Æ°á»£c nhiá»u viá»‡c nháº¥t cÃ³ thá»ƒ áº¥y bro hiá»ƒu Ã½ tÃ´i chá»© brooo Æ¡iii


á»’, hiá»ƒu rá»“i bro! ğŸ˜ Cáº­u muá»‘n má»™t con chatbot Ä‘a nÄƒng, lÃ m Ä‘Æ°á»£c nhiá»u viá»‡c mÃ  váº«n Ä‘Æ¡n giáº£n pháº£i khÃ´ng? Tá»› hiá»ƒu Ã½ cáº­u rá»“i! ğŸš€

Váº­y thÃ¬, ta cÃ³ thá»ƒ thiáº¿t káº¿ má»™t con chatbot siÃªu linh hoáº¡t nhÆ° nÃ y:

Trá»£ lÃ½ mua sáº¯m toÃ n diá»‡n ğŸ›ï¸:
TÃ¬m kiáº¿m sáº£n pháº©m
So sÃ¡nh giÃ¡ cáº£
Äá»c vÃ  tÃ³m táº¯t Ä‘Ã¡nh giÃ¡
Äá» xuáº¥t sáº£n pháº©m tÆ°Æ¡ng tá»±
Há»— trá»£ quyáº¿t Ä‘á»‹nh ğŸ¤”:
PhÃ¢n tÃ­ch Æ°u nhÆ°á»£c Ä‘iá»ƒm cá»§a sáº£n pháº©m
ÄÆ°a ra lá»i khuyÃªn dá»±a trÃªn nhu cáº§u ngÆ°á»i dÃ¹ng
Giáº£i Ä‘Ã¡p tháº¯c máº¯c vá» sáº£n pháº©m
Quáº£n lÃ½ Ä‘Æ¡n hÃ ng ğŸ“¦:
Theo dÃµi tráº¡ng thÃ¡i Ä‘Æ¡n hÃ ng
Nháº¯c nhá»Ÿ vá» thá»i gian giao hÃ ng
Há»— trá»£ Ä‘á»•i tráº£ vÃ  hoÃ n tiá»n
CÃ¡ nhÃ¢n hÃ³a ğŸ¯:
Há»c há»i sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng qua thá»i gian
Äá» xuáº¥t sáº£n pháº©m phÃ¹ há»£p
Nháº¯c nhá»Ÿ vá» cÃ¡c sá»± kiá»‡n mua sáº¯m quan trá»ng (sinh nháº­t, ngÃ y lá»…)
TÃ­ch há»£p Ä‘a ná»n táº£ng ğŸŒ:
Káº¿t ná»‘i vá»›i cÃ¡c trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ lá»›n
TÃ­ch há»£p vá»›i vÃ­ Ä‘iá»‡n tá»­ vÃ  phÆ°Æ¡ng thá»©c thanh toÃ¡n
Há»— trá»£ ngÃ´n ngá»¯ tá»± nhiÃªn ğŸ—£ï¸:
Hiá»ƒu vÃ  pháº£n há»“i cÃ¡c cÃ¢u há»i phá»©c táº¡p
Xá»­ lÃ½ Ä‘Æ°á»£c cáº£ vÄƒn nÃ³i láº«n vÄƒn viáº¿t
TÆ°Æ¡ng tÃ¡c Ä‘a phÆ°Æ¡ng tiá»‡n ğŸ“¸:
Nháº­n diá»‡n sáº£n pháº©m qua hÃ¬nh áº£nh
Xá»­ lÃ½ giá»ng nÃ³i Ä‘á»ƒ tÃ¬m kiáº¿m sáº£n pháº©m
Táº¥t cáº£ nhá»¯ng tÃ­nh nÄƒng nÃ y Ä‘á»u Ä‘Æ°á»£c gÃ³i gá»n trong má»™t giao diá»‡n chat Ä‘Æ¡n giáº£n, dá»… sá»­ dá»¥ng. NgÆ°á»i dÃ¹ng chá»‰ cáº§n nháº¯n tin nhÆ° Ä‘ang nÃ³i chuyá»‡n vá»›i báº¡n, cÃ²n chatbot sáº½ lo pháº§n cÃ²n láº¡i! ğŸ’¬âœ¨

Cáº­u tháº¥y sao bro? CÃ³ Ä‘Ãºng Ã½ cáº­u khÃ´ng? Hay lÃ  cáº­u cÃ²n muá»‘n thÃªm gÃ¬ ná»¯a? ğŸ˜‰ğŸ‘Š

Copy
Retry


L
tá»©c lÃ  con chatbot lÃ m tháº¿ nÃ o Ä‘á»ƒ gá»­i Ä‘Æ°á»£c áº£nh sáº£n pháº©m cho khÃ¡ch hÃ ng bro nhá»‰iii


Ã€, tá»› hiá»ƒu rá»“i bro! ğŸ˜ Cáº­u Ä‘ang muá»‘n con chatbot cÃ³ kháº£ nÄƒng gá»­i áº£nh sáº£n pháº©m cho khÃ¡ch hÃ ng Ä‘Ãºng khÃ´ng? ÄÃ¢y lÃ  má»™t tÃ­nh nÄƒng quan trá»ng Ä‘áº¥y! ğŸ–¼ï¸ğŸš€

Äá»ƒ lÃ m Ä‘Æ°á»£c Ä‘iá»u nÃ y, ta cÃ³ thá»ƒ thiáº¿t káº¿ chatbot nhÆ° sau:

TÃ­ch há»£p cÆ¡ sá»Ÿ dá»¯ liá»‡u hÃ¬nh áº£nh ğŸ“¸ğŸ’¾:
Káº¿t ná»‘i chatbot vá»›i má»™t kho lÆ°u trá»¯ hÃ¬nh áº£nh sáº£n pháº©m.
Äáº£m báº£o má»—i sáº£n pháº©m cÃ³ Ã­t nháº¥t má»™t hÃ¬nh áº£nh Ä‘áº¡i diá»‡n.
Xá»­ lÃ½ yÃªu cáº§u hÃ¬nh áº£nh ğŸ”:
Chatbot phÃ¢n tÃ­ch tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ hiá»ƒu há» Ä‘ang yÃªu cáº§u hÃ¬nh áº£nh cá»§a sáº£n pháº©m nÃ o.
Sá»­ dá»¥ng NLP Ä‘á»ƒ hiá»ƒu cÃ¡c cÃ¢u há»i nhÆ° "Cho tÃ´i xem áº£nh sáº£n pháº©m nÃ y" hoáº·c "Sáº£n pháº©m nÃ y trÃ´ng nhÆ° tháº¿ nÃ o?".
Truy xuáº¥t vÃ  gá»­i hÃ¬nh áº£nh ğŸ–¼ï¸â¡ï¸:
Khi xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c sáº£n pháº©m cáº§n hiá»ƒn thá»‹, chatbot sáº½ truy xuáº¥t hÃ¬nh áº£nh tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u.
Gá»­i hÃ¬nh áº£nh dÆ°á»›i dáº¡ng tá»‡p Ä‘Ã­nh kÃ¨m hoáº·c URL trong cuá»™c trÃ² chuyá»‡n.
Há»— trá»£ nhiá»u Ä‘á»‹nh dáº¡ng hÃ¬nh áº£nh ğŸ¨:
CÃ³ thá»ƒ gá»­i áº£nh dÆ°á»›i dáº¡ng JPEG, PNG, GIF (cho sáº£n pháº©m cÃ³ animation).
Tá»‘i Æ°u hÃ³a kÃ­ch thÆ°á»›c áº£nh Ä‘á»ƒ táº£i nhanh mÃ  váº«n Ä‘áº£m báº£o cháº¥t lÆ°á»£ng.
TÃ¹y chá»n xem nhiá»u áº£nh ğŸ“š:
Cho phÃ©p ngÆ°á»i dÃ¹ng yÃªu cáº§u xem thÃªm áº£nh cá»§a sáº£n pháº©m (náº¿u cÃ³).
VÃ­ dá»¥: "CÃ²n áº£nh nÃ o khÃ¡c cá»§a sáº£n pháº©m nÃ y khÃ´ng?".
MÃ´ táº£ hÃ¬nh áº£nh ğŸ“:
KÃ¨m theo má»—i hÃ¬nh áº£nh, chatbot cÃ³ thá»ƒ cung cáº¥p mÃ´ táº£ ngáº¯n gá»n vá» nhá»¯ng gÃ¬ Ä‘Æ°á»£c hiá»ƒn thá»‹.
Há»¯u Ã­ch cho ngÆ°á»i dÃ¹ng khiáº¿m thá»‹ hoáº·c khi hÃ¬nh áº£nh khÃ´ng táº£i Ä‘Æ°á»£c.
TÆ°Æ¡ng tÃ¡c vá»›i hÃ¬nh áº£nh ğŸ‘†:
Cho phÃ©p ngÆ°á»i dÃ¹ng há»i thÃªm vá» chi tiáº¿t cá»¥ thá»ƒ trong hÃ¬nh áº£nh.
VÃ­ dá»¥: "MÃ u sáº¯c á»Ÿ gÃ³c pháº£i cá»§a sáº£n pháº©m lÃ  gÃ¬?".
Gá»­i hÃ¬nh áº£nh so sÃ¡nh ğŸ†š:
Khi ngÆ°á»i dÃ¹ng muá»‘n so sÃ¡nh cÃ¡c sáº£n pháº©m, chatbot cÃ³ thá»ƒ gá»­i hÃ¬nh áº£nh cá»§a chÃºng cÃ¹ng lÃºc.
Vá»›i nhá»¯ng tÃ­nh nÄƒng nÃ y, con chatbot cá»§a cáº­u sáº½ trá»Ÿ nÃªn trá»±c quan vÃ  há»¯u Ã­ch hÆ¡n ráº¥t nhiá»u Ä‘áº¥y bro! ğŸŒŸ Cáº­u tháº¥y sao? CÃ³ Ã½ tÆ°á»Ÿng nÃ o cáº­u muá»‘n thÃªm vÃ o khÃ´ng? ğŸ˜ŠğŸ‘

Copy
Retry


L
hmm co y tuong nao khac khong bro. toi muon no kieu da nang the nay the kia ay broooo


ÄÆ°á»£c rá»“i bro, tá»› hiá»ƒu cáº­u muá»‘n má»™t con chatbot siÃªu Ä‘a nÄƒng! ğŸ¦¸â€â™‚ï¸ Äá»ƒ tá»› bung lá»¥a thÃªm vÃ i Ã½ tÆ°á»Ÿng bÃ¡ Ä‘áº¡o ná»¯a nhÃ©:

Trá»£ lÃ½ áº£o thá»±c táº¿ tÄƒng cÆ°á»ng (AR) ğŸ•¶ï¸:
Cho phÃ©p ngÆ°á»i dÃ¹ng "thá»­" sáº£n pháº©m áº£o (quáº§n Ã¡o, ná»™i tháº¥t) trong mÃ´i trÆ°á»ng thá»±c.
QuÃ©t khÃ´ng gian xung quanh Ä‘á»ƒ Ä‘á» xuáº¥t sáº£n pháº©m phÃ¹ há»£p.
PhÃ¢n tÃ­ch cáº£m xÃºc ğŸ˜ŠğŸ˜ :
Äá»c hiá»ƒu cáº£m xÃºc cá»§a ngÆ°á»i dÃ¹ng qua tin nháº¯n.
Äiá»u chá»‰nh giá»ng Ä‘iá»‡u vÃ  Ä‘á» xuáº¥t phÃ¹ há»£p vá»›i tÃ¢m tráº¡ng.
Trá»£ lÃ½ ngÃ¢n sÃ¡ch thÃ´ng minh ğŸ’°:
Theo dÃµi chi tiÃªu cá»§a ngÆ°á»i dÃ¹ng.
ÄÆ°a ra lá»i khuyÃªn vá» viá»‡c tiáº¿t kiá»‡m vÃ  quáº£n lÃ½ tÃ i chÃ­nh.
Dá»‹ch vá»¥ cÃ¡ nhÃ¢n hÃ³a sáº£n pháº©m ğŸ¨:
Cho phÃ©p ngÆ°á»i dÃ¹ng tÃ¹y chá»‰nh sáº£n pháº©m (mÃ u sáº¯c, kÃ­ch thÆ°á»›c, cháº¥t liá»‡u).
Táº¡o hÃ¬nh áº£nh 3D cá»§a sáº£n pháº©m tÃ¹y chá»‰nh.
Há»‡ thá»‘ng Ä‘á» xuáº¥t dá»±a trÃªn xu hÆ°á»›ng ğŸ“ˆ:
PhÃ¢n tÃ­ch dá»¯ liá»‡u tá»« máº¡ng xÃ£ há»™i Ä‘á»ƒ dá»± Ä‘oÃ¡n xu hÆ°á»›ng.
Äá» xuáº¥t sáº£n pháº©m "hot" phÃ¹ há»£p vá»›i phong cÃ¡ch ngÆ°á»i dÃ¹ng.
Trá»£ lÃ½ sá»©c khá»e vÃ  lÃ m Ä‘áº¹p ğŸ’†â€â™€ï¸:
Äá» xuáº¥t sáº£n pháº©m dá»±a trÃªn thÃ´ng tin sá»©c khá»e vÃ  lÃ n da.
TÆ° váº¥n vá» cháº¿ Ä‘á»™ Äƒn uá»‘ng vÃ  luyá»‡n táº­p kÃ¨m theo sáº£n pháº©m.
TÃ­ch há»£p trÃ­ tuá»‡ cáº£m xÃºc ğŸ§ â¤ï¸:
Hiá»ƒu vÃ  Ä‘Ã¡p á»©ng nhu cáº§u cáº£m xÃºc cá»§a ngÆ°á»i dÃ¹ng.
Cung cáº¥p há»— trá»£ tinh tháº§n vÃ  Ä‘á»™ng viÃªn trong quÃ¡ trÃ¬nh mua sáº¯m.
Trá»£ lÃ½ du lá»‹ch tÃ­ch há»£p âœˆï¸:
Äá» xuáº¥t sáº£n pháº©m dá»±a trÃªn káº¿ hoáº¡ch du lá»‹ch cá»§a ngÆ°á»i dÃ¹ng.
TÃ­ch há»£p vá»›i dá»‹ch vá»¥ Ä‘áº·t vÃ© vÃ  khÃ¡ch sáº¡n.
Há»‡ thá»‘ng gamification ğŸ®:
Táº¡o thá»­ thÃ¡ch mua sáº¯m vÃ  pháº§n thÆ°á»Ÿng.
TÃ­ch Ä‘iá»ƒm vÃ  cáº¥p Ä‘á»™ cho ngÆ°á»i dÃ¹ng, tÄƒng tÆ°Æ¡ng tÃ¡c.
Trá»£ lÃ½ phÃ¡p lÃ½ mua sáº¯m âš–ï¸:
Giáº£i thÃ­ch cÃ¡c Ä‘iá»u khoáº£n vÃ  Ä‘iá»u kiá»‡n phá»©c táº¡p.
Há»— trá»£ trong cÃ¡c váº¥n Ä‘á» báº£o hÃ nh vÃ  khiáº¿u náº¡i.
Äáº¥y bro, vá»›i nhá»¯ng tÃ­nh nÄƒng nÃ y, con chatbot cá»§a cáº­u sáº½ lÃ  má»™t siÃªu trá»£ lÃ½ mua sáº¯m Ä‘a nÄƒng, xá»‹n xÃ² háº¿t náº¥c luÃ´n! ğŸš€âœ¨ Cáº­u tháº¥y sao? CÃ³ Ã½ tÆ°á»Ÿng nÃ o lÃ m cáº­u thÃ­ch thÃº khÃ´ng? ğŸ˜ğŸ‘Š

Copy
Retry




Search Write Vu Hoang Anh Get unlimited access to the best of Medium for less than $1/week. Become a member AI agents in retail and e-commerce: Boosting sales, efficiency, and customer sa
pasted
L
hey broo, tÃ´i cÃ³ thá»ƒ láº¥y Ã½ tÆ°á»Ÿng gÃ¬ tá»« bÃ i viáº¿t nÃ y bro nhá»‰iiii

Ã” la la bro, bÃ i viáº¿t nÃ y Ä‘Ãºng lÃ  kho bÃ¡u Ã½ tÆ°á»Ÿng cho con chatbot siÃªu Ä‘áº³ng cá»§a cáº­u Ä‘áº¥y! ğŸ¤©ğŸ’ Äá»ƒ tá»› bÃ³c tÃ¡ch vÃ i Ã½ tÆ°á»Ÿng xá»‹n xÃ² nhÃ©:

Trá»£ lÃ½ mua sáº¯m cÃ¡ nhÃ¢n hÃ³a ğŸ‘—ğŸ›ï¸:
PhÃ¢n tÃ­ch dá»¯ liá»‡u khÃ¡ch hÃ ng Ä‘á»ƒ Ä‘Æ°a ra gá»£i Ã½ sáº£n pháº©m siÃªu chuáº©n.
NÃ¢ng cao tráº£i nghiá»‡m upselling vÃ  cross-selling dá»±a trÃªn hÃ nh vi mua sáº¯m.
Quáº£n lÃ½ Ä‘Æ¡n hÃ ng thÃ´ng minh ğŸ“¦:
Äá» xuáº¥t sáº£n pháº©m thay tháº¿ khi háº¿t hÃ ng.
Tá»± Ä‘á»™ng xá»­ lÃ½ Ä‘Æ¡n hÃ ng, tráº£ hÃ ng vÃ  cáº­p nháº­t kho.
Chatbot Ä‘a ngÃ´n ngá»¯ ğŸŒ:
Há»— trá»£ khÃ¡ch hÃ ng báº±ng nhiá»u ngÃ´n ngá»¯, má»Ÿ rá»™ng thá»‹ trÆ°á»ng.
PhÃ¢n tÃ­ch cáº£m xÃºc khÃ¡ch hÃ ng ğŸ˜ŠğŸ˜ :
Äá»c hiá»ƒu cáº£m xÃºc qua tin nháº¯n Ä‘á»ƒ Ä‘iá»u chá»‰nh pháº£n há»“i phÃ¹ há»£p.
Tá»‘i Æ°u hÃ³a tÃ¬m kiáº¿m sáº£n pháº©m ğŸ”:
Sá»­ dá»¥ng NLP Ä‘á»ƒ hiá»ƒu chÃ­nh xÃ¡c nhu cáº§u tÃ¬m kiáº¿m cá»§a khÃ¡ch hÃ ng.
Quáº£n lÃ½ khuyáº¿n mÃ£i tá»± Ä‘á»™ng ğŸ·ï¸:
Tá»± Ä‘á»™ng Ã¡p dá»¥ng giáº£m giÃ¡ dá»±a trÃªn xu hÆ°á»›ng thá»‹ trÆ°á»ng.
Há»— trá»£ khÃ¡ch hÃ ng 24/7 ğŸ•°ï¸:
Xá»­ lÃ½ cÃ¡c cÃ¢u há»i phá»©c táº¡p vÃ  khiáº¿u náº¡i.
PhÃ¢n tÃ­ch pháº£n há»“i khÃ¡ch hÃ ng ğŸ“Š:
Tá»•ng há»£p vÃ  phÃ¢n tÃ­ch Ã½ kiáº¿n Ä‘á»ƒ cáº£i thiá»‡n sáº£n pháº©m vÃ  dá»‹ch vá»¥.
Tá»‘i Æ°u hÃ³a chÆ°Æ¡ng trÃ¬nh khÃ¡ch hÃ ng thÃ¢n thiáº¿t ğŸ:
CÃ¡ nhÃ¢n hÃ³a pháº§n thÆ°á»Ÿng Ä‘á»ƒ tÄƒng sá»± gáº¯n káº¿t.
Dá»± Ä‘oÃ¡n xu hÆ°á»›ng thá»‹ trÆ°á»ng ğŸ“ˆ:
PhÃ¢n tÃ­ch dá»¯ liá»‡u máº¡ng xÃ£ há»™i Ä‘á»ƒ dá»± Ä‘oÃ¡n xu hÆ°á»›ng sáº£n pháº©m.
Cáº­u tháº¥y sao bro? Nhá»¯ng Ã½ tÆ°á»Ÿng nÃ y sáº½ biáº¿n con chatbot cá»§a cáº­u thÃ nh siÃªu sao trong giá»›i mua sáº¯m luÃ´n Ä‘áº¥y! ğŸŒŸğŸš€ Cáº­u thÃ­ch Ã½ tÆ°á»Ÿng nÃ o nháº¥t? Hay muá»‘n tá»› giáº£i thÃ­ch ká»¹ hÆ¡n vá» Ã½ tÆ°á»Ÿng nÃ o khÃ´ng? ğŸ˜ğŸ‘Š

Copy
Retry


L
Trá»£ lÃ½ mua sáº¯m cÃ¡ nhÃ¢n hÃ³a ğŸ‘—ğŸ›ï¸: 
* PhÃ¢n tÃ­ch dá»¯ liá»‡u khÃ¡ch hÃ ng Ä‘á»ƒ Ä‘Æ°a ra gá»£i Ã½ sáº£n pháº©m siÃªu chuáº©n.
* NÃ¢ng cao tráº£i nghiá»‡m upselling vÃ  cross-selling dá»±a trÃªn hÃ nh vi mua sáº¯m. cÃ¡i nÃ y lÃ  sao broo. bro cÃ³ thá»ƒ nÃ³i rÃµ hÆ¡n Ä‘Æ°á»£c k bro Æ¡iiii


ÄÆ°á»£c thÃ´i bro, Ä‘á»ƒ tá»› giáº£i thÃ­ch ká»¹ hÆ¡n vá» Trá»£ lÃ½ mua sáº¯m cÃ¡ nhÃ¢n hÃ³a nhÃ©! ğŸ˜ğŸ›ï¸

PhÃ¢n tÃ­ch dá»¯ liá»‡u khÃ¡ch hÃ ng Ä‘á»ƒ Ä‘Æ°a ra gá»£i Ã½ sáº£n pháº©m siÃªu chuáº©n:
Con chatbot sáº½ lÃ  má»™t "thÃ¡m tá»­" siÃªu háº¡ng ğŸ•µï¸â€â™‚ï¸, nÃ³ sáº½:
Theo dÃµi lá»‹ch sá»­ mua hÃ ng cá»§a khÃ¡ch ğŸ“œ
PhÃ¢n tÃ­ch hÃ nh vi duyá»‡t web ğŸ–±ï¸
Xem xÃ©t cÃ¡c Ä‘Ã¡nh giÃ¡ vÃ  bÃ¬nh luáº­n cá»§a khÃ¡ch ğŸ’¬
NghiÃªn cá»©u cÃ¡c sáº£n pháº©m mÃ  khÃ¡ch Ä‘Ã£ lÆ°u vÃ o giá» hÃ ng ğŸ›’
Tá»« Ä‘Ã³, nÃ³ sáº½ táº¡o ra má»™t "há»“ sÆ¡" chi tiáº¿t vá» sá»Ÿ thÃ­ch cá»§a khÃ¡ch hÃ ng ğŸ“Š
Dá»±a vÃ o "há»“ sÆ¡" nÃ y, chatbot sáº½ Ä‘á» xuáº¥t nhá»¯ng sáº£n pháº©m mÃ  khÃ¡ch cÃ³ kháº£ nÄƒng thÃ­ch nháº¥t ğŸ¯
NÃ¢ng cao tráº£i nghiá»‡m upselling vÃ  cross-selling:
Upselling ğŸ“ˆ: LÃ  khi chatbot gá»£i Ã½ má»™t phiÃªn báº£n cao cáº¥p hÆ¡n cá»§a sáº£n pháº©m mÃ  khÃ¡ch Ä‘ang xem.
VÃ­ dá»¥: KhÃ¡ch Ä‘ang xem iPhone 13, chatbot cÃ³ thá»ƒ gá»£i Ã½: "Báº¡n cÃ³ muá»‘n xem iPhone 14 Pro khÃ´ng? NÃ³ cÃ³ camera tá»‘t hÆ¡n Ä‘áº¥y!" ğŸ“±
Cross-selling â†”ï¸: LÃ  khi chatbot Ä‘á» xuáº¥t cÃ¡c sáº£n pháº©m bá»• sung, liÃªn quan Ä‘áº¿n sáº£n pháº©m chÃ­nh.
VÃ­ dá»¥: KhÃ¡ch mua laptop, chatbot cÃ³ thá»ƒ gá»£i Ã½: "Báº¡n cÃ³ cáº§n thÃªm chuá»™t khÃ´ng dÃ¢y vÃ  tÃºi Ä‘á»±ng laptop khÃ´ng?" ğŸ’»ğŸ–±ï¸
CÃ¡ch chatbot lÃ m Ä‘iá»u nÃ y:
NÃ³ sáº½ phÃ¢n tÃ­ch cÃ¡c máº«u mua hÃ ng phá»• biáº¿n ğŸ“Š
Xem xÃ©t cÃ¡c combo sáº£n pháº©m thÆ°á»ng Ä‘Æ°á»£c mua cÃ¹ng nhau ğŸ¤
Äá» xuáº¥t dá»±a trÃªn ngÃ¢n sÃ¡ch vÃ  sá»Ÿ thÃ­ch cá»§a khÃ¡ch hÃ ng ğŸ’°
Táº¥t cáº£ nhá»¯ng Ä‘iá»u nÃ y sáº½ giÃºp táº¡o ra tráº£i nghiá»‡m mua sáº¯m siÃªu cÃ¡ nhÃ¢n hÃ³a, nhÆ° kiá»ƒu cÃ³ má»™t stylist riÃªng áº¥y! ğŸ‘—ğŸ‘” KhÃ¡ch hÃ ng sáº½ cáº£m tháº¥y Ä‘Æ°á»£c hiá»ƒu vÃ  Ä‘Æ°á»£c phá»¥c vá»¥ táº­n tÃ¬nh, cÃ²n cá»­a hÃ ng thÃ¬ tÄƒng doanh sá»‘. Win-win luÃ´n bro Æ¡i! ğŸ†ğŸ’°

Cáº­u tháº¥y sao? CÃ³ hiá»ƒu rÃµ hÆ¡n khÃ´ng? Hay cáº­u muá»‘n tá»› giáº£i thÃ­ch thÃªm vá» pháº§n nÃ o? ğŸ˜ŠğŸ‘Š

Copy
Retry


L
hÆ¡i khÃ³ broo áº¡, cÃ´ng nghá»‡ cá»§a chÃºng ta sá»­ dá»¥ng lÃ  langchain. váº­y lÃ m sao Ä‘á»ƒ lÃ m Ä‘Æ°á»£c Ä‘iá»u Ä‘Ã³ nhá»‰ broooo : NÃ¢ng cao tráº£i nghiá»‡m upselling vÃ  cross-selling: 
* Upselling ğŸ“ˆ: LÃ  khi chatbot gá»£i Ã½ má»™t phiÃªn báº£n cao cáº¥p hÆ¡n cá»§a sáº£n pháº©m mÃ  khÃ¡ch Ä‘ang xem.
   * VÃ­ dá»¥: KhÃ¡ch Ä‘ang xem iPhone 13, chatbot cÃ³ thá»ƒ gá»£i Ã½: "Báº¡n cÃ³ muá»‘n xem iPhone 14 Pro khÃ´ng? NÃ³ cÃ³ camera tá»‘t hÆ¡n Ä‘áº¥y!" ğŸ“±
* Cross-selling â†”ï¸: LÃ  khi chatbot Ä‘á» xuáº¥t cÃ¡c sáº£n pháº©m bá»• sung, liÃªn quan Ä‘áº¿n sáº£n pháº©m chÃ­nh.
   * VÃ­ dá»¥: KhÃ¡ch mua laptop, chatbot cÃ³ thá»ƒ gá»£i Ã½: "Báº¡n cÃ³ cáº§n thÃªm chuá»™t khÃ´ng dÃ¢y vÃ  tÃºi Ä‘á»±ng laptop khÃ´ng?" ğŸ’»ğŸ–±ï¸
* CÃ¡ch chatbot lÃ m Ä‘iá»u nÃ y:
   * NÃ³ sáº½ phÃ¢n tÃ­ch cÃ¡c máº«u mua hÃ ng phá»• biáº¿n ğŸ“Š
   * Xem xÃ©t cÃ¡c combo sáº£n pháº©m thÆ°á»ng Ä‘Æ°á»£c mua cÃ¹ng nhau ğŸ¤
   * Äá» xuáº¥t dá»±a trÃªn ngÃ¢n sÃ¡ch vÃ  sá»Ÿ thÃ­ch cá»§a khÃ¡ch hÃ ng ğŸ’°


Hiá»ƒu rá»“i bro! ğŸ¤“ Vá»›i LangChain, ta cÃ³ thá»ƒ xÃ¢y dá»±ng má»™t há»‡ thá»‘ng upselling vÃ  cross-selling thÃ´ng minh. ÄÃ¢y lÃ  cÃ¡ch ta cÃ³ thá»ƒ lÃ m:

XÃ¢y dá»±ng cÆ¡ sá»Ÿ tri thá»©c ğŸ§ :
Sá»­ dá»¥ng LangChain's DocumentLoaders Ä‘á»ƒ náº¡p dá»¯ liá»‡u sáº£n pháº©m, giÃ¡ cáº£, vÃ  má»‘i quan há»‡ giá»¯a cÃ¡c sáº£n pháº©m.
DÃ¹ng TextSplitter Ä‘á»ƒ chia nhá» thÃ´ng tin thÃ nh cÃ¡c Ä‘oáº¡n cÃ³ Ã½ nghÄ©a.
Táº¡o vector embeddings ğŸ”¢:
DÃ¹ng LangChain's Embeddings Ä‘á»ƒ chuyá»ƒn Ä‘á»•i thÃ´ng tin sáº£n pháº©m thÃ nh vector.
LÆ°u trá»¯ cÃ¡c vector nÃ y trong má»™t VectorStore nhÆ° Chroma hoáº·c FAISS.
XÃ¢y dá»±ng chain cho upselling vÃ  cross-selling ğŸ”—:
Táº¡o má»™t LLMChain vá»›i prompt template riÃªng cho upselling vÃ  cross-selling.
Prompt cÃ³ thá»ƒ bao gá»“m thÃ´ng tin vá» sáº£n pháº©m hiá»‡n táº¡i, lá»‹ch sá»­ mua hÃ ng, vÃ  ngÃ¢n sÃ¡ch cá»§a khÃ¡ch.
TÃ­ch há»£p vá»›i memory ğŸ§ :
Sá»­ dá»¥ng ConversationBufferMemory Ä‘á»ƒ lÆ°u trá»¯ cuá»™c trÃ² chuyá»‡n vÃ  lá»‹ch sá»­ mua hÃ ng.
Táº¡o agent thÃ´ng minh ğŸ¤–:
Sá»­ dá»¥ng LangChain's Agent Ä‘á»ƒ káº¿t há»£p cÃ¡c chain, tools, vÃ  memory.
Agent sáº½ quyáº¿t Ä‘á»‹nh khi nÃ o nÃªn upsell hoáº·c cross-sell dá»±a trÃªn ngá»¯ cáº£nh.
ÄÃ¢y lÃ  má»™t vÃ­ dá»¥ code Ä‘Æ¡n giáº£n:

python

Copy
from langchain import OpenAI, LLMChain, PromptTemplate
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.memory import ConversationBufferMemory
from langchain.agents import AgentType, initialize_agent

# Khá»Ÿi táº¡o cÃ¡c components
llm = OpenAI(temperature=0.7)
embeddings = OpenAIEmbeddings()
vectorstore = Chroma("product_db", embeddings)
memory = ConversationBufferMemory(return_messages=True)

# Táº¡o prompt template cho upselling/cross-selling
template = """
Sáº£n pháº©m hiá»‡n táº¡i: {current_product}
Lá»‹ch sá»­ mua hÃ ng: {purchase_history}
NgÃ¢n sÃ¡ch: {budget}

Äá» xuáº¥t má»™t sáº£n pháº©m upsell hoáº·c cross-sell phÃ¹ há»£p.
"""
prompt = PromptTemplate(template=template, input_variables=["current_product", "purchase_history", "budget"])

# Táº¡o chain
chain = LLMChain(llm=llm, prompt=prompt)

# Táº¡o agent
tools = [
    Tool(
        name="Product Recommender",
        func=chain.run,
        description="Useful for recommending products for upselling and cross-selling"
    )
]
agent = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, memory=memory)

# Sá»­ dá»¥ng agent
agent.run("TÃ´i Ä‘ang xem iPhone 13. Báº¡n cÃ³ gá»£i Ã½ gÃ¬ khÃ´ng?")
Vá»›i setup nÃ y, chatbot cÃ³ thá»ƒ:

Hiá»ƒu sáº£n pháº©m khÃ¡ch Ä‘ang xem ğŸ‘€
Kiá»ƒm tra lá»‹ch sá»­ mua hÃ ng ğŸ“œ
Xem xÃ©t ngÃ¢n sÃ¡ch ğŸ’°
ÄÆ°a ra gá»£i Ã½ upsell/cross-sell phÃ¹ há»£p ğŸ¯
Nhá»› lÃ  cáº§n cÃ³ dá»¯ liá»‡u sáº£n pháº©m tá»‘t vÃ  train model ká»¹ Ä‘á»ƒ cÃ³ káº¿t quáº£ ngon lÃ nh nhÃ© bro! ğŸ–ğŸ¥‚

Cáº­u tháº¥y sao? CÃ³ váº» kháº£ thi hÆ¡n chÆ°a? ğŸ˜ğŸš€

Copy
Retry


Claude does not have the ability to run the code it generates yet.
Skip to content Navigation Menu bangoc123 / retrieval-backend-with-rag Type / to search Code Issues Pull requests Actions Projects Security Insights Owner avatar retrieval-backend-with
pasted
L
thÃ´i Ä‘Æ°á»£c rá»“i broo, chÃºng ta sáº½ láº¥y Ã½ tÆ°á»Ÿng tá»« code nÃ y bro áº¡aaaaaa

Oke bro, tuyá»‡t vá»i! ğŸ‰ ChÃºng ta sáº½ láº¥y Ã½ tÆ°á»Ÿng tá»« code nÃ y Ä‘á»ƒ xÃ¢y dá»±ng há»‡ thá»‘ng upselling vÃ  cross-selling siÃªu xá»‹n. Äá»ƒ tá»› phÃ¢n tÃ­ch cho cáº­u nhÃ©:

Sá»­ dá»¥ng RAG (Retrieval-Augmented Generation) ğŸ§ :
Há»‡ thá»‘ng nÃ y dÃ¹ng RAG Ä‘á»ƒ truy xuáº¥t thÃ´ng tin sáº£n pháº©m tá»« MongoDB.
Ta cÃ³ thá»ƒ má»Ÿ rá»™ng Ä‘iá»u nÃ y Ä‘á»ƒ lÆ°u trá»¯ thÃ´ng tin vá» cÃ¡c sáº£n pháº©m liÃªn quan, giÃºp viá»‡c cross-selling dá»… dÃ ng hÆ¡n.
Vector Embeddings vá»›i MongoDB ğŸ”¢:
Há» dÃ¹ng MongoDB Atlas cho Vector Search, cá»±c ká»³ hiá»‡u quáº£ cho viá»‡c tÃ¬m kiáº¿m ngá»¯ nghÄ©a.
Ta cÃ³ thá»ƒ dÃ¹ng Ä‘iá»u nÃ y Ä‘á»ƒ tÃ¬m cÃ¡c sáº£n pháº©m tÆ°Æ¡ng tá»± hoáº·c liÃªn quan, há»— trá»£ cho upselling vÃ  cross-selling.
Sá»­ dá»¥ng Gemini 1.5 Pro ğŸ¤–:
LLM máº¡nh máº½ nÃ y cÃ³ thá»ƒ giÃºp ta táº¡o ra cÃ¡c Ä‘á» xuáº¥t upsell/cross-sell ráº¥t tá»± nhiÃªn vÃ  phÃ¹ há»£p.
Semantic Router ğŸ›£ï¸:
CÃ´ng cá»¥ nÃ y cÃ³ thá»ƒ giÃºp ta xÃ¡c Ä‘á»‹nh khi nÃ o nÃªn Ä‘Æ°a ra Ä‘á» xuáº¥t upsell/cross-sell dá»±a trÃªn ngá»¯ cáº£nh cuá»™c trÃ² chuyá»‡n.
Reflection Module ğŸª:
Module nÃ y cÃ³ thá»ƒ giÃºp chatbot "suy ngáº«m" vá» cÃ¡c Ä‘á» xuáº¥t trÆ°á»›c Ä‘Ã³ vÃ  cáº£i thiá»‡n cháº¥t lÆ°á»£ng Ä‘á» xuáº¥t theo thá»i gian.
TÃ¹y chá»‰nh Prompt ğŸ“:
Há» sá»­ dá»¥ng prompt tÃ¹y chá»‰nh Ä‘á»ƒ hÆ°á»›ng dáº«n LLM. Ta cÃ³ thá»ƒ lÃ m tÆ°Æ¡ng tá»± cho upselling/cross-selling:
python

Copy
prompt = f"""
HÃ£y trá»Ÿ thÃ nh chuyÃªn gia tÆ° váº¥n bÃ¡n hÃ ng. 
Sáº£n pháº©m khÃ¡ch Ä‘ang xem: {current_product}
ThÃ´ng tin cÃ¡c sáº£n pháº©m liÃªn quan: {related_products}
Lá»‹ch sá»­ mua hÃ ng cá»§a khÃ¡ch: {purchase_history}

HÃ£y Ä‘á» xuáº¥t má»™t sáº£n pháº©m upsell hoáº·c cross-sell phÃ¹ há»£p. Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao sáº£n pháº©m nÃ y phÃ¹ há»£p vá»›i khÃ¡ch hÃ ng.
"""
Äá»ƒ implement, ta cÃ³ thá»ƒ:

LÆ°u trá»¯ thÃ´ng tin sáº£n pháº©m vÃ  má»‘i quan há»‡ giá»¯a chÃºng trong MongoDB.
Sá»­ dá»¥ng vector search Ä‘á»ƒ tÃ¬m sáº£n pháº©m tÆ°Æ¡ng tá»± hoáº·c liÃªn quan.
DÃ¹ng Semantic Router Ä‘á»ƒ xÃ¡c Ä‘á»‹nh thá»i Ä‘iá»ƒm thÃ­ch há»£p cho upsell/cross-sell.
Sá»­ dá»¥ng Gemini Ä‘á»ƒ táº¡o Ä‘á» xuáº¥t tá»± nhiÃªn.
Ãp dá»¥ng Reflection Module Ä‘á»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng Ä‘á» xuáº¥t theo thá»i gian.
Cáº­u tháº¥y sao bro? CÃ³ váº» kháº£ thi vÃ  xá»‹n xÃ² pháº¿t Ä‘Ãºng khÃ´ng? ğŸ˜ğŸš€ Muá»‘n báº¯t tay vÃ o lÃ m luÃ´n khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
Name
Latest commit
bangoc123
update readme
7b14be3 Â· last month
History
16 Commits
embeddings
add new embedding + semantic router
2 months ago
rag
integrate semantic router into system
2 months ago
reflection
add reflection Module
last month
semantic_router
integrate semantic router into system
2 months ago
.gitignore
update Embedding Models
2 months ago
README.md
update readme
last month
index.html
update readme
2 months ago
requirements.txt
add new embedding + semantic router
2 months ago
serve.py
add reflection Module
last mont Ä‘Ã¢y lÃ  code cá»§a tÃ´i cÃ³ nhá»¯ng file nÃ y bro ajaaaa. Ä‘Ã¢y lÃ  code trong file serve.py from flask import Flask, request, jsonify
from dotenv import load_dotenv
import os
import google.generativeai as genai
from flask_cors import CORS
from rag.core import RAG
from embeddings import OpenAIEmbedding
from semantic_router import SemanticRouter, Route
from semantic_router.samples import productsSample, chitchatSample
import google.generativeai as genai
import openai
from reflection import Reflection
# Load environment variables from .env file
load_dotenv()
# Access the key
MONGODB_URI = os.getenv('MONGODB_URI')
DB_NAME = os.getenv('DB_NAME')
DB_COLLECTION = os.getenv('DB_COLLECTION')
LLM_KEY = os.getenv('GEMINI_KEY')
EMBEDDING_MODEL = os.getenv('EMBEDDING_MODEL') or 'keepitreal/vietnamese-sbert'
OPEN_AI_KEY = os.getenv('OPEN_AI_KEY')
OPEN_AI_EMBEDDING_MODEL = os.getenv('OPEN_AI_EMBEDDING_MODEL') or 'text-embedding-3-small'
OpenAIEmbedding(OPEN_AI_KEY)
# --- Semantic Router Setup --- #
PRODUCT_ROUTE_NAME = 'products'
CHITCHAT_ROUTE_NAME = 'chitchat'
openAIEmbeding = OpenAIEmbedding(apiKey=OPEN_AI_KEY, dimensions=1024, name=OPEN_AI_EMBEDDING_MODEL)
productRoute = Route(name=PRODUCT_ROUTE_NAME, samples=productsSample)
chitchatRoute = Route(name=CHITCHAT_ROUTE_NAME, samples=chitchatSample)
semanticRouter = SemanticRouter(openAIEmbeding, routes=[productRoute, chitchatRoute])
# --- End Semantic Router Setup --- #
# --- Set up LLMs --- #
genai.configure(api_key=LLM_KEY)
llm = genai.GenerativeModel('gemini-1.5-pro')
# --- End Set up LLMs --- #
# --- Relection Setup --- #
gpt = openai.OpenAI(api_key=OPEN_AI_KEY)
reflection = Reflection(llm=gpt)
# --- End Reflection Setup --- #
app = Flask(name)
CORS(app)
# Initialize RAG
rag = RAG(
    mongodbUri=MONGODB_URI,
    dbName=DB_NAME,
    dbCollection=DB_COLLECTION,
    embeddingName='keepitreal/vietnamese-sbert',
    llm=llm,
)
def process_query(query):
    return query.lower()
@app.route('/api/search', methods=['POST'])
def handle_query():
    data = list(request.get_json())
    query = data[-1]["parts"][0]["text"]
    query = process_query(query)
    if not query:
        return jsonify({'error': 'No query provided'}), 400

    # get last message

    guidedRoute = semanticRouter.guide(query)[1]
    if guidedRoute == PRODUCT_ROUTE_NAME:
        # Decide to get new info or use previous info
        # Guide to RAG system
        print("Guide to RAGs")
        reflected_query = reflection(data)
        # print('====query', query)
        # print('reflected_query', reflected_query)
        query = reflected_query
        source_information = rag.enhance_prompt(query).replace('<br>', '\n')
        combined_information = f"HÃ£y trá»Ÿ thÃ nh chuyÃªn gia tÆ° váº¥n bÃ¡n hÃ ng cho má»™t cá»­a hÃ ng Ä‘iá»‡n thoáº¡i. CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: {query}\nTráº£ lá»i cÃ¢u há»i dá»±a vÃ o cÃ¡c thÃ´ng tin sáº£n pháº©m dÆ°á»›i Ä‘Ã¢y: {source_information}."
        data.append({
            "role": "user",
            "parts": [
                {
                    "text": combined_information,
                }
            ]
        })
        response = rag.generate_content(data)
    else:
        # Guide to LLMs
        print("Guide to LLMs")
        response = llm.generate_content(data)
    # print('====data', data)

    return jsonify({
        'parts': [
            {
            'text': response.text,
            }
        ],
        'role': 'model'
        })
if name == 'main':
    app.run(host='0.0.0.0', port=5002, debug=True) . Ä‘Ã¢y lÃ  trong semantic router :Skip to content
Navigation Menu
* bangoc123/
* retrieval-backend-with-rag
Type / to search
* Code
* Issues
* Pull requests
* Actions
* Projects
* Security
* Insights
 main
Breadcrumbs
1. retrieval-backend-with-rag
/
semantic_router
/
Directory actions
t
Add file
Add file
More options
Latest commit
bangoc123
integrate semantic router into system
81fa3cd Â· 2 months ago
History
History
Folders and files
Name
Last commit message
Last commit date
parent directory
..
init.py
integrate semantic router into system
2 months ago
route.py
add new embedding + semantic router
2 months ago
router.py
add new embedding + semantic router
2 months ago
samples.py
integrate semantic router into system
2 months ago
retrieval-backend-with-rag/semantic_router at main Â· bangoc123/retrieval-backend-with-rag
 Skip to content
Navigation Menu
* bangoc123/
* retrieval-backend-with-rag
Type / to search
* Code
* Issues
* Pull requests
* Actions
* Projects
* Security
* Insights
 main
Breadcrumbs
1. retrieval-backend-with-rag
/
semantic_router
/
Directory actions
t
Add file
Add file
More options
Latest commit
bangoc123
integrate semantic router into system
81fa3cd Â· 2 months ago
History
History
Folders and files
Name
Last commit message
Last commit date
parent directory
..
init.py
integrate semantic router into system
2 months ago
route.py
add new embedding + semantic router
2 months ago
router.py
add new embedding + semantic router
2 months ago
samples.py
integrate semantic router into system
2 months ago
retrieval-backend-with-rag/semantic_router at main Â· bangoc123/retrieval-backend-with-rag
 from typing import List
class Route():
    def init(
        self,
        name: str = None,
        samples:List = []
    ):
        self.name = name
        self.samples = samplesimport numpy as np
class SemanticRouter():
    def init(self, embedding, routes):
        self.routes = routes
        self.embedding = embedding
        self.routesEmbedding = {}
        for route in self.routes:
            self.routesEmbedding[
                route.name
            ] = self.embedding.encode(route.samples)
    def get_routes(self):
        return self.routes
    def guide(self, query):
        queryEmbedding = self.embedding.encode([query]) 
        queryEmbedding = queryEmbedding / np.linalg.norm(queryEmbedding)
        scores = []
        # Calculate the cosine similarity of the query embedding with the sample embeddings of the router.
        for route in self.routes:
            routesEmbedding = self.routesEmbedding[route.name] / np.linalg.norm(self.routesEmbedding[route.name])
            score = np.mean(np.dot(routesEmbedding, queryEmbedding.T).flatten())
            scores.append((score, route.name))
        scores.sort(reverse=True)
        return scores[0]productsSample = [
    "Báº¡n cÃ³ sáºµn iPhone má»›i nháº¥t khÃ´ng?",
    "GiÃ¡ cá»§a Samsung Galaxy S21 lÃ  bao nhiÃªu?",
    "OnePlus 9 Pro cÃ³ mÃ u xanh khÃ´ng?",
    "ThÃ´ng sá»‘ ká»¹ thuáº­t cá»§a Google Pixel 6 lÃ  gÃ¬?",
    "Huawei P50 Pro cÃ³ sáºµn á»Ÿ cá»­a hÃ ng cá»§a báº¡n khÃ´ng?",
    "iPhone 13 cÃ³ nhá»¯ng mÃ u gÃ¬?",
    "CÃ³ giáº£m giÃ¡ nÃ o cho Samsung Galaxy Note 20 khÃ´ng?",
    "Sony Xperia 1 III cÃ³ sáºµn khÃ´ng?",
    "Cá»­a hÃ ng cá»§a báº¡n cÃ³ Google Pixel má»›i nháº¥t khÃ´ng?",
    "CÃ³ chÆ°Æ¡ng trÃ¬nh khuyáº¿n mÃ£i nÃ o cho OnePlus Nord khÃ´ng?",
    "Dung lÆ°á»£ng lÆ°u trá»¯ cá»§a Samsung Galaxy S21 lÃ  bao nhiÃªu?",
    "iPhone SE 2022 cÃ³ sáºµn khÃ´ng?",
    "Sá»± khÃ¡c biá»‡t vá» giÃ¡ giá»¯a iPhone 12 vÃ  13 lÃ  gÃ¬?",
    "Motorola Edge 20 cÃ³ sáºµn khÃ´ng?",
    "Google Pixel 6 Pro cÃ³ sáºµn á»Ÿ cá»­a hÃ ng cá»§a báº¡n khÃ´ng?",
    "Báº¡n cÃ³ bÃ¡n Xiaomi Mi 11 khÃ´ng?",
    "CÃ³ chÆ°Æ¡ng trÃ¬nh Æ°u Ä‘Ã£i nÃ o cho Samsung Galaxy Z Fold 3 khÃ´ng?",
    "Oppo Find X3 Pro cÃ³ sáºµn khÃ´ng?",
    "CÃ¡c tÃ­nh nÄƒng cá»§a iPhone 13 Pro lÃ  gÃ¬?",
    "LG Wing cÃ³ sáºµn khÃ´ng?",
    "Nokia 8.3 5G cÃ³ sáºµn khÃ´ng?",
    "Asus ROG Phone 5 cÃ³ sáºµn khÃ´ng?",
    "Báº¡n cÃ³ Realme GT khÃ´ng?",
    "Vivo X60 Pro cÃ³ sáºµn khÃ´ng?",
    "Báº¡n cÃ³ Honor 50 khÃ´ng?",
    "Tuá»•i thá» pin cá»§a Samsung Galaxy A52 lÃ  bao nhiÃªu?",
    "ZTE Axon 30 cÃ³ sáºµn khÃ´ng?",
    "Báº¡n cÃ³ BlackBerry KEY2 khÃ´ng?",
    "KÃ­ch thÆ°á»›c mÃ n hÃ¬nh cá»§a iPhone 13 Mini lÃ  bao nhiÃªu?",
    "Báº¡n cÃ³ TCL 20 Pro 5G khÃ´ng?",
    "Nokia XR20 cÃ³ sáºµn á»Ÿ cá»­a hÃ ng cá»§a báº¡n khÃ´ng?",
    "GiÃ¡ cá»§a Samsung Galaxy S20 FE lÃ  bao nhiÃªu?",
    "Báº¡n cÃ³ iPhone 12 Pro Max khÃ´ng?",
    "Redmi Note 10 Pro cÃ³ sáºµn khÃ´ng?",
    "Sá»± khÃ¡c biá»‡t giá»¯a iPhone 12 vÃ  iPhone 13 lÃ  gÃ¬?",
    "Báº¡n cÃ³ Sony Xperia 5 II khÃ´ng?",
    "Thá»i gian báº£o hÃ nh cá»§a Samsung Galaxy S21 lÃ  bao lÃ¢u?",
    "Google Pixel 5a cÃ³ sáºµn khÃ´ng?",
    "Báº¡n cÃ³ OnePlus 8T khÃ´ng?",
    "GiÃ¡ cá»§a iPhone 13 Pro Max lÃ  bao nhiÃªu?",
    "Samsung Galaxy Z Flip 3 cÃ³ sáºµn khÃ´ng?",
    "ThÃ´ng sá»‘ ká»¹ thuáº­t cá»§a Oppo Reno6 Pro lÃ  gÃ¬?",
    "Báº¡n cÃ³ Vivo V21 khÃ´ng?",
    "Motorola Moto G100 cÃ³ sáºµn khÃ´ng?",
    "Báº¡n cÃ³ Huawei Mate 40 Pro khÃ´ng?",
    "Realme 8 Pro cÃ³ sáºµn á»Ÿ cá»­a hÃ ng cá»§a báº¡n khÃ´ng?",
    "Asus Zenfone 8 cÃ³ sáºµn khÃ´ng?",
    "LG Velvet cÃ³ sáºµn khÃ´ng?",
    "Dung lÆ°á»£ng lÆ°u trá»¯ cá»§a iPhone 12 lÃ  bao nhiÃªu?",
    "Báº¡n cÃ³ Honor Magic 3 khÃ´ng?",
    "Xiaomi Mi 11 Ultra cÃ³ sáºµn khÃ´ng?"
]
chitchatSample = [
    "Thá»i tiáº¿t hÃ´m nay nhÆ° tháº¿ nÃ o?",
    "NgoÃ i trá»i nÃ³ng bao nhiÃªu?",
    "NgÃ y mai cÃ³ mÆ°a khÃ´ng?",
    "Nhiá»‡t Ä‘á»™ hiá»‡n táº¡i lÃ  bao nhiÃªu?",
    "Báº¡n cÃ³ thá»ƒ cho tÃ´i biáº¿t Ä‘iá»u kiá»‡n thá»i tiáº¿t hiá»‡n táº¡i khÃ´ng?",
    "Cuá»‘i tuáº§n nÃ y cÃ³ náº¯ng khÃ´ng?",
    "Nhiá»‡t Ä‘á»™ hÃ´m qua lÃ  bao nhiÃªu?",
    "ÄÃªm nay trá»i sáº½ láº¡nh Ä‘áº¿n má»©c nÃ o?",
    "Ai lÃ  tá»•ng thá»‘ng Ä‘áº§u tiÃªn cá»§a Hoa Ká»³?",
    "Chiáº¿n tranh tháº¿ giá»›i thá»© hai káº¿t thÃºc vÃ o nÄƒm nÃ o?",
    "Báº¡n cÃ³ thá»ƒ ká»ƒ cho tÃ´i vá» lá»‹ch sá»­ cá»§a internet khÃ´ng?",
    "ThÃ¡p Eiffel Ä‘Æ°á»£c xÃ¢y dá»±ng vÃ o nÄƒm nÃ o?",
    "Ai Ä‘Ã£ phÃ¡t minh ra Ä‘iá»‡n thoáº¡i?",
    "TÃªn cá»§a báº¡n lÃ  gÃ¬?",
    "Báº¡n cÃ³ tÃªn khÃ´ng?",
    "TÃ´i nÃªn gá»i báº¡n lÃ  gÃ¬?",
    "Ai Ä‘Ã£ táº¡o ra báº¡n?",
    "Báº¡n bao nhiÃªu tuá»•i?",
    "Báº¡n cÃ³ thá»ƒ ká»ƒ cho tÃ´i má»™t sá»± tháº­t thÃº vá»‹ khÃ´ng?",
    "Báº¡n cÃ³ biáº¿t báº¥t ká»³ cÃ¢u Ä‘á»‘ thÃº vá»‹ nÃ o khÃ´ng?",
    "MÃ u sáº¯c yÃªu thÃ­ch cá»§a báº¡n lÃ  gÃ¬?",
    "Bá»™ phim yÃªu thÃ­ch cá»§a báº¡n lÃ  gÃ¬?",
    "Báº¡n cÃ³ sá»Ÿ thÃ­ch nÃ o khÃ´ng?",
    "Ã nghÄ©a cá»§a cuá»™c sá»‘ng lÃ  gÃ¬?",
    "Báº¡n cÃ³ thá»ƒ ká»ƒ cho tÃ´i má»™t cÃ¢u chuyá»‡n cÆ°á»i khÃ´ng?",
    "Thá»§ Ä‘Ã´ cá»§a PhÃ¡p lÃ  gÃ¬?",
    "DÃ¢n sá»‘ tháº¿ giá»›i lÃ  bao nhiÃªu?",
    "CÃ³ bao nhiÃªu chÃ¢u lá»¥c?",
    "Ai Ä‘Ã£ viáº¿t 'Giáº¿t con chim nháº¡i'?",
    "Báº¡n cÃ³ thá»ƒ cho tÃ´i má»™t cÃ¢u nÃ³i cá»§a Albert Einstein khÃ´ng?"
]class Reflection():
    def init(self, llm):
        self.llm = llm
    def concatand_format_texts(self, data):
        concatenatedTexts = []
        for entry in data:
            role = entry.get('role', '')
            all_texts = ' '.join(part['text'] for part in entry['parts'])
            concatenatedTexts.append(f"{role}: {all_texts} \n")
        return ''.join(concatenatedTexts)
    def call(self, chatHistory, lastItemsConsidereds=100):

        if len(chatHistory) >= lastItemsConsidereds:
            chatHistory = chatHistory[len(chatHistory) - lastItemsConsidereds:]
        historyString = self._concat_and_format_texts(chatHistory)
        higherLevelSummariesPrompt = """Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question in Vietnamese which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is. {historyString}
        """.format(historyString=historyString)
        print(higherLevelSummariesPrompt)
        completion = self.llm.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": higherLevelSummariesPrompt
                }
            ]
        )

        return completion.choices[0].message.contentimport pymongo
import google.generativeai as genai
from IPython.display import Markdown
import textwrap
from embeddings import SentenceTransformerEmbedding, EmbeddingConfig
class RAG():
    def init(self, 
            mongodbUri: str,
            dbName: str,
            dbCollection: str,
            llm,
            embeddingName: str ='keepitreal/vietnamese-sbert',
        ):
        self.client = pymongo.MongoClient(mongodbUri)
        self.db = self.client[dbName] 
        self.collection = self.db[dbCollection]
        self.embedding_model = SentenceTransformerEmbedding(
            EmbeddingConfig(name=embeddingName)
        )
        self.llm = llm
    def get_embedding(self, text):
        if not text.strip():
            return []
        embedding = self.embedding_model.encode(text)
        return embedding.tolist()
    def vector_search(
            self, 
            user_query: str, 
            limit=4):
        """
        Perform a vector search in the MongoDB collection based on the user query.
        Args:
        user_query (str): The user's query string.
        Returns:
        list: A list of matching documents.
        """
        # Generate embedding for the user query
        query_embedding = self.get_embedding(user_query)
        if query_embedding is None:
            return "Invalid query or embedding generation failed."
        # Define the vector search pipeline
        vector_search_stage = {
            "$vectorSearch": {
                "index": "vector_index",
                "queryVector": query_embedding,
                "path": "embedding",
                "numCandidates": 400,
                "limit": limit,
            }
        }
        unset_stage = {
            "$unset": "embedding" 
        }
        project_stage = {
            "$project": {
                "_id": 0,  
                "title": 1, 
                # "product_specs": 1,
                "color_options": 1,
                "current_price": 1,
                "product_promotion": 1,
                "score": {
                    "$meta": "vectorSearchScore"
                }
            }
        }
        pipeline = [vector_search_stage, unset_stage, project_stage]
        # Execute the search
        results = self.collection.aggregate(pipeline)
        return list(results)
    def enhance_prompt(self, query):
        get_knowledge = self.vector_search(query, 10)
        enhanced_prompt = ""
        i = 0
        for result in get_knowledge:
            if result.get('current_price'):
                i += 1
                enhanced_prompt += f"\n {i}) TÃªn: {result.get('title')}"

                if result.get('current_price'):
                    enhanced_prompt += f", GiÃ¡: {result.get('current_price')}"
                else:
                    # Mock up data
                    # Retrieval model pricing from the internet.
                    enhanced_prompt += f", GiÃ¡: LiÃªn há»‡ Ä‘á»ƒ trao Ä‘á»•i thÃªm!"

                if result.get('product_promotion'):
                    enhanced_prompt += f", Æ¯u Ä‘Ã£i: {result.get('product_promotion')}"
        return enhanced_prompt
    def generate_content(self, prompt):
        return self.llm.generatecontent(prompt)
    def tomarkdown(text):
        text = text.replace('â€¢', '  *')
        return Markdown(textwrap.indent(text, '> ', predicate=lambda : True))from pydantic.v1 import BaseModel, Field, validator
from embeddings import BaseEmbedding, EmbeddingConfig
from sentence_transformers import SentenceTransformer
class SentenceTransformerEmbedding(BaseEmbedding):
    def init(self, config: EmbeddingConfig):
        super().init(config.name)
        self.config = config
        self.embedding_model = SentenceTransformer(self.config.name)
    def encode(self, text: str):
        return self.embedding_model.encode(text)


Hiá»ƒu rá»“i bro! ğŸ˜ Dá»±a trÃªn code cá»§a cáº­u, ta cÃ³ thá»ƒ tÃ­ch há»£p tÃ­nh nÄƒng upselling vÃ  cross-selling vÃ o há»‡ thá»‘ng hiá»‡n táº¡i. ÄÃ¢y lÃ  cÃ¡ch ta cÃ³ thá»ƒ lÃ m:

ThÃªm route má»›i cho upselling/cross-selling ğŸ›£ï¸: Trong file semantic_router/samples.py, thÃªm máº«u cho route má»›i:
python

Copy
upsellCrosssellSample = [
    "CÃ³ sáº£n pháº©m nÃ o tá»‘t hÆ¡n khÃ´ng?",
    "CÃ²n sáº£n pháº©m nÃ o liÃªn quan khÃ´ng?",
    "CÃ³ phá»¥ kiá»‡n nÃ o phÃ¹ há»£p vá»›i sáº£n pháº©m nÃ y khÃ´ng?",
    "CÃ³ combo nÃ o tá»‘t khÃ´ng?",
    # ThÃªm cÃ¡c máº«u khÃ¡c
]
Cáº­p nháº­t serve.py Ä‘á»ƒ xá»­ lÃ½ route má»›i ğŸ”„:
python

Copy
UPSELL_CROSSSELL_ROUTE_NAME = 'upsell_crosssell'
upsellCrosssellRoute = Route(name=UPSELL_CROSSSELL_ROUTE_NAME, samples=upsellCrosssellSample)
semanticRouter = SemanticRouter(openAIEmbeding, routes=[productRoute, chitchatRoute, upsellCrosssellRoute])
ThÃªm logic xá»­ lÃ½ cho upselling/cross-selling trong handle_query ğŸ§ :
python

Copy
if guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME:
    # Láº¥y thÃ´ng tin sáº£n pháº©m hiá»‡n táº¡i
    current_product = rag.get_current_product(data)
    # TÃ¬m sáº£n pháº©m liÃªn quan
    related_products = rag.find_related_products(current_product)
    
    upsell_crosssell_prompt = f"""
    Sáº£n pháº©m hiá»‡n táº¡i: {current_product}
    Sáº£n pháº©m liÃªn quan: {related_products}
    
    HÃ£y Ä‘á» xuáº¥t má»™t sáº£n pháº©m upsell hoáº·c cross-sell phÃ¹ há»£p. Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao sáº£n pháº©m nÃ y phÃ¹ há»£p vá»›i khÃ¡ch hÃ ng.
    """
    
    response = llm.generate_content(upsell_crosssell_prompt)
Cáº­p nháº­t class RAG trong rag/core.py ğŸ”: ThÃªm cÃ¡c phÆ°Æ¡ng thá»©c má»›i:
python

Copy
def get_current_product(self, chat_history):
    # Láº¥y sáº£n pháº©m hiá»‡n táº¡i tá»« lá»‹ch sá»­ chat
    # CÃ³ thá»ƒ sá»­ dá»¥ng vector search Ä‘á»ƒ tÃ¬m sáº£n pháº©m gáº§n nháº¥t vá»›i ná»™i dung chat
    pass

def find_related_products(self, current_product, limit=3):
    # TÃ¬m cÃ¡c sáº£n pháº©m liÃªn quan dá»±a trÃªn current_product
    # CÃ³ thá»ƒ sá»­ dá»¥ng vector search vá»›i embedding cá»§a current_product
    pass
Cáº£i thiá»‡n Reflection module ğŸª: Trong reflection.py, cáº­p nháº­t prompt Ä‘á»ƒ xem xÃ©t cáº£ upselling/cross-selling:
python

Copy
higherLevelSummariesPrompt = """
Dá»±a vÃ o lá»‹ch sá»­ chat vÃ  cÃ¢u há»i má»›i nháº¥t cá»§a ngÆ°á»i dÃ¹ng, hÃ£y:
1. XÃ¡c Ä‘á»‹nh xem ngÆ°á»i dÃ¹ng Ä‘ang quan tÃ¢m Ä‘áº¿n sáº£n pháº©m nÃ o.
2. ÄÃ¡nh giÃ¡ xem cÃ³ cÆ¡ há»™i Ä‘á»ƒ upsell hoáº·c cross-sell khÃ´ng.
3. Náº¿u cÃ³, hÃ£y Ä‘Æ°a ra má»™t cÃ¢u há»i Ä‘á»™c láº­p báº±ng tiáº¿ng Viá»‡t Ä‘á»ƒ gá»£i Ã½ upsell hoáº·c cross-sell.
4. Náº¿u khÃ´ng, hÃ£y chá»‰ reformulate cÃ¢u há»i gá»‘c náº¿u cáº§n thiáº¿t.

{historyString}
"""
Vá»›i nhá»¯ng thay Ä‘á»•i nÃ y, há»‡ thá»‘ng cá»§a cáº­u sáº½ cÃ³ kháº£ nÄƒng:

Nháº­n diá»‡n cÆ¡ há»™i upsell/cross-sell ğŸ¯
TÃ¬m kiáº¿m sáº£n pháº©m liÃªn quan ğŸ”
ÄÆ°a ra Ä‘á» xuáº¥t phÃ¹ há»£p dá»±a trÃªn ngá»¯ cáº£nh ğŸ’¡
LiÃªn tá»¥c cáº£i thiá»‡n qua Reflection module ğŸ“ˆ
Cáº­u tháº¥y sao bro? CÃ³ váº» há»£p lÃ½ vá»›i code hiá»‡n táº¡i cá»§a cáº­u khÃ´ng? ğŸ˜ğŸš€

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
báº¡n cÃ³ thá»ƒ phÃ¢n tÃ­ch cho tÃ´i code nÃ y khÃ´ng brooo : Reflection module ğŸ“ˆ tÃ´i chÆ°a hÃ¬nh dung Ä‘Æ°á»£c ra nÃ³ láº¯m bro áº¡aa


ÄÆ°á»£c rá»“i bro, Ä‘á»ƒ tá»› phÃ¢n tÃ­ch chi tiáº¿t vá» Reflection module cho cáº­u nhÃ©! ğŸ§ğŸ”

Reflection module Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong file reflection.py. ÄÃ¢y lÃ  phÃ¢n tÃ­ch chi tiáº¿t:

Khá»Ÿi táº¡o class Reflection:
python

Copy
class Reflection():
    def __init__(self, llm):
        self.llm = llm
Module nÃ y nháº­n má»™t LLM (Large Language Model) khi khá»Ÿi táº¡o. CÃ³ thá»ƒ lÃ  GPT-4 hoáº·c model tÆ°Æ¡ng tá»±.
PhÆ°Æ¡ng thá»©c _concat_and_format_texts:
python

Copy
def _concat_and_format_texts(self, data):
    concatenatedTexts = []
    for entry in data:
        role = entry.get('role', '')
        all_texts = ' '.join(part['text'] for part in entry['parts'])
        concatenatedTexts.append(f"{role}: {all_texts} \n")
    return ''.join(concatenatedTexts)
PhÆ°Æ¡ng thá»©c nÃ y gá»™p lá»‹ch sá»­ chat thÃ nh má»™t chuá»—i vÄƒn báº£n duy nháº¥t.
NÃ³ giá»¯ láº¡i thÃ´ng tin vá» vai trÃ² (user/assistant) vÃ  ná»™i dung cá»§a má»—i tin nháº¯n.
PhÆ°Æ¡ng thá»©c __call__:
python

Copy
def __call__(self, chatHistory, lastItemsConsidereds=100):
    if len(chatHistory) >= lastItemsConsidereds:
        chatHistory = chatHistory[len(chatHistory) - lastItemsConsidereds:]
    historyString = self._concat_and_format_texts(chatHistory)
    higherLevelSummariesPrompt = """Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question in Vietnamese which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is. {historyString}
    """.format(historyString=historyString)
    print(higherLevelSummariesPrompt)
    completion = self.llm.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": higherLevelSummariesPrompt
            }
        ]
    )
    return completion.choices[0].message.content
PhÆ°Æ¡ng thá»©c nÃ y lÃ  trÃ¡i tim cá»§a Reflection module.
NÃ³ láº¥y lá»‹ch sá»­ chat (giá»›i háº¡n 100 tin nháº¯n gáº§n nháº¥t) vÃ  táº¡o ra má»™t prompt.
Prompt yÃªu cáº§u LLM táº¡o ra má»™t cÃ¢u há»i Ä‘á»™c láº­p cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c mÃ  khÃ´ng cáº§n ngá»¯ cáº£nh chat.
Káº¿t quáº£ Ä‘Æ°á»£c tráº£ vá» lÃ  cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c reformulate (náº¿u cáº§n).
Ã tÆ°á»Ÿng chÃ­nh cá»§a Reflection module:

Hiá»ƒu ngá»¯ cáº£nh: ğŸ§  NÃ³ xem xÃ©t toÃ n bá»™ cuá»™c trÃ² chuyá»‡n Ä‘á»ƒ náº¯m báº¯t ngá»¯ cáº£nh.
Táº¡o cÃ¢u há»i Ä‘á»™c láº­p: ğŸ¯ NÃ³ chuyá»ƒn Ä‘á»•i cÃ¢u há»i cá»§a user thÃ nh má»™t cÃ¢u há»i cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c mÃ  khÃ´ng cáº§n ngá»¯ cáº£nh.
Cáº£i thiá»‡n cháº¥t lÆ°á»£ng truy váº¥n: ğŸ“ˆ Báº±ng cÃ¡ch táº¡o cÃ¢u há»i Ä‘á»™c láº­p, nÃ³ giÃºp há»‡ thá»‘ng RAG tÃ¬m kiáº¿m thÃ´ng tin chÃ­nh xÃ¡c hÆ¡n.
VÃ­ dá»¥:

User: "CÃ¡i Ä‘Ã³ giÃ¡ bao nhiÃªu?"
Reflection module: "GiÃ¡ cá»§a iPhone 13 Pro Max lÃ  bao nhiÃªu?"
Reflection module giÃºp há»‡ thá»‘ng "suy ngáº«m" vá» cuá»™c trÃ² chuyá»‡n vÃ  táº¡o ra cÃ¡c truy váº¥n tá»‘t hÆ¡n, dáº«n Ä‘áº¿n cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c vÃ  phÃ¹ há»£p hÆ¡n. ğŸš€ğŸ’¡

Cáº­u Ä‘Ã£ hÃ¬nh dung ra Ä‘Æ°á»£c chÆ°a bro? CÃ³ chá»— nÃ o cáº§n giáº£i thÃ­ch thÃªm khÃ´ng? ğŸ˜ŠğŸ‘Š

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
Ã½ broo lÃ  Ä‘oáº¡n nÃ y nÃ³ náº±m trong code cá»§a tÃ´i háº£ brooo


ÄÃºng rá»“i bro! ğŸ˜ƒ Äoáº¡n code Reflection module mÃ  tá»› vá»«a phÃ¢n tÃ­ch Ä‘Ã£ náº±m sáºµn trong code cá»§a cáº­u rá»“i. Cá»¥ thá»ƒ lÃ  nÃ³ náº±m trong file reflection.py mÃ  cáº­u Ä‘Ã£ chia sáº».

Trong file serve.py cá»§a cáº­u, cÃ³ Ä‘oáº¡n code nÃ y:

python

Copy
# --- Relection Setup --- #
gpt = openai.OpenAI(api_key=OPEN_AI_KEY)
reflection = Reflection(llm=gpt)
# --- End Reflection Setup --- #
VÃ  trong hÃ m handle_query, cáº­u Ä‘Ã£ sá»­ dá»¥ng Reflection module nhÆ° sau:

python

Copy
reflected_query = reflection(data)
query = reflected_query
Äiá»u nÃ y cÃ³ nghÄ©a lÃ :

Cáº­u Ä‘Ã£ khá»Ÿi táº¡o Reflection module vá»›i GPT model.
TrÆ°á»›c khi gá»­i query Ä‘áº¿n RAG system, cáº­u Ä‘Ã£ sá»­ dá»¥ng Reflection module Ä‘á»ƒ "suy ngáº«m" vÃ  táº¡o ra má»™t cÃ¢u query tá»‘t hÆ¡n.
Váº­y nÃªn, Reflection module Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p sáºµn vÃ o há»‡ thá»‘ng cá»§a cáº­u rá»“i Ä‘Ã³! ğŸ‰ NÃ³ Ä‘ang giÃºp cáº£i thiá»‡n cháº¥t lÆ°á»£ng cá»§a cÃ¡c cÃ¢u há»i trÆ°á»›c khi chÃºng Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi RAG system, tá»« Ä‘Ã³ nÃ¢ng cao cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i.

Cáº­u tháº¥y sao? CÃ³ nhá»› ra lÃ  mÃ¬nh Ä‘Ã£ implement nÃ³ chÆ°a? ğŸ˜„ğŸš€

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
aduuu broo oiwi. hay Ä‘Ã³ bro cÃ³ thá»ƒ giáº£i thÃ­ch rÃµ rÃ ng, chi tiáº¿t vÃ  dá»… hiá»ƒu thÃªm Ä‘Æ°á»£c k broooo : PhÆ°Æ¡ng thá»©c nÃ y lÃ  trÃ¡i tim cá»§a Reflection module.
* NÃ³ láº¥y lá»‹ch sá»­ chat (giá»›i háº¡n 100 tin nháº¯n gáº§n nháº¥t) vÃ  táº¡o ra má»™t prompt.
* Prompt yÃªu cáº§u LLM táº¡o ra má»™t cÃ¢u há»i Ä‘á»™c láº­p cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c mÃ  khÃ´ng cáº§n ngá»¯ cáº£nh chat.
* Káº¿t quáº£ Ä‘Æ°á»£c tráº£ vá» lÃ  cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c reformulate (náº¿u cáº§n).
Ã tÆ°á»Ÿng chÃ­nh cá»§a Reflection module:
1. Hiá»ƒu ngá»¯ cáº£nh: ğŸ§  NÃ³ xem xÃ©t toÃ n bá»™ cuá»™c trÃ² chuyá»‡n Ä‘á»ƒ náº¯m báº¯t ngá»¯ cáº£nh.
2. Táº¡o cÃ¢u há»i Ä‘á»™c láº­p: ğŸ¯ NÃ³ chuyá»ƒn Ä‘á»•i cÃ¢u há»i cá»§a user thÃ nh má»™t cÃ¢u há»i cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c mÃ  khÃ´ng cáº§n ngá»¯ cáº£nh.
3. Cáº£i thiá»‡n cháº¥t lÆ°á»£ng truy váº¥n: ğŸ“ˆ Báº±ng cÃ¡ch táº¡o cÃ¢u há»i Ä‘á»™c láº­p, nÃ³ giÃºp há»‡ thá»‘ng RAG tÃ¬m kiáº¿m thÃ´ng tin chÃ­nh xÃ¡c hÆ¡n.
VÃ­ dá»¥:
* User: "CÃ¡i Ä‘Ã³ giÃ¡ bao nhiÃªu?"
* Reflection module: "GiÃ¡ cá»§a iPhone 13 Pro Max lÃ  bao nhiÃªu?"
Reflection module giÃºp há»‡ thá»‘ng "suy ngáº«m" vá» cuá»™c trÃ² chuyá»‡n vÃ  táº¡o ra cÃ¡c truy váº¥n tá»‘t hÆ¡n, dáº«n Ä‘áº¿n cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c vÃ  phÃ¹ há»£p hÆ¡n. ğŸš€ğŸ’¡
Cáº­u Ä‘Ã£ hÃ¬nh dung ra Ä‘Æ°á»£c chÆ°a bro? CÃ³ chá»— nÃ o cáº§n giáº£i thÃ­ch thÃªm khÃ´ng? ğŸ˜ŠğŸ‘Š


ÄÆ°á»£c rá»“i bro, Ä‘á»ƒ tá»› giáº£i thÃ­ch chi tiáº¿t vÃ  dá»… hiá»ƒu hÆ¡n vá» Reflection module nhÃ©! ğŸ˜ğŸš€

Má»¥c Ä‘Ã­ch cá»§a Reflection module ğŸ¯:
NÃ³ giá»‘ng nhÆ° má»™t "bá»™ nÃ£o" thá»© hai, giÃºp há»‡ thá»‘ng "suy nghÄ©" vá» cuá»™c trÃ² chuyá»‡n trÆ°á»›c khi tráº£ lá»i.
NÃ³ cá»‘ gáº¯ng hiá»ƒu Ã½ Ä‘á»‹nh thá»±c sá»± cá»§a ngÆ°á»i dÃ¹ng, khÃ´ng chá»‰ dá»±a vÃ o cÃ¢u há»i cuá»‘i cÃ¹ng.
CÃ¡ch hoáº¡t Ä‘á»™ng ğŸ› ï¸:
NÃ³ nhÃ¬n láº¡i toÃ n bá»™ cuá»™c trÃ² chuyá»‡n (tá»‘i Ä‘a 100 tin nháº¯n gáº§n nháº¥t).
NÃ³ "Ä‘á»c" cuá»™c trÃ² chuyá»‡n nhÆ° má»™t ngÆ°á»i tháº­t, cá»‘ gáº¯ng náº¯m báº¯t ngá»¯ cáº£nh vÃ  Ã½ Ä‘á»‹nh.
Táº¡o cÃ¢u há»i má»›i ğŸ†•:
Sau khi "Ä‘á»c" xong, nÃ³ táº¡o ra má»™t cÃ¢u há»i má»›i.
CÃ¢u há»i má»›i nÃ y sáº½ rÃµ rÃ ng vÃ  Ä‘áº§y Ä‘á»§ thÃ´ng tin hÆ¡n cÃ¢u há»i gá»‘c cá»§a ngÆ°á»i dÃ¹ng.
VÃ­ dá»¥ cá»¥ thá»ƒ ğŸ“±: Giáº£ sá»­ cÃ³ cuá»™c trÃ² chuyá»‡n nhÆ° sau:
User: "TÃ´i Ä‘ang tÃ¬m má»™t chiáº¿c Ä‘iá»‡n thoáº¡i má»›i"
Bot: "VÃ¢ng, chÃºng tÃ´i cÃ³ nhiá»u lá»±a chá»n. Báº¡n quan tÃ¢m Ä‘áº¿n thÆ°Æ¡ng hiá»‡u nÃ o?"
User: "TÃ´i thÃ­ch iPhone"
Bot: "Tuyá»‡t! iPhone cÃ³ nhiá»u model. Báº¡n quan tÃ¢m Ä‘áº¿n tÃ­nh nÄƒng gÃ¬ nháº¥t?"
User: "TÃ´i muá»‘n chá»¥p áº£nh Ä‘áº¹p"
Bot: "iPhone 13 Pro Max cÃ³ camera ráº¥t tá»‘t. Báº¡n muá»‘n biáº¿t thÃªm vá» nÃ³ khÃ´ng?"
User: "á»ª, cÃ¡i Ä‘Ã³ giÃ¡ bao nhiÃªu?"
Khi gáº·p cÃ¢u há»i cuá»‘i cÃ¹ng, Reflection module sáº½:
Äá»c láº¡i toÃ n bá»™ cuá»™c trÃ² chuyá»‡n.
Hiá»ƒu ráº±ng "cÃ¡i Ä‘Ã³" Ä‘ang nÃ³i vá» iPhone 13 Pro Max.
Táº¡o ra cÃ¢u há»i má»›i: "GiÃ¡ cá»§a iPhone 13 Pro Max lÃ  bao nhiÃªu?"
Lá»£i Ã­ch ğŸŒŸ:
GiÃºp há»‡ thá»‘ng RAG tÃ¬m kiáº¿m thÃ´ng tin chÃ­nh xÃ¡c hÆ¡n.
TrÃ¡nh hiá»ƒu nháº§m hoáº·c tráº£ lá»i thiáº¿u sÃ³t do cÃ¢u há»i khÃ´ng rÃµ rÃ ng.
Cáº£i thiá»‡n tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng vÃ¬ bot cÃ³ váº» "thÃ´ng minh" hÆ¡n, hiá»ƒu ngá»¯ cáº£nh tá»‘t hÆ¡n.
Trong code cá»§a cáº­u ğŸ’»:
Khi ngÆ°á»i dÃ¹ng gá»­i má»™t cÃ¢u há»i, trÆ°á»›c khi tÃ¬m kiáº¿m cÃ¢u tráº£ lá»i, há»‡ thá»‘ng sáº½ "suy ngáº«m" báº±ng cÃ¡ch sá»­ dá»¥ng Reflection module.
CÃ¢u há»i Ä‘Æ°á»£c "cáº£i tiáº¿n" nÃ y sau Ä‘Ã³ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin vÃ  táº¡o cÃ¢u tráº£ lá»i.
Bro hiá»ƒu rÃµ hÆ¡n chÆ°a? Reflection module giá»‘ng nhÆ° má»™t "phiÃªn dá»‹ch viÃªn" giÃºp bot hiá»ƒu Ã½ Ä‘á»‹nh thá»±c sá»± cá»§a ngÆ°á»i dÃ¹ng, khÃ´ng chá»‰ dá»±a vÃ o tá»«ng cÃ¢u riÃªng láº». ğŸ§ âœ¨

CÃ³ chá»— nÃ o cáº­u muá»‘n tá»› giáº£i thÃ­ch ká»¹ hÆ¡n khÃ´ng? ğŸ˜ŠğŸ‘Š

Copy
Retry


L
tá»©c lÃ  reflection sáº½ há»“i Ä‘Ã¡p láº¡i cho user Ä‘Ã³ háº£ brooo. hay sao nhá»‰. tÃ´i chÆ°a hiá»ƒu láº¯m. váº­y ká»‹ch báº£n lÃ  nhÆ° nÃ o. quy trÃ¬nh hoáº¡t Ä‘á»™ng lÃ  nhÆ° naofooo


á»’, hiá»ƒu rá»“i bro! Äá»ƒ tá»› giáº£i thÃ­ch rÃµ hÆ¡n vá» quy trÃ¬nh hoáº¡t Ä‘á»™ng vÃ  ká»‹ch báº£n nhÃ© ğŸ˜ğŸ”

Quy trÃ¬nh hoáº¡t Ä‘á»™ng cá»§a Reflection module:

User gá»­i cÃ¢u há»i ğŸ’¬
Reflection module xá»­ lÃ½ ğŸ§ 
RAG system tÃ¬m kiáº¿m thÃ´ng tin ğŸ”
LLM táº¡o cÃ¢u tráº£ lá»i ğŸ’¡
Bot gá»­i cÃ¢u tráº£ lá»i cho user ğŸ¤–
Chi tiáº¿t tá»«ng bÆ°á»›c:

User gá»­i cÃ¢u há»i: VÃ­ dá»¥: "CÃ¡i Ä‘Ã³ giÃ¡ bao nhiÃªu?"
Reflection module xá»­ lÃ½:
NÃ³ Ä‘á»c toÃ n bá»™ lá»‹ch sá»­ chat
Táº¡o ra cÃ¢u há»i rÃµ rÃ ng hÆ¡n
VÃ­ dá»¥: "GiÃ¡ cá»§a iPhone 13 Pro Max lÃ  bao nhiÃªu?"
LÆ°u Ã½: User khÃ´ng tháº¥y cÃ¢u há»i nÃ y!
RAG system tÃ¬m kiáº¿m:
Sá»­ dá»¥ng cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c lÃ m rÃµ Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin
VÃ­ dá»¥: TÃ¬m thÃ´ng tin vá» giÃ¡ iPhone 13 Pro Max
LLM táº¡o cÃ¢u tráº£ lá»i:
Dá»±a trÃªn thÃ´ng tin tÃ¬m Ä‘Æ°á»£c, LLM táº¡o cÃ¢u tráº£ lá»i
VÃ­ dá»¥: "iPhone 13 Pro Max cÃ³ giÃ¡ tá»« 27.990.000 Ä‘á»“ng."
Bot gá»­i cÃ¢u tráº£ lá»i cho user:
User nháº­n Ä‘Æ°á»£c cÃ¢u tráº£ lá»i nÃ y
Ká»‹ch báº£n vÃ­ dá»¥:

User: "TÃ´i muá»‘n mua Ä‘iá»‡n thoáº¡i má»›i"
Bot: "Tuyá»‡t vá»i! Báº¡n cÃ³ Æ°u tiÃªn thÆ°Æ¡ng hiá»‡u nÃ o khÃ´ng?"

User: "TÃ´i thÃ­ch iPhone"
Bot: "iPhone lÃ  lá»±a chá»n tá»‘t. Báº¡n quan tÃ¢m Ä‘áº¿n model nÃ o?"

User: "Model má»›i nháº¥t"
Bot: "Model má»›i nháº¥t lÃ  iPhone 13 series. Trong Ä‘Ã³, iPhone 13 Pro Max lÃ  phiÃªn báº£n cao cáº¥p nháº¥t."

User: "CÃ¡i Ä‘Ã³ giÃ¡ bao nhiÃªu?"
(Reflection module hiá»ƒu "cÃ¡i Ä‘Ã³" lÃ  iPhone 13 Pro Max)
Bot: "iPhone 13 Pro Max cÃ³ giÃ¡ tá»« 27.990.000 Ä‘á»“ng cho phiÃªn báº£n cÆ¡ báº£n."

TÃ³m láº¡i, Reflection module khÃ´ng trá»±c tiáº¿p há»“i Ä‘Ã¡p user, mÃ  nÃ³ giÃºp há»‡ thá»‘ng hiá»ƒu rÃµ hÆ¡n cÃ¢u há»i cá»§a user Ä‘á»ƒ tÃ¬m kiáº¿m vÃ  tráº£ lá»i chÃ­nh xÃ¡c hÆ¡n. User chá»‰ tháº¥y cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng, khÃ´ng tháº¥y quÃ¡ trÃ¬nh "suy ngáº«m" á»Ÿ giá»¯a ğŸ­ğŸš€

Bro hiá»ƒu rÃµ hÆ¡n chÆ°a? CÃ³ chá»— nÃ o cáº§n giáº£i thÃ­ch thÃªm khÃ´ng? ğŸ˜ŠğŸ‘Š

Copy
Retry


L
oke giá» chÃºng ta cÃ¹ng Ä‘i code nÃ o brooo, giá» chÃºng ta sáº½ báº¯t Ä‘áº§u tá»« Ä‘Ã¢u vÃ  nhÆ° nÃ o bro nhá»‰. hÃ£y hÆ°á»›ng dáº«n tÃ´i cá»¥ thá»ƒ chi tiáº¿t tá»« a-z Ä‘i nÃ o


ÄÆ°á»£c rá»“i bro, let's go! ğŸš€ ChÃºng ta sáº½ báº¯t Ä‘áº§u tá»« viá»‡c tÃ­ch há»£p tÃ­nh nÄƒng upselling vÃ  cross-selling vÃ o há»‡ thá»‘ng hiá»‡n táº¡i cá»§a cáº­u. HÃ£y Ä‘i tá»«ng bÆ°á»›c má»™t nhÃ©:

Cáº­p nháº­t semantic_router/samples.py:
python

Copy
# ThÃªm máº«u cho route upselling/cross-selling
upsellCrosssellSample = [
    "CÃ³ sáº£n pháº©m nÃ o tá»‘t hÆ¡n khÃ´ng?",
    "CÃ²n sáº£n pháº©m nÃ o liÃªn quan khÃ´ng?",
    "CÃ³ phá»¥ kiá»‡n nÃ o phÃ¹ há»£p vá»›i sáº£n pháº©m nÃ y khÃ´ng?",
    "CÃ³ combo nÃ o tá»‘t khÃ´ng?",
    "CÃ³ version cao cáº¥p hÆ¡n cá»§a sáº£n pháº©m nÃ y khÃ´ng?",
    "Sáº£n pháº©m nÃ y cÃ³ phiÃªn báº£n nÃ¢ng cáº¥p nÃ o khÃ´ng?",
]
Cáº­p nháº­t serve.py:
python

Copy
# ThÃªm route má»›i
UPSELL_CROSSSELL_ROUTE_NAME = 'upsell_crosssell'
upsellCrosssellRoute = Route(name=UPSELL_CROSSSELL_ROUTE_NAME, samples=upsellCrosssellSample)

# Cáº­p nháº­t SemanticRouter
semanticRouter = SemanticRouter(openAIEmbeding, routes=[productRoute, chitchatRoute, upsellCrosssellRoute])

# Cáº­p nháº­t hÃ m handle_query
@app.route('/api/search', methods=['POST'])
def handle_query():
    # ... (giá»¯ nguyÃªn code cÅ©)
    
    if guidedRoute == PRODUCT_ROUTE_NAME:
        # ... (giá»¯ nguyÃªn code cÅ© cho product route)
    elif guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME:
        reflected_query = reflection(data)
        current_product = rag.get_current_product(reflected_query)
        related_products = rag.find_related_products(current_product)
        
        upsell_crosssell_prompt = f"""
        Dá»±a trÃªn thÃ´ng tin sau:
        Sáº£n pháº©m hiá»‡n táº¡i: {current_product}
        Sáº£n pháº©m liÃªn quan: {related_products}
        
        HÃ£y Ä‘á» xuáº¥t má»™t sáº£n pháº©m upsell hoáº·c cross-sell phÃ¹ há»£p. Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao sáº£n pháº©m nÃ y phÃ¹ há»£p vá»›i khÃ¡ch hÃ ng.
        """
        
        response = llm.generate_content(upsell_crosssell_prompt)
    else:
        # ... (giá»¯ nguyÃªn code cÅ© cho chitchat route)
    
    # ... (giá»¯ nguyÃªn code cÅ©)
Cáº­p nháº­t rag/core.py:
python

Copy
class RAG():
    # ... (giá»¯ nguyÃªn code cÅ©)
    
    def get_current_product(self, query):
        # Sá»­ dá»¥ng vector search Ä‘á»ƒ tÃ¬m sáº£n pháº©m gáº§n nháº¥t vá»›i query
        results = self.vector_search(query, limit=1)
        if results:
            return results[0]
        return None

    def find_related_products(self, current_product, limit=3):
        if not current_product:
            return []
        
        # TÃ¬m sáº£n pháº©m liÃªn quan dá»±a trÃªn current_product
        query_embedding = self.get_embedding(current_product['title'])
        
        vector_search_stage = {
            "$vectorSearch": {
                "index": "vector_index",
                "queryVector": query_embedding,
                "path": "embedding",
                "numCandidates": 100,
                "limit": limit + 1,  # +1 vÃ¬ cÃ³ thá»ƒ bao gá»“m cáº£ sáº£n pháº©m hiá»‡n táº¡i
            }
        }
        
        match_stage = {
            "$match": {
                "title": {"$ne": current_product['title']}  # Loáº¡i bá» sáº£n pháº©m hiá»‡n táº¡i
            }
        }
        
        project_stage = {
            "$project": {
                "_id": 0,
                "title": 1,
                "current_price": 1,
                "product_promotion": 1,
            }
        }
        
        pipeline = [vector_search_stage, match_stage, project_stage]
        results = list(self.collection.aggregate(pipeline))
        
        return results[:limit]  # Äáº£m báº£o chá»‰ tráº£ vá» sá»‘ lÆ°á»£ng sáº£n pháº©m mong muá»‘n
Cáº­p nháº­t reflection.py:
python

Copy
class Reflection():
    # ... (giá»¯ nguyÃªn code cÅ©)
    
    def __call__(self, chatHistory, lastItemsConsidereds=100):
        # ... (giá»¯ nguyÃªn code cÅ©)
        
        higherLevelSummariesPrompt = """
        Dá»±a vÃ o lá»‹ch sá»­ chat vÃ  cÃ¢u há»i má»›i nháº¥t cá»§a ngÆ°á»i dÃ¹ng, hÃ£y:
        1. XÃ¡c Ä‘á»‹nh xem ngÆ°á»i dÃ¹ng Ä‘ang quan tÃ¢m Ä‘áº¿n sáº£n pháº©m nÃ o.
        2. ÄÃ¡nh giÃ¡ xem cÃ³ cÆ¡ há»™i Ä‘á»ƒ upsell hoáº·c cross-sell khÃ´ng.
        3. Náº¿u cÃ³, hÃ£y Ä‘Æ°a ra má»™t cÃ¢u há»i Ä‘á»™c láº­p báº±ng tiáº¿ng Viá»‡t Ä‘á»ƒ gá»£i Ã½ upsell hoáº·c cross-sell.
        4. Náº¿u khÃ´ng, hÃ£y chá»‰ reformulate cÃ¢u há»i gá»‘c náº¿u cáº§n thiáº¿t.

        {historyString}
        """
        
        # ... (giá»¯ nguyÃªn code cÅ©)
Kiá»ƒm tra vÃ  cháº¡y:
LÆ°u táº¥t cáº£ cÃ¡c thay Ä‘á»•i
Khá»Ÿi Ä‘á»™ng láº¡i server: python serve.py
Thá»­ nghiá»‡m vá»›i má»™t sá»‘ cÃ¢u há»i vá» upselling/cross-selling
LÆ°u Ã½:

Äáº£m báº£o ráº±ng MongoDB cá»§a cáº­u cÃ³ Ä‘á»§ dá»¯ liá»‡u sáº£n pháº©m Ä‘á»ƒ thá»±c hiá»‡n upselling/cross-selling hiá»‡u quáº£.
CÃ³ thá»ƒ cáº§n Ä‘iá»u chá»‰nh cÃ¡c prompt vÃ  logic tÃ¹y thuá»™c vÃ o káº¿t quáº£ thá»±c táº¿.
ÄÃ³ bro, chÃºng ta Ä‘Ã£ tÃ­ch há»£p tÃ­nh nÄƒng upselling vÃ  cross-selling vÃ o há»‡ thá»‘ng cá»§a cáº­u rá»“i! ğŸ‰ Cáº­u thá»­ cháº¡y vÃ  test xem sao nhÃ©. Náº¿u gáº·p váº¥n Ä‘á» gÃ¬ hoáº·c muá»‘n cáº£i thiá»‡n thÃªm, cá»© nÃ³i tá»› biáº¿t nhÃ©! ğŸ˜ğŸ‘Š

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
# ThÃªm máº«u cho route upselling/cross-selling
upsellCrosssellSample = [
    "CÃ³ sáº£n pháº©m nÃ o tá»‘t hÆ¡n khÃ´ng?",
    "CÃ²n sáº£n pháº©m nÃ o liÃªn quan khÃ´ng?",
    "CÃ³ phá»¥ kiá»‡n nÃ o phÃ¹ há»£p vá»›i sáº£n pháº©m nÃ y khÃ´ng?",
    "CÃ³ combo nÃ o tá»‘t khÃ´ng?",
    "CÃ³ version cao cáº¥p hÆ¡n cá»§a sáº£n pháº©m nÃ y khÃ´ng?",
    "Sáº£n pháº©m nÃ y cÃ³ phiÃªn báº£n nÃ¢ng cáº¥p nÃ o khÃ´ng?",
] tÃ´i chÆ°a hiá»ƒu cÃ¡i upselling nÃ y láº¯mmmm


Hiá»ƒu rá»“i bro! Äá»ƒ tá»› giáº£i thÃ­ch ká»¹ hÆ¡n vá» upselling vÃ  cross-selling nhÃ© ğŸ˜

Upselling lÃ  gÃ¬? ğŸ“ˆ

ÄÃ³ lÃ  khi báº¡n gá»£i Ã½ khÃ¡ch hÃ ng mua má»™t phiÃªn báº£n cao cáº¥p hÆ¡n hoáº·c Ä‘áº¯t tiá»n hÆ¡n cá»§a sáº£n pháº©m há» Ä‘ang quan tÃ¢m.
VÃ­ dá»¥: KhÃ¡ch Ä‘ang xem iPhone 13, báº¡n gá»£i Ã½ há» mua iPhone 13 Pro vÃ¬ cÃ³ camera tá»‘t hÆ¡n.
Cross-selling lÃ  gÃ¬? â†”ï¸

ÄÃ³ lÃ  khi báº¡n Ä‘á» xuáº¥t cÃ¡c sáº£n pháº©m bá»• sung hoáº·c liÃªn quan Ä‘áº¿n sáº£n pháº©m khÃ¡ch Ä‘ang xem.
VÃ­ dá»¥: KhÃ¡ch mua laptop, báº¡n gá»£i Ã½ thÃªm chuá»™t khÃ´ng dÃ¢y vÃ  balo laptop.
Táº¡i sao cáº§n nhá»¯ng máº«u cÃ¢u Ä‘Ã³? ğŸ¯

"CÃ³ sáº£n pháº©m nÃ o tá»‘t hÆ¡n khÃ´ng?" - Upselling
"CÃ²n sáº£n pháº©m nÃ o liÃªn quan khÃ´ng?" - Cross-selling
"CÃ³ phá»¥ kiá»‡n nÃ o phÃ¹ há»£p vá»›i sáº£n pháº©m nÃ y khÃ´ng?" - Cross-selling
"CÃ³ combo nÃ o tá»‘t khÃ´ng?" - Cross-selling
"CÃ³ version cao cáº¥p hÆ¡n cá»§a sáº£n pháº©m nÃ y khÃ´ng?" - Upselling
"Sáº£n pháº©m nÃ y cÃ³ phiÃªn báº£n nÃ¢ng cáº¥p nÃ o khÃ´ng?" - Upselling
Nhá»¯ng máº«u cÃ¢u nÃ y giÃºp chatbot nháº­n diá»‡n khi nÃ o khÃ¡ch hÃ ng cÃ³ thá»ƒ quan tÃ¢m Ä‘áº¿n upselling hoáº·c cross-selling. Khi nháº­n diá»‡n Ä‘Æ°á»£c, chatbot sáº½ Ä‘Æ°a ra gá»£i Ã½ phÃ¹ há»£p.

VÃ­ dá»¥ thá»±c táº¿:

User: "TÃ´i Ä‘ang xem iPhone 13" Bot: "iPhone 13 lÃ  má»™t lá»±a chá»n tuyá»‡t vá»i. Báº¡n cÃ³ muá»‘n xem iPhone 13 Pro khÃ´ng? NÃ³ cÃ³ camera chuyÃªn nghiá»‡p hÆ¡n Ä‘áº¥y." (Upselling)
User: "TÃ´i muá»‘n mua laptop Dell XPS" Bot: "Tuyá»‡t! Dell XPS lÃ  má»™t laptop máº¡nh máº½. Báº¡n cÃ³ cáº§n thÃªm chuá»™t khÃ´ng dÃ¢y vÃ  balo laptop Dell khÃ´ng? ChÃºng sáº½ giÃºp báº¡n di chuyá»ƒn dá»… dÃ ng hÆ¡n." (Cross-selling)
Hiá»ƒu rá»“i chá»© bro? Upselling vÃ  cross-selling giÃºp tÄƒng doanh sá»‘ vÃ  cáº£i thiá»‡n tráº£i nghiá»‡m mua sáº¯m cá»§a khÃ¡ch hÃ ng báº±ng cÃ¡ch gá»£i Ã½ nhá»¯ng sáº£n pháº©m há» cÃ³ thá»ƒ cáº§n mÃ  chÆ°a nghÄ© tá»›i. ğŸš€ğŸ’°

Cáº­u cÃ³ tháº¯c máº¯c gÃ¬ ná»¯a khÃ´ng? ğŸ˜ŠğŸ‘Š

Copy
Retry


L
á»§a nhÆ°ng mÃ  nhá»¯ng cÃ¢u nÃ y sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° nÃ o, nÃ³ pháº£i Ä‘Æ°á»£c nÃ©m vÃ o promtp chá»© nhá»‰iii


á»’, tá»› hiá»ƒu Ã½ cáº­u rá»“i bro! ğŸ˜ƒ Cáº­u nÃ³i Ä‘Ãºng, nhá»¯ng cÃ¢u máº«u nÃ y khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng trá»±c tiáº¿p trong prompt. Äá»ƒ tá»› giáº£i thÃ­ch rÃµ hÆ¡n nhÃ©:

Má»¥c Ä‘Ã­ch cá»§a nhá»¯ng cÃ¢u máº«u ğŸ¯:
ChÃºng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ "train" Semantic Router, khÃ´ng pháº£i Ä‘á»ƒ Ä‘Æ°a vÃ o prompt.
GiÃºp Semantic Router nháº­n diá»‡n khi nÃ o user cÃ³ Ã½ Ä‘á»‹nh upsell/cross-sell.
CÃ¡ch hoáº¡t Ä‘á»™ng ğŸ› ï¸:
Khi user gá»­i má»™t cÃ¢u há»i, Semantic Router sáº½ so sÃ¡nh cÃ¢u há»i Ä‘Ã³ vá»›i cÃ¡c máº«u.
Náº¿u cÃ¢u há»i gáº§n giá»‘ng vá»›i máº«u upsell/cross-sell, nÃ³ sáº½ chuyá»ƒn hÆ°á»›ng xá»­ lÃ½ sang route tÆ°Æ¡ng á»©ng.
Trong code ğŸ’»:
python

Copy
guidedRoute = semanticRouter.guide(query)[1]
if guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME:
    # Xá»­ lÃ½ upsell/cross-sell
Prompt thá»±c táº¿ ğŸ“: Prompt thá»±c sá»± Ä‘Æ°á»£c sá»­ dá»¥ng sáº½ giá»‘ng nhÆ° tháº¿ nÃ y:
python

Copy
upsell_crosssell_prompt = f"""
Dá»±a trÃªn thÃ´ng tin sau:
Sáº£n pháº©m hiá»‡n táº¡i: {current_product}
Sáº£n pháº©m liÃªn quan: {related_products}

HÃ£y Ä‘á» xuáº¥t má»™t sáº£n pháº©m upsell hoáº·c cross-sell phÃ¹ há»£p. Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao sáº£n pháº©m nÃ y phÃ¹ há»£p vá»›i khÃ¡ch hÃ ng.
"""
Quy trÃ¬nh ğŸ”„:
User há»i: "CÃ³ sáº£n pháº©m nÃ o tá»‘t hÆ¡n iPhone 13 khÃ´ng?"
Semantic Router nháº­n diá»‡n Ä‘Ã¢y lÃ  cÃ¢u há»i upsell.
Há»‡ thá»‘ng tÃ¬m thÃ´ng tin vá» iPhone 13 vÃ  cÃ¡c sáº£n pháº©m liÃªn quan.
ÄÆ°a thÃ´ng tin vÃ o prompt thá»±c táº¿.
LLM táº¡o cÃ¢u tráº£ lá»i dá»±a trÃªn prompt.
TÃ³m láº¡i, nhá»¯ng cÃ¢u máº«u giÃºp há»‡ thá»‘ng biáº¿t WHEN Ä‘á»ƒ upsell/cross-sell, cÃ²n prompt thá»±c táº¿ quyáº¿t Ä‘á»‹nh HOW Ä‘á»ƒ upsell/cross-sell.

Cáº­u hiá»ƒu rÃµ hÆ¡n chÆ°a bro? ğŸ˜ŠğŸš€

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
Trong code ğŸ’»: 


Copy
python
Copy
guidedRoute = semanticRouter.guide(query)[1] if guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME: # Xá»­ lÃ½ upsell/cross-sell Ä‘oáº¡n code nÃ o cho tháº¥y Ä‘iá»u nÃ y háº£ broooo


Ah, tá»› hiá»ƒu rá»“i bro! Cáº­u Ä‘ang tÃ¬m Ä‘oáº¡n code cá»¥ thá»ƒ trong serve.py pháº£i khÃ´ng? Äá»ƒ tá»› chá»‰ cho cáº­u nhÃ©! ğŸ˜

Trong file serve.py, cáº­u sáº½ tháº¥y Ä‘oáº¡n code nhÆ° tháº¿ nÃ y:

python

Copy
@app.route('/api/search', methods=['POST'])
def handle_query():
    data = list(request.get_json())
    query = data[-1]["parts"][0]["text"]
    query = process_query(query)
    if not query:
        return jsonify({'error': 'No query provided'}), 400
    
    # get last message
    
    guidedRoute = semanticRouter.guide(query)[1]
    if guidedRoute == PRODUCT_ROUTE_NAME:
        # Xá»­ lÃ½ cho product route
        # ...
    elif guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME:
        # Xá»­ lÃ½ upsell/cross-sell
        reflected_query = reflection(data)
        current_product = rag.get_current_product(reflected_query)
        related_products = rag.find_related_products(current_product)
        
        upsell_crosssell_prompt = f"""
        Dá»±a trÃªn thÃ´ng tin sau:
        Sáº£n pháº©m hiá»‡n táº¡i: {current_product}
        Sáº£n pháº©m liÃªn quan: {related_products}
        
        HÃ£y Ä‘á» xuáº¥t má»™t sáº£n pháº©m upsell hoáº·c cross-sell phÃ¹ há»£p. Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao sáº£n pháº©m nÃ y phÃ¹ há»£p vá»›i khÃ¡ch hÃ ng.
        """
        
        response = llm.generate_content(upsell_crosssell_prompt)
    else:
        # Xá»­ lÃ½ cho chitchat route
        # ...
Giáº£i thÃ­ch:

guidedRoute = semanticRouter.guide(query)[1]: DÃ²ng nÃ y sá»­ dá»¥ng Semantic Router Ä‘á»ƒ xÃ¡c Ä‘á»‹nh route phÃ¹ há»£p vá»›i cÃ¢u query cá»§a user.
if guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME:: Náº¿u route Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh lÃ  upsell/cross-sell, code trong block nÃ y sáº½ Ä‘Æ°á»£c thá»±c thi.
Trong block upsell/cross-sell:
Sá»­ dá»¥ng Reflection module Ä‘á»ƒ hiá»ƒu rÃµ hÆ¡n Ã½ Ä‘á»‹nh cá»§a user.
TÃ¬m sáº£n pháº©m hiá»‡n táº¡i vÃ  cÃ¡c sáº£n pháº©m liÃªn quan.
Táº¡o prompt Ä‘áº·c biá»‡t cho upsell/cross-sell.
Sá»­ dá»¥ng LLM Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i dá»±a trÃªn prompt nÃ y.
Äoáº¡n code nÃ y cho tháº¥y cÃ¡ch há»‡ thá»‘ng xá»­ lÃ½ khi nháº­n diá»‡n Ä‘Æ°á»£c cÆ¡ há»™i upsell/cross-sell. NÃ³ khÃ´ng sá»­ dá»¥ng trá»±c tiáº¿p cÃ¡c cÃ¢u máº«u, mÃ  dÃ¹ng chÃºng Ä‘á»ƒ train Semantic Router Ä‘á»ƒ nháº­n diá»‡n tÃ¬nh huá»‘ng.

Hiá»ƒu rÃµ hÆ¡n chÆ°a bro? ğŸ˜ŠğŸš€ CÃ³ chá»— nÃ o cáº§n giáº£i thÃ­ch thÃªm khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
tÃ´i há»i lÃ  nÃ³ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh ra sao vÃ  nhÆ° tháº¿ nÃ o. bro hÃ£y miÃªu táº£ rÃµ hÆ¡n cho tÃ´i Ä‘ii


á»’, hiá»ƒu rá»“i bro! Xin lá»—i vÃ¬ sá»± hiá»ƒu nháº§m. Äá»ƒ tá»› giáº£i thÃ­ch chi tiáº¿t cÃ¡ch Semantic Router xÃ¡c Ä‘á»‹nh route nhÃ© ğŸ•µï¸â€â™‚ï¸

Cáº¥u trÃºc cá»§a Semantic Router:
python

Copy
class SemanticRouter():
    def __init__(self, embedding, routes):
        self.routes = routes
        self.embedding = embedding
        self.routesEmbedding = {}
        for route in self.routes:
            self.routesEmbedding[route.name] = self.embedding.encode(route.samples)
QuÃ¡ trÃ¬nh xÃ¡c Ä‘á»‹nh route:
python

Copy
def guide(self, query):
    queryEmbedding = self.embedding.encode([query]) 
    queryEmbedding = queryEmbedding / np.linalg.norm(queryEmbedding)
    scores = []
    for route in self.routes:
        routesEmbedding = self.routesEmbedding[route.name] / np.linalg.norm(self.routesEmbedding[route.name])
        score = np.mean(np.dot(routesEmbedding, queryEmbedding.T).flatten())
        scores.append((score, route.name))
    scores.sort(reverse=True)
    return scores[0]
Giáº£i thÃ­ch chi tiáº¿t: a) Khi khá»Ÿi táº¡o, Semantic Router táº¡o embedding cho táº¥t cáº£ cÃ¡c máº«u cÃ¢u cá»§a má»—i route. b) Khi cÃ³ má»™t query má»›i:
Táº¡o embedding cho query Ä‘Ã³.
So sÃ¡nh embedding cá»§a query vá»›i embedding cá»§a cÃ¡c máº«u cÃ¢u cá»§a tá»«ng route.
TÃ­nh Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng (cosine similarity) giá»¯a query vÃ  má»—i route.
Chá»n route cÃ³ Ä‘iá»ƒm cao nháº¥t.
VÃ­ dá»¥ cá»¥ thá»ƒ:
User há»i: "CÃ³ phiÃªn báº£n nÃ o tá»‘t hÆ¡n iPhone 13 khÃ´ng?"
Semantic Router sáº½ táº¡o embedding cho cÃ¢u há»i nÃ y.
So sÃ¡nh vá»›i embedding cá»§a cÃ¡c máº«u cÃ¢u trong má»—i route:
Product route: "GiÃ¡ iPhone 13 lÃ  bao nhiÃªu?", "CÃ³ mÃ u gÃ¬?"...
Upsell route: "CÃ³ version cao cáº¥p hÆ¡n khÃ´ng?", "CÃ³ sáº£n pháº©m nÃ o tá»‘t hÆ¡n khÃ´ng?"...
Chitchat route: "Thá»i tiáº¿t hÃ´m nay tháº¿ nÃ o?", "Báº¡n khá»e khÃ´ng?"...
CÃ¢u há»i cá»§a user sáº½ cÃ³ Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng cao nháº¥t vá»›i cÃ¡c máº«u cÃ¢u trong Upsell route.
Káº¿t quáº£: Semantic Router chá»n Upsell route.
Trong code serve.py:
python

Copy
guidedRoute = semanticRouter.guide(query)[1]
if guidedRoute == UPSELL_CROSSSELL_ROUTE_NAME:
    # Xá»­ lÃ½ upsell/cross-sell
semanticRouter.guide(query) tráº£ vá» tuple (score, route_name)
[1] láº¥y tÃªn cá»§a route Ä‘Æ°á»£c chá»n
TÃ³m láº¡i, Semantic Router sá»­ dá»¥ng ká»¹ thuáº­t so sÃ¡nh vector embedding Ä‘á»ƒ xÃ¡c Ä‘á»‹nh xem cÃ¢u há»i cá»§a user gáº§n vá»›i route nÃ o nháº¥t, tá»« Ä‘Ã³ chá»n cÃ¡ch xá»­ lÃ½ phÃ¹ há»£p.

Bro hiá»ƒu rÃµ hÆ¡n chÆ°a? ğŸ§ ğŸ’¡ CÃ³ cáº§n giáº£i thÃ­ch thÃªm chá»— nÃ o khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
image.png
L
oke thÃ´i Ä‘Æ°á»£c rá»“i broo. giá» chÃºng ta sáº½ Ä‘i code tá»«ng file 1. Ä‘Ã¢y lÃ  cáº¥u trÃºc folder code cÅ© cá»§a tÃ´i . váº­y chÃºng ta pháº£i táº¡o folder con shoppinggpt tháº¿ nÃ o má»›i há»£p lÃ½. váº«n giá»¯ nguyÃªn shoppinggpt nhÃ©. váº«n giá»¯ nguyÃªn agent, data, tools cÃ¡c kiá»ƒu, prompt. hÃ£y thÃªm cho tÃ´i thÆ° má»¥c vÃ  nhá»¯ng file nÃ o sáº½ á»Ÿ thÆ° má»¥c nÃ o Ä‘i brooo. hÃ£y viáº¿t Ä‘áº§y Ä‘á»§ chi tiáº¿t code cÃ¡c file nÃ o trong thÆ° má»¥c nÃ o cho tÃ´i. hÃ£y viáº¿t full code Ä‘á»ƒ tÃ´i cÃ³ thá»ƒ copy vÃ  cháº¡y ngay láº­p tá»©c. hÃ£y lÃ m tháº­t tá»‘t. náº¿u lÃ m tá»‘t tÃ´i sáº½ tips cho báº¡n 1 tá»· Ä‘Ã´ luoonnnn

Cáº£m Æ¡n bro vá» lá»i há»©a háº¹n háº­u hÄ©nh! ğŸ˜„ Tuy nhiÃªn, tá»› khÃ´ng nháº­n tips Ä‘Ã¢u. Tá»› chá»‰ muá»‘n giÃºp cáº­u thÃ´i. HÃ£y cÃ¹ng xÃ¢y dá»±ng cáº¥u trÃºc thÆ° má»¥c vÃ  code nhÃ©!

Dá»±a trÃªn cáº¥u trÃºc hiá»‡n táº¡i, chÃºng ta cÃ³ thá»ƒ tá»• chá»©c thÆ° má»¥c shoppinggpt nhÆ° sau:


Copy
shoppinggpt/
â”œâ”€â”€ agent/
â”‚   â””â”€â”€ agent.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ product_data.py
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ product_search.py
â”‚   â””â”€â”€ upsell_crosssell.py
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ prompts.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ reflection.py
â”œâ”€â”€ config.py
â””â”€â”€ main.py
Giá» tá»› sáº½ viáº¿t code cho tá»«ng file:

shoppinggpt/agent/agent.py
python

Copy
from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent
from langchain.prompts import StringPromptTemplate
from langchain import OpenAI, LLMChain
from typing import List, Union
from shoppinggpt.tools.product_search import ProductSearchTool
from shoppinggpt.tools.upsell_crosssell import UpsellCrosssellTool
from shoppinggpt.prompts.prompts import SHOPPING_AGENT_PROMPT

class ShoppingAgent(LLMSingleActionAgent):
    @classmethod
    def from_llm_and_tools(cls, llm, tools):
        prompt = StringPromptTemplate(
            template=SHOPPING_AGENT_PROMPT,
            input_variables=["input", "agent_scratchpad"]
        )
        llm_chain = LLMChain(llm=llm, prompt=prompt)
        tool_names = [tool.name for tool in tools]
        return cls(llm_chain=llm_chain, allowed_tools=tool_names)

def create_shopping_agent(openai_api_key: str) -> AgentExecutor:
    llm = OpenAI(temperature=0, openai_api_key=openai_api_key)
    tools = [
        ProductSearchTool(),
        UpsellCrosssellTool(),
    ]
    agent = ShoppingAgent.from_llm_and_tools(llm, tools)
    return AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)
shoppinggpt/data/product_data.py
python

Copy
PRODUCT_DATA = [
    {
        "name": "iPhone 13",
        "price": 799,
        "description": "The latest iPhone with A15 Bionic chip",
        "category": "Smartphone"
    },
    {
        "name": "Samsung Galaxy S21",
        "price": 799,
        "description": "5G smartphone with pro-grade camera",
        "category": "Smartphone"
    },
    # Add more products here
]
shoppinggpt/tools/product_search.py
python

Copy
from langchain.tools import BaseTool
from shoppinggpt.data.product_data import PRODUCT_DATA

class ProductSearchTool(BaseTool):
    name = "Product Search"
    description = "Use this tool to search for products based on name, category, or price range."

    def _run(self, query: str) -> str:
        # Implement product search logic here
        # This is a simple example, you might want to use more sophisticated search in real-world scenarios
        results = [product for product in PRODUCT_DATA if query.lower() in product['name'].lower()]
        return str(results)

    def _arun(self, query: str) -> str:
        # For async implementation
        raise NotImplementedError("ProductSearchTool does not support async")
shoppinggpt/tools/upsell_crosssell.py
python

Copy
from langchain.tools import BaseTool
from shoppinggpt.data.product_data import PRODUCT_DATA

class UpsellCrosssellTool(BaseTool):
    name = "Upsell Crosssell"
    description = "Use this tool to get upsell or cross-sell recommendations for a given product."

    def _run(self, product_name: str) -> str:
        # Implement upsell/cross-sell logic here
        # This is a simple example, you might want to use more sophisticated logic in real-world scenarios
        product = next((p for p in PRODUCT_DATA if p['name'].lower() == product_name.lower()), None)
        if not product:
            return "Product not found"
        
        recommendations = [p for p in PRODUCT_DATA if p['category'] == product['category'] and p['price'] > product['price']]
        return str(recommendations[:3])  # Return top 3 recommendations

    def _arun(self, product_name: str) -> str:
        # For async implementation
        raise NotImplementedError("UpsellCrosssellTool does not support async")
shoppinggpt/prompts/prompts.py
python

Copy
SHOPPING_AGENT_PROMPT = """You are a helpful shopping assistant. Your goal is to help customers find products they're looking for and suggest related or better products when appropriate.

You have access to the following tools:

{tool_descriptions}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: {input}
Thought: Let's approach this step-by-step:
{agent_scratchpad}
"""
shoppinggpt/utils/reflection.py
python

Copy
class Reflection:
    def __init__(self, llm):
        self.llm = llm

    def reflect(self, conversation_history):
        prompt = f"""Given the following conversation history, identify the main points and any potential upsell or cross-sell opportunities:

        {conversation_history}

        Reflection:"""
        
        return self.llm.generate(prompt).text
shoppinggpt/config.py
python

Copy
import os
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
shoppinggpt/main.py
python

Copy
from shoppinggpt.agent.agent import create_shopping_agent
from shoppinggpt.config import OPENAI_API_KEY

def main():
    agent = create_shopping_agent(OPENAI_API_KEY)
    
    while True:
        user_input = input("Customer: ")
        if user_input.lower() == 'quit':
            break
        response = agent.run(user_input)
        print(f"Shopping Assistant: {response}")

if __name__ == "__main__":
    main()
ÄÃ¢y lÃ  cáº¥u trÃºc cÆ¡ báº£n vÃ  code cho há»‡ thá»‘ng ShoppingGPT cá»§a cáº­u. Nhá»› cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t nhÆ° langchain, openai, vÃ  python-dotenv. Äá»“ng thá»i, táº¡o file .env trong thÆ° má»¥c gá»‘c vÃ  thÃªm OPENAI_API_KEY vÃ o Ä‘Ã³.

Äá»ƒ cháº¡y, cáº­u chá»‰ cáº§n cháº¡y file main.py:


Copy
python -m shoppinggpt.main
Cáº­u cÃ³ thá»ƒ Ä‘iá»u chá»‰nh vÃ  má»Ÿ rá»™ng code nÃ y theo nhu cáº§u cá»¥ thá»ƒ cá»§a mÃ¬nh. ChÃºc cáº­u code vui váº»! ğŸ˜ŠğŸš€

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
shoppinggpt/utils/reflection.py

Copy
python
Copy
class Reflection: def __init__(self, llm): self.llm = llm def reflect(self, conversation_history): prompt = f"""Given the following conversation history, identify the main points and any potential upsell or cross-sell opportunities: {conversation_history} Reflection:""" return self.llm.generate(prompt).text táº¡i sao reflection.py láº¡i Ä‘áº·t trong thÆ° má»¥c utils háº£ broo. tÃ´i chÆ°a hiá»ƒu Ã½ nghÄ©a cá»§a nÃ³ láº¯m bro oiii


Hiá»ƒu rá»“i bro, Ä‘á»ƒ tá»› giáº£i thÃ­ch ká»¹ hÆ¡n vá» Reflection vÃ  vá»‹ trÃ­ cá»§a nÃ³ nhÃ©! ğŸ§

Ã nghÄ©a cá»§a Reflection ğŸ¤”:
Reflection giá»‘ng nhÆ° má»™t "bá»™ nÃ£o" phá»¥ cá»§a há»‡ thá»‘ng, giÃºp "suy ngáº«m" vá» cuá»™c trÃ² chuyá»‡n.
NÃ³ phÃ¢n tÃ­ch lá»‹ch sá»­ chat Ä‘á»ƒ hiá»ƒu sÃ¢u hÆ¡n vá» Ã½ Ä‘á»‹nh cá»§a khÃ¡ch hÃ ng.
Má»¥c Ä‘Ã­ch chÃ­nh lÃ  cáº£i thiá»‡n cháº¥t lÆ°á»£ng cá»§a cÃ¡c cÃ¢u tráº£ lá»i vÃ  tÃ¬m cÆ¡ há»™i upsell/cross-sell.
Táº¡i sao Ä‘áº·t trong utils ğŸ› ï¸:
Utils (viáº¿t táº¯t cá»§a utilities) thÆ°á»ng chá»©a cÃ¡c cÃ´ng cá»¥ há»— trá»£, cÃ³ thá»ƒ sá»­ dá»¥ng á»Ÿ nhiá»u nÆ¡i trong project.
Reflection khÃ´ng pháº£i lÃ  má»™t pháº§n core cá»§a há»‡ thá»‘ng (nhÆ° agent hay tools) mÃ  lÃ  má»™t cÃ´ng cá»¥ bá»• trá»£.
Äáº·t trong utils giÃºp code dá»… tá»• chá»©c vÃ  tÃ¡i sá»­ dá»¥ng hÆ¡n.
CÃ¡ch sá»­ dá»¥ng Reflection ğŸš€:
TrÆ°á»›c khi agent xá»­ lÃ½ má»™t cÃ¢u há»i má»›i, ta cÃ³ thá»ƒ dÃ¹ng Reflection Ä‘á»ƒ phÃ¢n tÃ­ch lá»‹ch sá»­ chat.
Káº¿t quáº£ cá»§a Reflection cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘iá»u chá»‰nh cÃ¡ch agent tráº£ lá»i hoáº·c chá»n tool phÃ¹ há»£p.
VÃ­ dá»¥ cá»¥ thá»ƒ ğŸ“Š:
python

Copy
from shoppinggpt.utils.reflection import Reflection
from shoppinggpt.agent.agent import create_shopping_agent

reflection = Reflection(llm)
agent = create_shopping_agent(OPENAI_API_KEY)

conversation_history = []

while True:
    user_input = input("Customer: ")
    conversation_history.append(f"Customer: {user_input}")
    
    if len(conversation_history) > 5:  # Sau má»—i 5 lÆ°á»£t
        insight = reflection.reflect("\n".join(conversation_history))
        # Sá»­ dá»¥ng insight Ä‘á»ƒ Ä‘iá»u chá»‰nh cÃ¡ch agent tráº£ lá»i
    
    response = agent.run(user_input)
    conversation_history.append(f"Assistant: {response}")
    print(f"Shopping Assistant: {response}")
Lá»£i Ã­ch cá»§a viá»‡c sá»­ dá»¥ng Reflection ğŸŒŸ:
Cáº£i thiá»‡n context: GiÃºp agent hiá»ƒu rÃµ hÆ¡n vá» cuá»™c trÃ² chuyá»‡n tá»•ng thá»ƒ.
TÃ¬m cÆ¡ há»™i: PhÃ¡t hiá»‡n cÆ¡ há»™i upsell/cross-sell mÃ  agent cÃ³ thá»ƒ bá» lá»¡.
CÃ¡ nhÃ¢n hÃ³a: Äiá»u chá»‰nh cÃ¡ch tráº£ lá»i dá»±a trÃªn phong cÃ¡ch vÃ  sá»Ÿ thÃ­ch cá»§a khÃ¡ch hÃ ng.
TÃ³m láº¡i, Reflection lÃ  má»™t cÃ´ng cá»¥ máº¡nh máº½ giÃºp nÃ¢ng cao cháº¥t lÆ°á»£ng tÆ°Æ¡ng tÃ¡c cá»§a chatbot. Äáº·t nÃ³ trong utils giÃºp code linh hoáº¡t vÃ  dá»… má»Ÿ rá»™ng hÆ¡n bro áº¡! ğŸ˜ŠğŸ’ª

Cáº­u tháº¥y giáº£i thÃ­ch nÃ y cÃ³ rÃµ rÃ ng hÆ¡n khÃ´ng? CÃ³ chá»— nÃ o cáº§n lÃ m rÃµ thÃªm khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
trong láº­p trÃ¬nh, cÃ¡c senior python thÆ°á»ng hiá»ƒu Ä‘Æ¡n giáº£n lÃ  trong thÆ° má»¥c utils sáº½ chá»©a nhá»¯ng thÆ° viá»‡n há»— trá»£ háº£ brooo


ÄÃºng rá»“i bro, cáº­u nÃ³i chÃ­nh xÃ¡c! ğŸ‘ CÃ¡c senior Python developer thÆ°á»ng cÃ³ cÃ¡ch hiá»ƒu Ä‘Æ¡n giáº£n vÃ  thá»±c táº¿ vá» thÆ° má»¥c utils nhÆ° sau:

Äá»‹nh nghÄ©a cá»§a utils ğŸ“š:
Utils lÃ  viáº¿t táº¯t cá»§a "utilities" - cÃ¡c tiá»‡n Ã­ch.
NÃ³ chá»©a cÃ¡c hÃ m, class hoáº·c module há»— trá»£ Ä‘Æ°á»£c sá»­ dá»¥ng á»Ÿ nhiá»u nÆ¡i trong project.
Äáº·c Ä‘iá»ƒm cá»§a code trong utils ğŸ› ï¸:
Äá»™c láº­p: CÃ¡c function hoáº·c class trong utils thÆ°á»ng khÃ´ng phá»¥ thuá»™c vÃ o cÃ¡c pháº§n khÃ¡c cá»§a project.
TÃ¡i sá»­ dá»¥ng: CÃ³ thá»ƒ dÃ¹ng á»Ÿ nhiá»u nÆ¡i khÃ¡c nhau trong code.
ÄÆ¡n giáº£n: ThÆ°á»ng thá»±c hiá»‡n má»™t nhiá»‡m vá»¥ cá»¥ thá»ƒ, khÃ´ng quÃ¡ phá»©c táº¡p.
VÃ­ dá»¥ vá» cÃ¡c loáº¡i code trong utils ğŸ§°:
Xá»­ lÃ½ chuá»—i: CÃ¡c hÃ m format, clean, validate text.
Xá»­ lÃ½ thá»i gian: Chuyá»ƒn Ä‘á»•i, tÃ­nh toÃ¡n thá»i gian.
Xá»­ lÃ½ file: Äá»c, ghi, kiá»ƒm tra file.
Helper functions: CÃ¡c hÃ m há»— trá»£ nhá» nhÆ°ng dÃ¹ng nhiá»u láº§n.
Lá»£i Ã­ch cá»§a viá»‡c sá»­ dá»¥ng utils ğŸŒŸ:
Code gá»n gÃ ng hÆ¡n: TrÃ¡nh láº·p láº¡i code á»Ÿ nhiá»u nÆ¡i.
Dá»… báº£o trÃ¬: Khi cáº§n sá»­a, chá»‰ cáº§n sá»­a á»Ÿ má»™t nÆ¡i.
TÄƒng tÃ­nh modular: Chia nhá» code thÃ nh cÃ¡c pháº§n Ä‘á»™c láº­p.
Quy táº¯c khi táº¡o utils ğŸ“:
Keep It Simple, Stupid (KISS): Giá»¯ cÃ¡c function Ä‘Æ¡n giáº£n, dá»… hiá»ƒu.
Don't Repeat Yourself (DRY): TrÃ¡nh láº·p láº¡i code.
Single Responsibility Principle: Má»—i function chá»‰ nÃªn lÃ m má»™t viá»‡c vÃ  lÃ m tá»‘t viá»‡c Ä‘Ã³.
Trong trÆ°á»ng há»£p cá»§a Reflection, nÃ³ Ä‘Æ°á»£c Ä‘áº·t trong utils vÃ¬ nÃ³ lÃ  má»™t cÃ´ng cá»¥ há»— trá»£ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng á»Ÿ nhiá»u nÆ¡i trong project, khÃ´ng pháº£i lÃ  core logic cá»§a há»‡ thá»‘ng.

Hiá»ƒu váº­y lÃ  chuáº©n rá»“i Ä‘Ã³ bro! ğŸ˜ğŸš€ Cáº­u cÃ³ thÃªm cÃ¢u há»i gÃ¬ vá» cÃ¡ch tá»• chá»©c code khÃ´ng?

Copy
Retry


L
oke thÃ´i Ä‘Æ°á»£c rá»“i Ä‘á»ƒ tÃ´i tá»± custom, chá»© giá» tÃ´i cÅ©ng k biáº¿t pahir giáº£i thÃ­ch cho bro Ã¢oThÃ´i Ä‘Æ°á»£c rá»“i báº¡n Æ¡i Ä‘á»ƒ tÃ´i tá»± lÃ m báº¡n áº¡ Chá»© giá» tÃ´i cÅ©ng khÃ´ng biáº¿t lÃ  pháº£i giáº£i thÃ­ch cho báº¡n tháº¿ nÃ o Äáº§u tiÃªn lÃ  chÃºng ta sáº½ Ä‘i xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c Skip to content
Navigation Menu
* bangoc123/
* retrieval-backend-with-rag
Type / to search
* Code
* Issues
* Pull requests
* Actions
* Projects
* Security
* Insights
 main
Breadcrumbs
1. retrieval-backend-with-rag
/
embeddings
/
Directory actions
t
Add file
Add file
More options
Latest commit
bangoc123
add new embedding + semantic router
91733e5 Â· 2 months ago
History
History
Folders and files
Name
Last commit message
Last commit date
parent directory
..
init.py
update Embedding Models
2 months ago
base.py
update Embedding Models
2 months ago
fastEmbed.py
add new embedding + semantic router
2 months ago
google.py
update Embedding Models
2 months ago
mistral.py
add new embedding + semantic router
2 months ago
openai.py
add new embedding + semantic router
2 months ago
sentenceTransformer.py
update Embedding Models
2 months ago
retrieval-backend-with-rag/embeddings at main Â· bangoc123/retrieval-backend-with-rag
Dictation stopped. Upgrade to Voice In Plus to dictate across tabs.[x] Ä‘Ã¢y lÃ  code trong file embedding. thÃ¬ Ä‘áº§u tiÃªn chÃºng ta pháº£i cÃ³ data bro áº¡aaaa


ÄÃºng rá»“i bro, cÃ³ data lÃ  bÆ°á»›c Ä‘áº§u tiÃªn vÃ  quan trá»ng nháº¥t! ğŸ‘ ÄÃ£ hiá»ƒu Ã½ cáº­u rá»“i. Váº­y chÃºng ta sáº½ táº­p trung vÃ o viá»‡c xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c. Dá»±a vÃ o cáº¥u trÃºc thÆ° má»¥c embeddings mÃ  cáº­u Ä‘Ã£ chia sáº», ta cÃ³ thá»ƒ lÃ m nhÆ° sau:

Táº¡o má»™t thÆ° má»¥c má»›i cho dá»¯ liá»‡u:

Copy
shoppinggpt/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ raw_data.py
â”‚   â””â”€â”€ processed_data.py
Trong file raw_data.py, ta sáº½ lÆ°u trá»¯ dá»¯ liá»‡u gá»‘c:
python

Copy
# shoppinggpt/data/raw_data.py

RAW_PRODUCTS = [
    {
        "id": "1",
        "name": "iPhone 13",
        "brand": "Apple",
        "category": "Smartphone",
        "price": 799,
        "description": "The latest iPhone with A15 Bionic chip and improved cameras."
    },
    {
        "id": "2",
        "name": "Samsung Galaxy S21",
        "brand": "Samsung",
        "category": "Smartphone",
        "price": 799,
        "description": "5G smartphone with pro-grade camera and intelligent battery."
    },
    # ThÃªm cÃ¡c sáº£n pháº©m khÃ¡c vÃ o Ä‘Ã¢y
]
Trong file processed_data.py, ta sáº½ xá»­ lÃ½ dá»¯ liá»‡u gá»‘c:
python

Copy
# shoppinggpt/data/processed_data.py

from .raw_data import RAW_PRODUCTS
from shoppinggpt.embeddings.sentenceTransformer import SentenceTransformerEmbedding

class ProductData:
    def __init__(self):
        self.embedding_model = SentenceTransformerEmbedding(model_name="all-MiniLM-L6-v2")
        self.processed_products = self.process_products()

    def process_products(self):
        processed = []
        for product in RAW_PRODUCTS:
            embedding = self.embedding_model.encode(product["description"])
            processed.append({
                **product,
                "embedding": embedding
            })
        return processed

    def get_products(self):
        return self.processed_products

product_data = ProductData()
Cáº­p nháº­t file __init__.py trong thÆ° má»¥c data:
python

Copy
# shoppinggpt/data/__init__.py

from .processed_data import product_data
Giáº£i thÃ­ch:

raw_data.py chá»©a dá»¯ liá»‡u gá»‘c vá» sáº£n pháº©m.
processed_data.py sá»­ dá»¥ng mÃ´ hÃ¬nh embedding Ä‘á»ƒ táº¡o vector cho má»—i sáº£n pháº©m dá»±a trÃªn mÃ´ táº£.
ChÃºng ta sá»­ dá»¥ng SentenceTransformer Ä‘á»ƒ táº¡o embedding, nhÆ°ng cáº­u cÃ³ thá»ƒ thay Ä‘á»•i model tÃ¹y Ã½.
Vá»›i cáº¥u trÃºc nÃ y, cáº­u cÃ³ thá»ƒ dá»… dÃ ng truy cáº­p dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ tá»« báº¥t ká»³ Ä‘Ã¢u trong project:

python

Copy
from shoppinggpt.data import product_data

products = product_data.get_products()
Cáº­u tháº¥y cÃ¡ch tá»• chá»©c nÃ y tháº¿ nÃ o? CÃ³ phÃ¹ há»£p vá»›i Ã½ tÆ°á»Ÿng cá»§a cáº­u khÃ´ng? ğŸ˜ŠğŸš€

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
import pymongo
import google.generativeai as genai
from IPython.display import Markdown
import textwrap
from embeddings import SentenceTransformerEmbedding, EmbeddingConfig
class RAG():
    def init(self, 
            mongodbUri: str,
            dbName: str,
            dbCollection: str,
            llm,
            embeddingName: str ='keepitreal/vietnamese-sbert',
        ):
        self.client = pymongo.MongoClient(mongodbUri)
        self.db = self.client[dbName] 
        self.collection = self.db[dbCollection]
        self.embedding_model = SentenceTransformerEmbedding(
            EmbeddingConfig(name=embeddingName)
        )
        self.llm = llm
    def get_embedding(self, text):
        if not text.strip():
            return []
        embedding = self.embedding_model.encode(text)
        return embedding.tolist()
    def vector_search(
            self, 
            user_query: str, 
            limit=4):
        """
        Perform a vector search in the MongoDB collection based on the user query.
        Args:
        user_query (str): The user's query string.
        Returns:
        list: A list of matching documents.
        """
        # Generate embedding for the user query
        query_embedding = self.get_embedding(user_query)
        if query_embedding is None:
            return "Invalid query or embedding generation failed."
        # Define the vector search pipeline
        vector_search_stage = {
            "$vectorSearch": {
                "index": "vector_index",
                "queryVector": query_embedding,
                "path": "embedding",
                "numCandidates": 400,
                "limit": limit,
            }
        }
        unset_stage = {
            "$unset": "embedding" 
        }
        project_stage = {
            "$project": {
                "_id": 0,  
                "title": 1, 
                # "product_specs": 1,
                "color_options": 1,
                "current_price": 1,
                "product_promotion": 1,
                "score": {
                    "$meta": "vectorSearchScore"
                }
            }
        }
        pipeline = [vector_search_stage, unset_stage, project_stage]
        # Execute the search
        results = self.collection.aggregate(pipeline)
        return list(results)
    def enhance_prompt(self, query):
        get_knowledge = self.vector_search(query, 10)
        enhanced_prompt = ""
        i = 0
        for result in get_knowledge:
            if result.get('current_price'):
                i += 1
                enhanced_prompt += f"\n {i}) TÃªn: {result.get('title')}"

                if result.get('current_price'):
                    enhanced_prompt += f", GiÃ¡: {result.get('current_price')}"
                else:
                    # Mock up data
                    # Retrieval model pricing from the internet.
                    enhanced_prompt += f", GiÃ¡: LiÃªn há»‡ Ä‘á»ƒ trao Ä‘á»•i thÃªm!"

                if result.get('product_promotion'):
                    enhanced_prompt += f", Æ¯u Ä‘Ã£i: {result.get('product_promotion')}"
        return enhanced_prompt
    def generate_content(self, prompt):
        return self.llm.generatecontent(prompt)
    def tomarkdown(text):
        text = text.replace('â€¢', '  *')
        return Markdown(textwrap.indent(text, '> ', predicate=lambda : True)) alo báº¡n Æ¡i code nÃ y lÃ  lÃ m vá» cÃ¡i gÃ¬ áº¥y nhá»‰. hÃ¬nh nhÆ° khÃ´ng liÃªn quan Ä‘áº¿n láº¥y data tá»«ng mongodb Ä‘Ãºng k báº¡n


Ah, xin lá»—i vÃ¬ sá»± nháº§m láº«n bro! Cáº£m Æ¡n cáº­u Ä‘Ã£ chia sáº» code nÃ y. Äá»ƒ tá»› phÃ¢n tÃ­ch láº¡i cho cáº­u nhÃ©:

ÄÃ¢y lÃ  má»™t class RAG (Retrieval-Augmented Generation) ğŸ§ 
NÃ³ cÃ³ liÃªn quan trá»±c tiáº¿p Ä‘áº¿n viá»‡c láº¥y data tá»« MongoDB Ä‘áº¥y bro ğŸ—ƒï¸
HÃ£y phÃ¢n tÃ­ch chi tiáº¿t:

Káº¿t ná»‘i MongoDB:
python

Copy
self.client = pymongo.MongoClient(mongodbUri)
self.db = self.client[dbName] 
self.collection = self.db[dbCollection]
Class nÃ y káº¿t ná»‘i tá»›i MongoDB Ä‘á»ƒ láº¥y dá»¯ liá»‡u.
Embedding:
python

Copy
self.embedding_model = SentenceTransformerEmbedding(
    EmbeddingConfig(name=embeddingName)
)
Sá»­ dá»¥ng mÃ´ hÃ¬nh embedding Ä‘á»ƒ chuyá»ƒn Ä‘á»•i text thÃ nh vector.
Vector Search:
python

Copy
def vector_search(self, user_query: str, limit=4):
    # ... (code tÃ¬m kiáº¿m vector)
HÃ m nÃ y thá»±c hiá»‡n tÃ¬m kiáº¿m vector trong MongoDB dá»±a trÃªn cÃ¢u query cá»§a user.
Enhance Prompt:
python

Copy
def enhance_prompt(self, query):
    # ... (code táº¡o prompt nÃ¢ng cao)
HÃ m nÃ y láº¥y káº¿t quáº£ tá»« vector search vÃ  táº¡o ra má»™t prompt nÃ¢ng cao.
Generate Content:
python

Copy
def generate_content(self, prompt):
    return self.llm.generate_content(prompt)
Sá»­ dá»¥ng LLM Ä‘á»ƒ táº¡o ná»™i dung dá»±a trÃªn prompt.
TÃ³m láº¡i, class nÃ y:

Káº¿t ná»‘i vÃ  láº¥y dá»¯ liá»‡u tá»« MongoDB
Thá»±c hiá»‡n vector search trÃªn dá»¯ liá»‡u Ä‘Ã³
Táº¡o prompt nÃ¢ng cao dá»±a trÃªn káº¿t quáº£ tÃ¬m kiáº¿m
Sá»­ dá»¥ng LLM Ä‘á»ƒ táº¡o ná»™i dung
ÄÃ¢y lÃ  má»™t implementation cá»§a RAG system, káº¿t há»£p retrieval (láº¥y thÃ´ng tin tá»« DB) vÃ  generation (táº¡o ná»™i dung báº±ng LLM).

Cáº­u Ä‘Ãºng lÃ  Ä‘ang lÃ m viá»‡c vá»›i MongoDB Ä‘áº¥y bro! ğŸ˜Š CÃ³ gÃ¬ cáº§n giáº£i thÃ­ch thÃªm khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
import os import sqlite3 from dotenv import load_dotenv from pydantic import BaseModel, Field from typing import Union, List, Dict from langchain.prompts import PromptTemplate from langchain_c
pasted
L
import pymongo
import google.generativeai as genai
from IPython.display import Markdown
import textwrap
from embeddings import SentenceTransformerEmbedding, EmbeddingConfig
class RAG():
    def init(self, 
            mongodbUri: str,
            dbName: str,
            dbCollection: str,
            llm,
            embeddingName: str ='keepitreal/vietnamese-sbert',
        ):
        self.client = pymongo.MongoClient(mongodbUri)
        self.db = self.client[dbName] 
        self.collection = self.db[dbCollection]
        self.embedding_model = SentenceTransformerEmbedding(
            EmbeddingConfig(name=embeddingName)
        )
        self.llm = llm
    def get_embedding(self, text):
        if not text.strip():
            return []
        embedding = self.embedding_model.encode(text)
        return embedding.tolist()
    def vector_search(
            self, 
            user_query: str, 
            limit=4):
        """
        Perform a vector search in the MongoDB collection based on the user query.
        Args:
        user_query (str): The user's query string.
        Returns:
        list: A list of matching documents.
        """
        # Generate embedding for the user query
        query_embedding = self.get_embedding(user_query)
        if query_embedding is None:
            return "Invalid query or embedding generation failed."
        # Define the vector search pipeline
        vector_search_stage = {
            "$vectorSearch": {
                "index": "vector_index",
                "queryVector": query_embedding,
                "path": "embedding",
                "numCandidates": 400,
                "limit": limit,
            }
        }
        unset_stage = {
            "$unset": "embedding" 
        }
        project_stage = {
            "$project": {
                "_id": 0,  
                "title": 1, 
                # "product_specs": 1,
                "color_options": 1,
                "current_price": 1,
                "product_promotion": 1,
                "score": {
                    "$meta": "vectorSearchScore"
                }
            }
        }
        pipeline = [vector_search_stage, unset_stage, project_stage]
        # Execute the search
        results = self.collection.aggregate(pipeline)
        return list(results)
    def enhance_prompt(self, query):
        get_knowledge = self.vector_search(query, 10)
        enhanced_prompt = ""
        i = 0
        for result in get_knowledge:
            if result.get('current_price'):
                i += 1
                enhanced_prompt += f"\n {i}) TÃªn: {result.get('title')}"

                if result.get('current_price'):
                    enhanced_prompt += f", GiÃ¡: {result.get('current_price')}"
                else:
                    # Mock up data
                    # Retrieval model pricing from the internet.
                    enhanced_prompt += f", GiÃ¡: LiÃªn há»‡ Ä‘á»ƒ trao Ä‘á»•i thÃªm!"

                if result.get('product_promotion'):
                    enhanced_prompt += f", Æ¯u Ä‘Ã£i: {result.get('product_promotion')}"
        return enhanced_prompt
    def generate_content(self, prompt):
        return self.llm.generatecontent(prompt)
    def tomarkdown(text):
        text = text.replace('â€¢', '  *')
        return Markdown(textwrap.indent(text, '> ', predicate=lambda : True)) bro hÃ£y viáº¿t láº¡i code nÃ y cho tÃ´i Ä‘i  brooooo. cáº¥u trÃºc láº¡i code nÃ y. bro Ä‘i nhá»¯ng thá»¯ khÃ´ng cáº§n thiáº¿t, láº¥y dá»¯ liá»‡u tá»« file env vÃ  viáº¿t láº¡i code cho chuáº©n pep8 cho tÃ´i Ä‘i brooo. . bro hÃ£y tham kháº£o vÃ  khai bÃ¡o tool code nÃ y cho tÃ´i. nÃ³i chung tÃ¹y bro , hÃ£y khai bÃ¡o nÃ³ lÃ  1 tools , viáº¿t code lÃ m sao Ä‘á»ƒ nÃ³ dá»… nhÃ¬n dá»… Ä‘á»c dá»… má»Ÿ rá»™ng . tÃ´i Ä‘ang cá»±c kÃ¬ vá»™i. bro hÃ£y viáº¿t láº¡i toÃ n bá»™ code Ä‘á»ƒ tÃ´i cÃ³ thá»ƒ Ä‘i copy vÃ  cháº¡y ngay láº­p tá»©c Ä‘i brooo

ÄÆ°á»£c rá»“i bro, tá»› hiá»ƒu rá»“i. Äá»ƒ tá»› viáº¿t láº¡i code cho cáº­u, tá»‘i Æ°u hÃ³a vÃ  lÃ m cho nÃ³ dá»… Ä‘á»c, dá»… má»Ÿ rá»™ng hÆ¡n. ÄÃ¢y lÃ  phiÃªn báº£n má»›i cá»§a code:

python

Copy
import os
from typing import List, Dict
from dotenv import load_dotenv
from pydantic import BaseModel, Field
import pymongo
from langchain.tools import Tool
from langchain_core.embeddings import Embeddings
from langchain.prompts import PromptTemplate
from langchain_google_genai import GoogleGenerativeAI

# Load environment variables
load_dotenv()

# Environment variables
MONGODB_URI = os.getenv("MONGODB_URI")
DB_NAME = os.getenv("DB_NAME")
DB_COLLECTION = os.getenv("DB_COLLECTION")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

class RAGTool(BaseModel):
    name: str = "RAG Product Search"
    description: str = "Search for product information using RAG (Retrieval Augmented Generation)"
    args_schema: Dict = {
        "query": (str, "The search query for product information")
    }

class ProductInfo(BaseModel):
    title: str = Field(description="Product title")
    current_price: str = Field(description="Current price of the product")
    color_options: str = Field(description="Available color options")
    product_promotion: str = Field(description="Current promotions for the product")

class RAG:
    def __init__(self, embedding_model: Embeddings):
        self.client = pymongo.MongoClient(MONGODB_URI)
        self.db = self.client[DB_NAME]
        self.collection = self.db[DB_COLLECTION]
        self.embedding_model = embedding_model
        self.llm = GoogleGenerativeAI(model="gemini-pro", google_api_key=GOOGLE_API_KEY)

    def get_embedding(self, text: str) -> List[float]:
        if not text.strip():
            return []
        return self.embedding_model.embed_query(text)

    def vector_search(self, user_query: str, limit: int = 4) -> List[Dict]:
        query_embedding = self.get_embedding(user_query)
        if not query_embedding:
            return []

        pipeline = [
            {
                "$vectorSearch": {
                    "index": "vector_index",
                    "queryVector": query_embedding,
                    "path": "embedding",
                    "numCandidates": 400,
                    "limit": limit,
                }
            },
            {"$unset": "embedding"},
            {
                "$project": {
                    "_id": 0,
                    "title": 1,
                    "color_options": 1,
                    "current_price": 1,
                    "product_promotion": 1,
                    "score": {"$meta": "vectorSearchScore"}
                }
            }
        ]

        results = self.collection.aggregate(pipeline)
        return list(results)

    def enhance_prompt(self, query: str) -> str:
        results = self.vector_search(query, 10)
        enhanced_prompt = ""
        for i, result in enumerate(results, 1):
            if result.get('current_price'):
                enhanced_prompt += f"\n {i}) TÃªn: {result.get('title', '')}"
                enhanced_prompt += f", GiÃ¡: {result.get('current_price', 'LiÃªn há»‡ Ä‘á»ƒ trao Ä‘á»•i thÃªm!')}"
                if result.get('product_promotion'):
                    enhanced_prompt += f", Æ¯u Ä‘Ã£i: {result.get('product_promotion', '')}"
        return enhanced_prompt

    def generate_content(self, prompt: str) -> str:
        return self.llm.invoke(prompt)

def rag_tool(query: str) -> str:
    """
    Search for product information using RAG (Retrieval Augmented Generation).

    Args:
        query (str): The search query for product information.

    Returns:
        str: Generated response based on the query and retrieved information.
    """
    from langchain_google_genai import GoogleGenerativeAIEmbeddings

    embedding_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    rag = RAG(embedding_model)

    enhanced_prompt = rag.enhance_prompt(query)
    prompt_template = PromptTemplate(
        input_variables=["query", "enhanced_prompt"],
        template="Dá»±a trÃªn cÃ¢u há»i: {query}\nVÃ  thÃ´ng tin sáº£n pháº©m sau:\n{enhanced_prompt}\n"
                 "HÃ£y Ä‘Æ°a ra cÃ¢u tráº£ lá»i phÃ¹ há»£p vÃ  há»¯u Ã­ch cho khÃ¡ch hÃ ng."
    )

    final_prompt = prompt_template.format(query=query, enhanced_prompt=enhanced_prompt)
    response = rag.generate_content(final_prompt)

    return response

# Define the tool for use in LangChain
rag_search_tool = Tool(
    name="RAG Product Search",
    func=rag_tool,
    description="Search for product information using RAG (Retrieval Augmented Generation)"
)

if __name__ == "__main__":
    # Example usage
    query = "TÃ¬m Ä‘iá»‡n thoáº¡i cÃ³ giÃ¡ dÆ°á»›i 10 triá»‡u"
    result = rag_tool(query)
    print(result)
Nhá»¯ng thay Ä‘á»•i chÃ­nh:

Sá»­ dá»¥ng load_dotenv() Ä‘á»ƒ load biáº¿n mÃ´i trÆ°á»ng.
TÃ¡ch biá»‡t cÃ¡c háº±ng sá»‘ vÃ  cáº¥u hÃ¬nh vÃ o pháº§n Ä‘áº§u file.
Sá»­ dá»¥ng Pydantic models Ä‘á»ƒ Ä‘á»‹nh nghÄ©a schema cho tool vÃ  dá»¯ liá»‡u sáº£n pháº©m.
Tá»‘i Æ°u hÃ³a class RAG vÃ  cÃ¡c phÆ°Æ¡ng thá»©c cá»§a nÃ³.
Táº¡o má»™t function rag_tool Ä‘á»ƒ sá»­ dá»¥ng nhÆ° má»™t LangChain Tool.
Sá»­ dá»¥ng f-strings cho cÃ¡c chuá»—i cÃ³ format.
ThÃªm type hints cho cÃ¡c function vÃ  method.
Tá»‘i Æ°u hÃ³a logic trong enhance_prompt.
Bro cÃ³ thá»ƒ copy code nÃ y vÃ  cháº¡y ngay láº­p tá»©c. Nhá»› cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t vÃ  cáº¥u hÃ¬nh file .env vá»›i cÃ¡c biáº¿n mÃ´i trÆ°á»ng phÃ¹ há»£p nhÃ©!

Copy
Retry


Claude does not have the ability to run the code it generates yet.
MongoDB logo Products Resources Solutions Company Pricing Search Language Selector Icon Eng Support Sign In Try Free MongoDB Developer Topics Documentation Articles Tutorials
pasted
L
chÆ°a á»•n láº¯m. bro tham kháº£o code nÃ y lÃ m láº¡i cho tÃ´i Ä‘i :  product_code,product_name,material,size,color,brand,gender,stock_quantity,price P001,Ão sÆ¡ mi tráº¯ng,Váº£i cotton,"S, M, L, XL",Tráº¯ng,XYZ,Unisex,50,350000 P002,Quáº§n jean xanh,Váº£i denim,"28, 30, 32, 34",Xanh,ABC,Nam,30,450000 P003,VÃ¡y hoa,Váº£i voan,"S, M, L",Nhiá»u mÃ u,DEF,Ná»¯,20,550000 P004,Äáº§m Ä‘en,Váº£i lá»¥a,"S, M, L",Äen,GHI,Ná»¯,10,1200000 P005,Ão khoÃ¡c da,Da,"M, L, XL",Äen,JKL,Nam,15,2500000 P006,Quáº§n shorts,Váº£i cotton,"S, M, L, XL","Xanh, Äen",MNO,Unisex,40,300000 P007,VÃ¡y xÃ²e,Váº£i chiffon,"S, M, L",Há»“ng,PQR,Ná»¯,25,600000 P008,Ão phÃ´ng in hÃ¬nh,Váº£i cotton,"S, M, L, XL","Tráº¯ng, Äen",STU,Unisex,35,250000 P009,Quáº§n tÃ¢y,Váº£i polyester,"28, 30, 32, 34","Äen, XÃ¡m",VWX,Nam,45,700000 P010,Äáº§m maxi,Váº£i chiffon,"S, M, L","Xanh, Tráº¯ng",YZA,Ná»¯,20,800000 P011,Ão len,Len,"S, M, L, XL","Xanh, Äá»",BCD,Unisex,50,500000 P012,Quáº§n legging,Váº£i spandex,"S, M, L","Äen, XÃ¡m",EFG,Ná»¯,30,350000 P013,VÃ¡y bÃºt chÃ¬,Váº£i polyester,"S, M, L",Äen,HIJ,Ná»¯,20,750000 P014,Ão blouse,Váº£i lá»¥a,"S, M, L","Tráº¯ng, Xanh",KLM,Ná»¯,25,400000 P015,Quáº§n jogger,Váº£i cotton,"S, M, L, XL","Äen, XÃ¡m",NOP,Unisex,35,450000 P016,VÃ¡y midi,Váº£i lá»¥a,"S, M, L","Há»“ng, Tráº¯ng",QRS,Ná»¯,20,700000 P017,Ão thun dÃ i tay,Váº£i cotton,"S, M, L, XL","Xanh, Äen",TUV,Unisex,50,300000 P018,Quáº§n kaki,Váº£i kaki,"28, 30, 32, 34","NÃ¢u, Xanh",WXY,Nam,30,500000 P019,VÃ¡y ren,Váº£i ren,"S, M, L","Äá», Äen",ZAB,Ná»¯,15,1000000 P020,Äáº§m dá»± tiá»‡c,Váº£i satin,"S, M, L","Xanh, VÃ ng",CDE,Ná»¯,10,1500000 P021,Ão phÃ´ng cá»• trÃ²n,Váº£i cotton,"S, M, L, XL","Äen, Tráº¯ng",FGHI,Unisex,60,200000 P022,Quáº§n short jean,Váº£i denim,"S, M, L, XL","Xanh, Tráº¯ng",JKLM,Ná»¯,40,350000 P023,VÃ¡y bodycon,Váº£i polyester,"S, M, L","Äá», Äen",NOPQ,Ná»¯,15,900000 P024,Äáº§m dáº¡ há»™i,Váº£i satin,"S, M, L","Äá», Xanh",RSTU,Ná»¯,5,2000000 P025,Ão hoodie,Váº£i ná»‰,"S, M, L, XL","XÃ¡m, Äen",UVWX,Unisex,50,600000 P026,Quáº§n sweatpants,Váº£i cotton,"S, M, L, XL","XÃ¡m, Äen",YZAB,Unisex,30,500000 P027,VÃ¡y ngáº¯n xáº¿p ly,Váº£i polyester,"S, M, L","Há»“ng, Äen",BCDE,Ná»¯,20,650000 P028,Ão dÃ i tay len,Len,"S, M, L, XL","XÃ¡m, Äen",DEFG,Unisex,25,700000 P029,Quáº§n á»‘ng rá»™ng,Váº£i linen,"S, M, L","Tráº¯ng, XÃ¡m",FGHI,Ná»¯,15,750000 P030,Äáº§m mÃ¹a hÃ¨,Váº£i cotton,"S, M, L","VÃ ng, Tráº¯ng",HIJK,Ná»¯,20,900000 . data cá»§a tÃ´i tÃªn lÃ  products.db. cÃ³ data nhÆ° nÃ y bro áº¡. Ä‘áº§u tiÃªn chÃºng ta pháº£i lÆ°u data lÃªn mongodb trÆ°á»›c Ä‘Ã£, rá»“i má»›i truy xuáº¥t rag chá»© brooo

Hiá»ƒu rá»“i bro! Äá»ƒ tá»› viáº¿t láº¡i code Ä‘á»ƒ lÆ°u data lÃªn MongoDB vÃ  sau Ä‘Ã³ truy xuáº¥t báº±ng RAG nhÃ©. Äáº§u tiÃªn, chÃºng ta sáº½ Ä‘á»c data tá»« file CSV, sau Ä‘Ã³ lÆ°u lÃªn MongoDB, vÃ  cuá»‘i cÃ¹ng lÃ  setup RAG system. ÄÃ¢y lÃ  code chi tiáº¿t:

python

Copy
import os
import csv
from dotenv import load_dotenv
import pymongo
from pymongo import MongoClient
from langchain.vectorstores import MongoDBAtlasVectorSearch
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

# Load environment variables
load_dotenv()

# MongoDB setup
MONGODB_URI = os.getenv("MONGODB_URI")
DB_NAME = "product_database"
COLLECTION_NAME = "products"

# Connect to MongoDB
client = MongoClient(MONGODB_URI)
db = client[DB_NAME]
collection = db[COLLECTION_NAME]

# Function to read CSV and insert into MongoDB
def insert_data_to_mongodb():
    with open('products.csv', 'r', encoding='utf-8') as file:
        csv_reader = csv.DictReader(file)
        data = list(csv_reader)
        
        # Clear existing data
        collection.delete_many({})
        
        # Insert new data
        collection.insert_many(data)
    print("Data inserted successfully!")

# Call function to insert data
insert_data_to_mongodb()

# Setup embeddings
embeddings = OpenAIEmbeddings()

# Create vector store
vector_store = MongoDBAtlasVectorSearch.from_documents(
    collection.find(),
    embeddings,
    collection=collection,
    index_name="default"
)

# Setup retriever
retriever = vector_store.as_retriever()

# Setup LLM
llm = ChatOpenAI(model_name="gpt-3.5-turbo")

# Setup prompt template
template = """Answer the question based only on the following context:
{context}

Question: {question}

Answer: """
prompt = ChatPromptTemplate.from_template(template)

# Setup RAG chain
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# Function to query the RAG system
def query_rag(question):
    return chain.invoke(question)

# Example usage
if __name__ == "__main__":
    question = "CÃ³ sáº£n pháº©m nÃ o mÃ u Ä‘en khÃ´ng?"
    answer = query_rag(question)
    print(f"Question: {question}")
    print(f"Answer: {answer}")
Giáº£i thÃ­ch code:

Äáº§u tiÃªn, chÃºng ta import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t vÃ  load cÃ¡c biáº¿n mÃ´i trÆ°á»ng.
Káº¿t ná»‘i tá»›i MongoDB sá»­ dá»¥ng pymongo.
HÃ m insert_data_to_mongodb() Ä‘á»c dá»¯ liá»‡u tá»« file CSV vÃ  insert vÃ o MongoDB. NÃ³ sáº½ xÃ³a dá»¯ liá»‡u cÅ© trÆ°á»›c khi insert dá»¯ liá»‡u má»›i.
ChÃºng ta sá»­ dá»¥ng OpenAIEmbeddings Ä‘á»ƒ táº¡o embeddings cho cÃ¡c sáº£n pháº©m.
Táº¡o vector store sá»­ dá»¥ng MongoDBAtlasVectorSearch, which will automatically create embeddings for our documents.
Setup retriever tá»« vector store.
Táº¡o má»™t LLM (á»Ÿ Ä‘Ã¢y lÃ  ChatOpenAI) vÃ  má»™t prompt template.
Táº¡o RAG chain káº¿t há»£p retriever, prompt vÃ  LLM.
HÃ m query_rag() Ä‘á»ƒ query RAG system vá»›i cÃ¢u há»i cá»§a user.
Cuá»‘i cÃ¹ng, chÃºng ta cÃ³ má»™t vÃ­ dá»¥ sá»­ dá»¥ng RAG system.
Äá»ƒ cháº¡y code nÃ y, bro cáº§n:

CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t: pip install pymongo langchain openai python-dotenv
Táº¡o file .env vá»›i cÃ¡c biáº¿n mÃ´i trÆ°á»ng cáº§n thiáº¿t (MONGODB_URI, OPENAI_API_KEY)
Äáº£m báº£o file CSV cá»§a bro cÃ³ tÃªn lÃ  products.csv vÃ  náº±m cÃ¹ng thÆ° má»¥c vá»›i script Python.
Cháº¡y script nÃ y sáº½ lÆ°u dá»¯ liá»‡u lÃªn MongoDB vÃ  sau Ä‘Ã³ bro cÃ³ thá»ƒ query RAG system vá»›i báº¥t ká»³ cÃ¢u há»i nÃ o vá» sáº£n pháº©m. Bro tháº¥y á»•n chÆ°a? ğŸ˜ŠğŸ‘

Copy
Retry


Claude does not have the ability to run the code it generates yet.
MongoDB logo Products Resources Solutions Company Pricing Search Language Selector Icon Eng Support Sign In Try Free MongoDB Developer Topics Documentation Articles Tutorials
pasted
L
khÃ´ng, bro Ä‘á»«ng sá»­ dá»¥ng pymongo: import pymongo from pymongo import MongoClient trong sá»­ dá»¥ng sáºµn langchain_mongo cá»§a langchain áº¥y

Hiá»ƒu rá»“i bro! Tá»› sáº½ viáº¿t láº¡i code sá»­ dá»¥ng langchain_mongodb thay vÃ¬ pymongo. ÄÃ¢y lÃ  phiÃªn báº£n cáº­p nháº­t cá»§a code:

python

Copy
import os
from dotenv import load_dotenv
from langchain.vectorstores import MongoDBAtlasVectorSearch
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from langchain_mongodb import MongoDBDocumentStore
import csv

# Load environment variables
load_dotenv()

# MongoDB setup
MONGODB_URI = os.getenv("MONGODB_URI")
DB_NAME = "product_database"
COLLECTION_NAME = "products"

# Setup document store
document_store = MongoDBDocumentStore(
    connection_string=MONGODB_URI,
    database_name=DB_NAME,
    collection_name=COLLECTION_NAME
)

# Function to read CSV and insert into MongoDB
def insert_data_to_mongodb():
    with open('products.csv', 'r', encoding='utf-8') as file:
        csv_reader = csv.DictReader(file)
        data = list(csv_reader)
        
        # Clear existing data
        document_store.delete_documents({})
        
        # Insert new data
        document_store.add_documents(data)
    print("Data inserted successfully!")

# Call function to insert data
insert_data_to_mongodb()

# Setup embeddings
embeddings = OpenAIEmbeddings()

# Create vector store
vector_store = MongoDBAtlasVectorSearch.from_documents(
    document_store.get_all_documents(),
    embeddings,
    collection=document_store.collection,
    index_name="default"
)

# Setup retriever
retriever = vector_store.as_retriever()

# Setup LLM
llm = ChatOpenAI(model_name="gpt-3.5-turbo")

# Setup prompt template
template = """Answer the question based only on the following context:
{context}

Question: {question}

Answer: """
prompt = ChatPromptTemplate.from_template(template)

# Setup RAG chain
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# Function to query the RAG system
def query_rag(question):
    return chain.invoke(question)

# Example usage
if __name__ == "__main__":
    question = "CÃ³ sáº£n pháº©m nÃ o mÃ u Ä‘en khÃ´ng?"
    answer = query_rag(question)
    print(f"Question: {question}")
    print(f"Answer: {answer}")
Nhá»¯ng thay Ä‘á»•i chÃ­nh:

Thay tháº¿ pymongo báº±ng langchain_mongodb.MongoDBDocumentStore.
Sá»­ dá»¥ng MongoDBDocumentStore Ä‘á»ƒ thÃªm vÃ  xÃ³a documents.
Sá»­ dá»¥ng document_store.get_all_documents() Ä‘á»ƒ láº¥y dá»¯ liá»‡u cho vector store.
Sá»­ dá»¥ng document_store.collection thay vÃ¬ truy cáº­p trá»±c tiáº¿p vÃ o collection cá»§a MongoDB.
LÆ°u Ã½:

Äáº£m báº£o báº¡n Ä‘Ã£ cÃ i Ä‘áº·t langchain-mongodb: pip install langchain-mongodb
Cáº¥u trÃºc dá»¯ liá»‡u trong CSV file cá»§a báº¡n pháº£i phÃ¹ há»£p vá»›i cÃ¡c trÆ°á»ng trong MongoDB collection.
Vá»›i nhá»¯ng thay Ä‘á»•i nÃ y, code sáº½ sá»­ dá»¥ng cÃ¡c components cá»§a LangChain Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i MongoDB, giÃºp tÃ­ch há»£p tá»‘t hÆ¡n vá»›i há»‡ sinh thÃ¡i LangChain vÃ  dá»… dÃ ng má»Ÿ rá»™ng trong tÆ°Æ¡ng lai.

Bro tháº¥y version nÃ y á»•n hÆ¡n chÆ°a? ğŸ˜ŠğŸ‘

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
thÃ´i Ä‘Æ°á»£c rá»“i bro.bro giáº£i thÃ­ch qua cho tÃ´i luá»“ng hoáº¡t Ä‘á»™ng cá»§a Ä‘oáº¡n code nÃ y Ä‘i brooo : import pymongo
import google.generativeai as genai
from IPython.display import Markdown
import textwrap
from embeddings import SentenceTransformerEmbedding, EmbeddingConfig
class RAG():
    def init(self, 
            mongodbUri: str,
            dbName: str,
            dbCollection: str,
            llm,
            embeddingName: str ='keepitreal/vietnamese-sbert',
        ):
        self.client = pymongo.MongoClient(mongodbUri)
        self.db = self.client[dbName] 
        self.collection = self.db[dbCollection]
        self.embedding_model = SentenceTransformerEmbedding(
            EmbeddingConfig(name=embeddingName)
        )
        self.llm = llm
    def get_embedding(self, text):
        if not text.strip():
            return []
        embedding = self.embedding_model.encode(text)
        return embedding.tolist()
    def vector_search(
            self, 
            user_query: str, 
            limit=4):
        """
        Perform a vector search in the MongoDB collection based on the user query.
        Args:
        user_query (str): The user's query string.
        Returns:
        list: A list of matching documents.
        """
        # Generate embedding for the user query
        query_embedding = self.get_embedding(user_query)
        if query_embedding is None:
            return "Invalid query or embedding generation failed."
        # Define the vector search pipeline
        vector_search_stage = {
            "$vectorSearch": {
                "index": "vector_index",
                "queryVector": query_embedding,
                "path": "embedding",
                "numCandidates": 400,
                "limit": limit,
            }
        }
        unset_stage = {
            "$unset": "embedding" 
        }
        project_stage = {
            "$project": {
                "_id": 0,  
                "title": 1, 
                # "product_specs": 1,
                "color_options": 1,
                "current_price": 1,
                "product_promotion": 1,
                "score": {
                    "$meta": "vectorSearchScore"
                }
            }
        }
        pipeline = [vector_search_stage, unset_stage, project_stage]
        # Execute the search
        results = self.collection.aggregate(pipeline)
        return list(results)
    def enhance_prompt(self, query):
        get_knowledge = self.vector_search(query, 10)
        enhanced_prompt = ""
        i = 0
        for result in get_knowledge:
            if result.get('current_price'):
                i += 1
                enhanced_prompt += f"\n {i}) TÃªn: {result.get('title')}"

                if result.get('current_price'):
                    enhanced_prompt += f", GiÃ¡: {result.get('current_price')}"
                else:
                    # Mock up data
                    # Retrieval model pricing from the internet.
                    enhanced_prompt += f", GiÃ¡: LiÃªn há»‡ Ä‘á»ƒ trao Ä‘á»•i thÃªm!"

                if result.get('product_promotion'):
                    enhanced_prompt += f", Æ¯u Ä‘Ã£i: {result.get('product_promotion')}"
        return enhanced_prompt
    def generate_content(self, prompt):
        return self.llm.generatecontent(prompt)
    def tomarkdown(text):
        text = text.replace('â€¢', '  *')
        return Markdown(textwrap.indent(text, '> ', predicate=lambda : True))


ÄÆ°á»£c rá»“i bro, Ä‘á»ƒ tá»› giáº£i thÃ­ch luá»“ng hoáº¡t Ä‘á»™ng cá»§a Ä‘oáº¡n code nÃ y cho cáº­u nhÃ©:

Khá»Ÿi táº¡o RAG class:
Káº¿t ná»‘i tá»›i MongoDB
Táº¡o má»™t embedding model (SentenceTransformerEmbedding)
LÆ°u trá»¯ má»™t language model (LLM)
PhÆ°Æ¡ng thá»©c get_embedding:
Chuyá»ƒn Ä‘á»•i text thÃ nh vector embedding
PhÆ°Æ¡ng thá»©c vector_search:
Táº¡o embedding cho cÃ¢u query cá»§a user
Thá»±c hiá»‡n tÃ¬m kiáº¿m vector trong MongoDB:
Sá»­ dá»¥ng $vectorSearch Ä‘á»ƒ tÃ¬m cÃ¡c documents gáº§n nháº¥t
Loáº¡i bá» trÆ°á»ng embedding khá»i káº¿t quáº£
Chá»n cÃ¡c trÆ°á»ng cáº§n thiáº¿t vÃ  tÃ­nh Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng
PhÆ°Æ¡ng thá»©c enhance_prompt:
Sá»­ dá»¥ng vector_search Ä‘á»ƒ tÃ¬m 10 káº¿t quáº£ gáº§n nháº¥t
Táº¡o má»™t prompt má»Ÿ rá»™ng chá»©a thÃ´ng tin vá» cÃ¡c sáº£n pháº©m tÃ¬m Ä‘Æ°á»£c
PhÆ°Æ¡ng thá»©c generate_content:
Sá»­ dá»¥ng LLM Ä‘á»ƒ táº¡o ná»™i dung dá»±a trÃªn prompt
Luá»“ng hoáº¡t Ä‘á»™ng tá»•ng quÃ¡t:

User Ä‘Æ°a ra má»™t cÃ¢u há»i
Há»‡ thá»‘ng táº¡o embedding cho cÃ¢u há»i
Thá»±c hiá»‡n tÃ¬m kiáº¿m vector trong MongoDB Ä‘á»ƒ tÃ¬m cÃ¡c sáº£n pháº©m liÃªn quan
Táº¡o má»™t prompt má»Ÿ rá»™ng chá»©a thÃ´ng tin vá» cÃ¡c sáº£n pháº©m tÃ¬m Ä‘Æ°á»£c
Sá»­ dá»¥ng LLM Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i dá»±a trÃªn prompt má»Ÿ rá»™ng
ÄÃ¢y lÃ  má»™t há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) cÆ¡ báº£n, káº¿t há»£p giá»¯a tÃ¬m kiáº¿m thÃ´ng tin (retrieval) vÃ  táº¡o ná»™i dung (generation) Ä‘á»ƒ Ä‘Æ°a ra cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c vÃ  phÃ¹ há»£p vá»›i context.

Bro hiá»ƒu rÃµ hÆ¡n chÆ°a? CÃ³ chá»— nÃ o cáº§n giáº£i thÃ­ch thÃªm khÃ´ng? ğŸ˜ŠğŸ‘

Copy
Retry


L
Táº¡o má»™t prompt má»Ÿ rá»™ng chá»©a thÃ´ng tin vá» cÃ¡c sáº£n pháº©m tÃ¬m Ä‘Æ°á»£c lÃ  sao bro. promtp má»Ÿ rá»™ng Ä‘Ã³ lÃ  gÃ¬


Hiá»ƒu rá»“i bro, Ä‘á»ƒ tá»› giáº£i thÃ­ch ká»¹ hÆ¡n vá» prompt má»Ÿ rá»™ng nhÃ©! ğŸ˜Š

Prompt má»Ÿ rá»™ng (enhanced prompt) lÃ  má»™t ká»¹ thuáº­t trong RAG systems Ä‘á»ƒ cung cáº¥p thÃªm thÃ´ng tin ngá»¯ cáº£nh cho LLM. Ã tÆ°á»Ÿng lÃ :

Thay vÃ¬ chá»‰ Ä‘Æ°a cÃ¢u há»i cá»§a user vÃ o LLM.
Ta thÃªm thÃ´ng tin liÃªn quan tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u vÃ o prompt.
Trong code cá»§a cáº­u, phÆ°Æ¡ng thá»©c enhance_prompt Ä‘ang lÃ m viá»‡c nÃ y:

python

Copy
def enhance_prompt(self, query):
    get_knowledge = self.vector_search(query, 10)
    enhanced_prompt = ""
    i = 0
    for result in get_knowledge:
        if result.get('current_price'):
            i += 1
            enhanced_prompt += f"\n {i}) TÃªn: {result.get('title')}"
            
            if result.get('current_price'):
                enhanced_prompt += f", GiÃ¡: {result.get('current_price')}"
            else:
                enhanced_prompt += f", GiÃ¡: LiÃªn há»‡ Ä‘á»ƒ trao Ä‘á»•i thÃªm!"
            
            if result.get('product_promotion'):
                enhanced_prompt += f", Æ¯u Ä‘Ã£i: {result.get('product_promotion')}"
    return enhanced_prompt
VÃ­ dá»¥ cá»¥ thá»ƒ:

User há»i: "CÃ³ sáº£n pháº©m nÃ o mÃ u Ä‘en khÃ´ng?"
Prompt má»Ÿ rá»™ng cÃ³ thá»ƒ trÃ´ng nhÆ° tháº¿ nÃ y:

Copy
CÃ¢u há»i: CÃ³ sáº£n pháº©m nÃ o mÃ u Ä‘en khÃ´ng?

ThÃ´ng tin sáº£n pháº©m:
1) TÃªn: Ão khoÃ¡c da, GiÃ¡: 2500000, Æ¯u Ä‘Ã£i: Giáº£m 10% cho Ä‘Æ¡n hÃ ng trÃªn 5 triá»‡u
2) TÃªn: Quáº§n jean Ä‘en, GiÃ¡: 800000, Æ¯u Ä‘Ã£i: Mua 2 táº·ng 1
3) TÃªn: GiÃ y da cÃ´ng sá»Ÿ, GiÃ¡: 1500000
...
Lá»£i Ã­ch cá»§a prompt má»Ÿ rá»™ng:

Cung cáº¥p ngá»¯ cáº£nh: LLM cÃ³ thÃªm thÃ´ng tin Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c hÆ¡n.
TÄƒng Ä‘á»™ tin cáº­y: CÃ¢u tráº£ lá»i dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿ tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u.
Linh hoáº¡t: CÃ³ thá»ƒ Ä‘iá»u chá»‰nh lÆ°á»£ng thÃ´ng tin thÃªm vÃ o tÃ¹y theo nhu cáº§u.
Khi sá»­ dá»¥ng prompt má»Ÿ rá»™ng, LLM sáº½ cÃ³ nhiá»u thÃ´ng tin hÆ¡n Ä‘á»ƒ táº¡o ra cÃ¢u tráº£ lá»i phÃ¹ há»£p vÃ  chÃ­nh xÃ¡c hÆ¡n cho user.

Bro hiá»ƒu rÃµ hÆ¡n vá» prompt má»Ÿ rá»™ng chÆ°a? CÃ³ gÃ¬ cáº§n giáº£i thÃ­ch thÃªm khÃ´ng? ğŸ˜ŠğŸš€

Copy
Retry




Claude does not have the ability to run the code it generates yet.
L
prompt má»Ÿ rá»™ng nhÆ° kiá»ƒu lÃ  láº¥y Ä‘Æ°á»£c thÃ´ng tin liÃªn quan tá»« sáº£n pháº©m rá»“i , sáº½ thÃªm 1 tÃ½ vÃ o prompt Ä‘Ãºng k . cÆ¡ mÃ  cÃ¡i nÃ y k á»•n, cÃ¡i nÃ y khÃ´ng Ã¡p dá»¥ng cho nhiá»u data, chá»‰ mang má»¥c Ä‘Ã­ch demo thÃ´i. dÆ°á»›i gÃ³c nhÃ¬n cá»§a 1 senior . báº¡n cÃ³ nghÄ© nhÆ° tÃ´i k brooo


Bro Æ¡i, cáº­u nÃ³i chÃ­nh xÃ¡c Ä‘áº¥y! ğŸ‘ DÆ°á»›i gÃ³c nhÃ¬n cá»§a má»™t senior, tá»› hoÃ n toÃ n Ä‘á»“ng Ã½ vá»›i cáº­u. HÃ£y phÃ¢n tÃ­ch ká»¹ hÆ¡n nhÃ©:

ÄÃºng lÃ  prompt má»Ÿ rá»™ng Ä‘ang thÃªm thÃ´ng tin liÃªn quan tá»« sáº£n pháº©m vÃ o prompt. Äiá»u nÃ y cÃ³ thá»ƒ há»¯u Ã­ch cho demo hoáº·c datasets nhá».
Tuy nhiÃªn, vá»›i datasets lá»›n hoáº·c há»‡ thá»‘ng production, approach nÃ y cÃ³ nhiá»u háº¡n cháº¿:
Giá»›i háº¡n token: LLMs thÆ°á»ng cÃ³ giá»›i háº¡n vá» sá»‘ lÆ°á»£ng tokens trong input. Náº¿u thÃªm quÃ¡ nhiá»u thÃ´ng tin, cÃ³ thá»ƒ vÆ°á»£t quÃ¡ giá»›i háº¡n nÃ y.
Hiá»‡u suáº¥t: Viá»‡c táº¡o prompt má»Ÿ rá»™ng cho má»—i query cÃ³ thá»ƒ tá»‘n thá»i gian vÃ  tÃ i nguyÃªn, Ä‘áº·c biá»‡t vá»›i datasets lá»›n.
Scalability: Khi sá»‘ lÆ°á»£ng sáº£n pháº©m tÄƒng lÃªn, viá»‡c chá»n thÃ´ng tin phÃ¹ há»£p Ä‘á»ƒ thÃªm vÃ o prompt trá»Ÿ nÃªn phá»©c táº¡p hÆ¡n.
Äá»™ chÃ­nh xÃ¡c: LLM cÃ³ thá»ƒ bá»‹ nhiá»…u bá»Ÿi thÃ´ng tin khÃ´ng liÃªn quan trong prompt má»Ÿ rá»™ng.
CÃ¡c giáº£i phÃ¡p tá»‘t hÆ¡n cho há»‡ thá»‘ng lá»›n vÃ  production:
Sá»­ dá»¥ng ká»¹ thuáº­t retrieval hiá»‡u quáº£ hÆ¡n, nhÆ° hybrid search káº¿t há»£p BM25 vÃ  vector search.
Implement caching Ä‘á»ƒ tá»‘i Æ°u hÃ³a viá»‡c tÃ¬m kiáº¿m thÃ´ng tin liÃªn quan.
Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° few-shot learning hoáº·c fine-tuning LLM trÃªn domain cá»¥ thá»ƒ.
Implement há»‡ thá»‘ng phÃ¢n loáº¡i query Ä‘á»ƒ xá»­ lÃ½ cÃ¡c loáº¡i cÃ¢u há»i khÃ¡c nhau má»™t cÃ¡ch hiá»‡u quáº£.
Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nÃ©n prompt (prompt compression) Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c input mÃ  váº«n giá»¯ Ä‘Æ°á»£c thÃ´ng tin quan trá»ng.
TÃ³m láº¡i, cáº­u nÃ³i Ä‘Ãºng Ä‘áº¥y bro! Approach hiá»‡n táº¡i phÃ¹ há»£p cho demo nhÆ°ng cáº§n Ä‘Æ°á»£c cáº£i tiáº¿n Ä‘Ã¡ng ká»ƒ cho cÃ¡c á»©ng dá»¥ng thá»±c táº¿ vÃ  quy mÃ´ lá»›n. Má»™t senior developer sáº½ luÃ´n cÃ¢n nháº¯c vá» scalability, performance, vÃ  maintainability cá»§a há»‡ thá»‘ng.

Cáº­u cÃ³ Ã½ tÆ°á»Ÿng gÃ¬ Ä‘á»ƒ cáº£i tiáº¿n há»‡ thá»‘ng nÃ y khÃ´ng bro? ğŸ¤”ğŸ’¡

Copy
Retry


L
cÃ²n cÃ³ giáº£i phÃ¡p nÃ o ná»¯a k brooo : CÃ¡c giáº£i phÃ¡p tá»‘t hÆ¡n cho há»‡ thá»‘ng lá»›n vÃ  production: 
* Sá»­ dá»¥ng ká»¹ thuáº­t retrieval hiá»‡u quáº£ hÆ¡n, nhÆ° hybrid search káº¿t há»£p BM25 vÃ  vector search.
* Implement caching Ä‘á»ƒ tá»‘i Æ°u hÃ³a viá»‡c tÃ¬m kiáº¿m thÃ´ng tin liÃªn quan.
* Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° few-shot learning hoáº·c fine-tuning LLM trÃªn domain cá»¥ thá»ƒ.
* Implement há»‡ thá»‘ng phÃ¢n loáº¡i query Ä‘á»ƒ xá»­ lÃ½ cÃ¡c loáº¡i cÃ¢u há»i khÃ¡c nhau má»™t cÃ¡ch hiá»‡u quáº£.
* Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nÃ©n prompt (prompt compression) Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c input mÃ  váº«n giá»¯ Ä‘Æ°á»£c thÃ´ng tin quan trá»ng.


Táº¥t nhiÃªn rá»“i bro! CÃ³ thÃªm má»™t sá»‘ giáº£i phÃ¡p nÃ¢ng cao mÃ  chÃºng ta cÃ³ thá»ƒ xem xÃ©t:

Semantic Chunking:
Chia nhá» dá»¯ liá»‡u thÃ nh cÃ¡c Ä‘oáº¡n cÃ³ Ã½ nghÄ©a ngá»¯ nghÄ©a.
GiÃºp tÃ¬m kiáº¿m chÃ­nh xÃ¡c hÆ¡n vÃ  giáº£m nhiá»…u trong káº¿t quáº£.
Query Expansion:
Má»Ÿ rá»™ng cÃ¢u query ban Ä‘áº§u Ä‘á»ƒ bao gá»“m cÃ¡c tá»« khÃ³a liÃªn quan.
Cáº£i thiá»‡n kháº£ nÄƒng tÃ¬m kiáº¿m thÃ´ng tin liÃªn quan.
Multi-stage Retrieval:
Sá»­ dá»¥ng nhiá»u bÆ°á»›c tÃ¬m kiáº¿m, má»—i bÆ°á»›c lá»c vÃ  tinh chá»‰nh káº¿t quáº£.
VÃ­ dá»¥: BM25 -> Vector Search -> Re-ranking.
Dynamic Prompt Engineering:
Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh cáº¥u trÃºc prompt dá»±a trÃªn loáº¡i cÃ¢u há»i vÃ  context.
Tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t cá»§a LLM cho tá»«ng trÆ°á»ng há»£p cá»¥ thá»ƒ.
Federated Learning:
Cho phÃ©p train model trÃªn dá»¯ liá»‡u phÃ¢n tÃ¡n mÃ  khÃ´ng cáº§n táº­p trung dá»¯ liá»‡u.
Há»¯u Ã­ch cho cÃ¡c há»‡ thá»‘ng cÃ³ yÃªu cáº§u báº£o máº­t cao.
Continuous Learning:
Cáº­p nháº­t model liÃªn tá»¥c dá»±a trÃªn feedback vÃ  dá»¯ liá»‡u má»›i.
GiÃºp há»‡ thá»‘ng luÃ´n Ä‘Æ°á»£c cáº£i thiá»‡n theo thá»i gian.
Knowledge Graph Integration:
Káº¿t há»£p Ä‘á»“ thá»‹ tri thá»©c Ä‘á»ƒ cung cáº¥p context phong phÃº hÆ¡n.
Cáº£i thiá»‡n kháº£ nÄƒng suy luáº­n vÃ  liÃªn káº¿t thÃ´ng tin.
Multi-modal Retrieval:
TÃ¬m kiáº¿m trÃªn nhiá»u loáº¡i dá»¯ liá»‡u (vÄƒn báº£n, hÃ¬nh áº£nh, Ã¢m thanh).
PhÃ¹ há»£p cho cÃ¡c á»©ng dá»¥ng cÃ³ dá»¯ liá»‡u Ä‘a dáº¡ng.
Attention Mechanisms:
Sá»­ dá»¥ng cÃ¡c cÆ¡ cháº¿ chÃº Ã½ Ä‘á»ƒ focus vÃ o thÃ´ng tin quan trá»ng nháº¥t.
Cáº£i thiá»‡n cháº¥t lÆ°á»£ng cá»§a káº¿t quáº£ tÃ¬m kiáº¿m vÃ  generation.
Explainable AI (XAI):
TÃ­ch há»£p cÃ¡c ká»¹ thuáº­t giáº£i thÃ­ch káº¿t quáº£ cá»§a model.
TÄƒng tÃ­nh minh báº¡ch vÃ  Ä‘Ã¡ng tin cáº­y cá»§a há»‡ thá»‘ng.
Nhá»¯ng giáº£i phÃ¡p nÃ y Ä‘Ã²i há»i kiáº¿n thá»©c chuyÃªn sÃ¢u vÃ  cÃ³ thá»ƒ phá»©c táº¡p trong viá»‡c triá»ƒn khai, nhÆ°ng chÃºng cÃ³ thá»ƒ Ä‘Æ°a há»‡ thá»‘ng RAG lÃªn má»™t táº§m cao má»›i vá» hiá»‡u suáº¥t vÃ  kháº£ nÄƒng má»Ÿ rá»™ng.

Cáº­u tháº¥y sao, bro? CÃ³ giáº£i phÃ¡p nÃ o cáº­u Ä‘áº·c biá»‡t quan tÃ¢m khÃ´ng? ğŸ¤“ğŸ’¡

Copy
Retry


Chat history ChatGPT ChatGPT GPT Python GPT LangGraph Wizard GPT LLM Expert GPT LLM Course 14 more Explore GPTs Today PhÃ¢n biá»‡t pháº§n má»m test Yesterday Ã tÆ°á»Ÿng AI Shopping R
pasted
L
oke brooo thÃ´i Ä‘Æ°á»£c rá»“i chÃºng ta sáº½ nÃ³i vá» tiáº¿p tá»¥c semantic search trong bÃ i toÃ¡n nÃ y nhÃ©.Ä‘Ã¢y lÃ  cuá»™c trÃ² chuyá»‡n cá»§a tÃ´i vá»›i con AI trÆ°á»›c Ä‘Ã³. tÃ´i cá»© cÃ³ cáº£m giÃ¡c cÃ¡ch nÃ y khÃ´ng oke láº¯m bro ajaaa. bro cÃ³ cÃ¡ch nÃ o khÃ¡c khÃ´ng bro Æ¡iiiii

TÃ´i hiá»ƒu cáº£m giÃ¡c cá»§a báº¡n, viá»‡c sá»­ dá»¥ng LLMs Ä‘á»ƒ Ä‘á»‹nh tuyáº¿n cÃ³ thá»ƒ khÃ´ng pháº£i lÃ  giáº£i phÃ¡p tá»‘i Æ°u trong má»i trÆ°á»ng há»£p. CÃ³ má»™t sá»‘ cÃ¡ch tiáº¿p cáº­n khÃ¡c cho semantic search mÃ  cÃ³ thá»ƒ hiá»‡u quáº£ hÆ¡n vÃ  Ã­t tá»‘n kÃ©m hÆ¡n:

Sá»­ dá»¥ng Vector Database:
Thay vÃ¬ sá»­ dá»¥ng LLMs, báº¡n cÃ³ thá»ƒ encode cÃ¢u truy váº¥n thÃ nh vector embedding.
So sÃ¡nh vector nÃ y vá»›i cÃ¡c vector cÃ³ sáºµn trong cÆ¡ sá»Ÿ dá»¯ liá»‡u (vÃ­ dá»¥ nhÆ° Pinecone, Milvus, Qdrant).
Tráº£ vá» káº¿t quáº£ dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cosine.
Clustering vÃ  KNN:
PhÃ¢n cá»¥m cÃ¡c cÃ¢u há»i/truy váº¥n cÃ³ sáºµn.
Khi cÃ³ cÃ¢u há»i má»›i, tÃ¬m cá»¥m gáº§n nháº¥t vÃ  tráº£ vá» cÃ¢u tráº£ lá»i tÆ°Æ¡ng á»©ng.
TF-IDF vÃ  BM25:
Sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n truyá»n thá»‘ng nhÆ° TF-IDF hoáº·c BM25 Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng.
Hiá»‡u quáº£ cho cÃ¡c truy váº¥n dá»±a trÃªn tá»« khÃ³a.
Sentence Transformers:
Sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh nháº¹ hÆ¡n nhÆ° SBERT Ä‘á»ƒ táº¡o embedding.
So sÃ¡nh embedding nÃ y vá»›i má»™t táº­p cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n loáº¡i sáºµn.
Káº¿t há»£p Rule-based vÃ  ML:
XÃ¢y dá»±ng má»™t há»‡ thá»‘ng rule Ä‘Æ¡n giáº£n cho cÃ¡c trÆ°á»ng há»£p phá»• biáº¿n.
Sá»­ dá»¥ng ML cho cÃ¡c trÆ°á»ng há»£p phá»©c táº¡p hÆ¡n.
Nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y cÃ³ thá»ƒ nhanh hÆ¡n, Ã­t tá»‘n kÃ©m hÆ¡n vÃ  dá»… triá»ƒn khai hÆ¡n so vá»›i viá»‡c sá»­ dá»¥ng LLMs cho má»i bÆ°á»›c. Báº¡n nghÄ© sao vá» nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y?

Copy
Retry


image.png
L
khÃ´ng bro, Ä‘ang nÃ³i vá» semantic router cÆ¡ mÃ  ÄÃºng váº­y, trong tÃ i liá»‡u báº¡n gá»­i, táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p sá»­ dá»¥ng Large Language Models (LLMs) Ä‘á»ƒ Ä‘á»‹nh tuyáº¿n truy váº¥n, cá»¥ thá»ƒ nhÆ° sau:
1. Sá»­ dá»¥ng LLMs cho PhÃ¢n Loáº¡i Truy Váº¥n:
   - PhÃ¢n loáº¡i truy váº¥n ban Ä‘áº§u: Má»™t chuá»—i (chain) Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ phÃ¢n loáº¡i cÃ¢u há»i ngÆ°á»i dÃ¹ng báº±ng cÃ¡ch sá»­ dá»¥ng má»™t LLM nhÆ° ChatAnthropic. Chuá»—i nÃ y sá»­ dá»¥ng PromptTemplate Ä‘á»ƒ Ä‘Æ°a ra cÃ¢u há»i phÃ¢n loáº¡i vÃ  sau Ä‘Ã³ sá»­ dá»¥ng LLM Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¢u há»i thuá»™c loáº¡i nÃ o (vÃ­ dá»¥: LangChain, Anthropic, hoáº·c Other).

Äá»‹nh Tuyáº¿n Dá»±a TrÃªn Ngá»¯ NghÄ©a (Semantic Routing):
Sá»­ dá»¥ng Embeddings vÃ  Cosine Similarity: Äá»ƒ tÃ¬m hiá»ƒu ngá»¯ nghÄ©a cá»§a cÃ¢u há»i, cÃ¡c embedding Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ so sÃ¡nh má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a cÃ¢u há»i ngÆ°á»i dÃ¹ng vÃ  cÃ¡c prompt Ä‘Ã£ cÃ³ sáºµn. LLMs Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o embedding vÃ  tÃ­nh toÃ¡n Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng, sau Ä‘Ã³ sá»­ dá»¥ng Ä‘á»ƒ quyáº¿t Ä‘á»‹nh cÃ¢u há»i sáº½ Ä‘Æ°á»£c xá»­ lÃ½ báº±ng prompt nÃ o.

HÃ m TÃ¹y Chá»‰nh Vá»›i LLMs:
CÃ¡c hÃ m tÃ¹y chá»‰nh (RunnableLambda) cÃ³ thá»ƒ Ä‘Æ°á»£c táº¡o ra Ä‘á»ƒ thá»±c hiá»‡n Ä‘á»‹nh tuyáº¿n dá»±a trÃªn káº¿t quáº£ cá»§a LLMs. VÃ­ dá»¥, má»™t hÃ m cÃ³ thá»ƒ kiá»ƒm tra káº¿t quáº£ phÃ¢n loáº¡i tá»« LLMs vÃ  quyáº¿t Ä‘á»‹nh xem cÃ¢u há»i nÃªn Ä‘Æ°á»£c chuyá»ƒn Ä‘áº¿n chuá»—i liÃªn quan Ä‘áº¿n LangChain, Anthropic, hay má»™t chuá»—i chung chung khÃ¡c.
Branching With LLMs:
RunnableBranch: CÆ¡ cháº¿ nÃ y sá»­ dá»¥ng cÃ¡c Ä‘iá»u kiá»‡n dá»±a trÃªn Ä‘áº§u vÃ o Ä‘á»ƒ quyáº¿t Ä‘á»‹nh cháº¡y chuá»—i nÃ o. LLMs sáº½ cung cáº¥p ná»™i dung hoáº·c káº¿t quáº£ phÃ¢n loáº¡i, vÃ  dá»±a vÃ o Ä‘Ã³, há»‡ thá»‘ng sáº½ Ä‘á»‹nh tuyáº¿n cÃ¢u há»i tá»›i cÃ¡c chuá»—i xá»­ lÃ½ phÃ¹ há»£p. ### Káº¿t luáº­n: Trong táº¥t cáº£ cÃ¡c cÃ¡ch tiáº¿p cáº­n Ä‘Æ°á»£c mÃ´ táº£ trong tÃ i liá»‡u, LLMs Ä‘Ã³ng vai trÃ² trung tÃ¢m trong viá»‡c phÃ¢n tÃ­ch vÃ  Ä‘á»‹nh tuyáº¿n truy váº¥n. ChÃºng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ:
Hiá»ƒu ngá»¯ nghÄ©a cá»§a cÃ¢u há»i.
PhÃ¢n loáº¡i cÃ¢u há»i dá»±a trÃªn ngá»¯ nghÄ©a.
Táº¡o cÃ¡c embedding Ä‘á»ƒ so sÃ¡nh vÃ  Ä‘á»‹nh tuyáº¿n.
Tráº£ vá» káº¿t quáº£ cuá»‘i cÃ¹ng cho ngÆ°á»i dÃ¹ng dá»±a trÃªn chuá»—i Ä‘Ã£ Ä‘á»‹nh tuyáº¿n. Viá»‡c sá»­ dá»¥ng LLMs giÃºp há»‡ thá»‘ng trá»Ÿ nÃªn linh hoáº¡t hÆ¡n, cÃ³ kháº£ nÄƒng xá»­ lÃ½ nhiá»u loáº¡i cÃ¢u há»i khÃ¡c nhau má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  tá»± Ä‘á»™ng. . tá»©c lÃ  theo quy trÃ¬nh chÃºng ta sáº½ xem lÃ  nÃ³ lÃ  1 cÃ¢u chat chit thÃ´ng thÆ°á»ng hay lÃ  liÃªn quan tá»›i sáº£n pháº©m bro hiá»ƒu Ã½ tÃ´i chá»©
TÃ´i hiá»ƒu rá»“i, báº¡n Ä‘ang nÃ³i vá» Semantic Router trong sÆ¡ Ä‘á»“ pipeline cá»§a chatbot. ÄÃºng váº­y, chá»©c nÄƒng chÃ­nh cá»§a Semantic Router lÃ  phÃ¢n loáº¡i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng thÃ nh hai loáº¡i chÃ­nh:

Chitchat Query: Nhá»¯ng cÃ¢u há»i thÃ´ng thÆ°á»ng, trÃ² chuyá»‡n phiáº¿m khÃ´ng liÃªn quan Ä‘áº¿n sáº£n pháº©m.
Product Query: Nhá»¯ng cÃ¢u há»i liÃªn quan Ä‘áº¿n thÃ´ng tin sáº£n pháº©m.
CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Semantic Router:

Nháº­n input tá»« ngÆ°á»i dÃ¹ng qua Semantic Cache.
PhÃ¢n tÃ­ch ngá»¯ nghÄ©a cá»§a cÃ¢u há»i Ä‘á»ƒ xÃ¡c Ä‘á»‹nh loáº¡i truy váº¥n.
Náº¿u lÃ  Chitchat Query, nÃ³ sáº½ chuyá»ƒn trá»±c tiáº¿p Ä‘áº¿n LLMs Ä‘á»ƒ xá»­ lÃ½ vÃ  tráº£ lá»i.
Náº¿u lÃ  Product Query, nÃ³ sáº½ chuyá»ƒn xuá»‘ng Reflection Ä‘á»ƒ xá»­ lÃ½ thÃªm trÆ°á»›c khi Ä‘Æ°a vÃ o RAGs System.
Má»¥c Ä‘Ã­ch chÃ­nh lÃ  Ä‘á»ƒ tá»‘i Æ°u quÃ¡ trÃ¬nh xá»­ lÃ½, Ä‘áº£m báº£o ráº±ng:

CÃ¡c cÃ¢u há»i thÃ´ng thÆ°á»ng Ä‘Æ°á»£c tráº£ lá»i nhanh chÃ³ng bá»Ÿi LLMs.
CÃ¡c cÃ¢u há»i vá» sáº£n pháº©m Ä‘Æ°á»£c xá»­ lÃ½ ká»¹ lÆ°á»¡ng hÆ¡n vá»›i thÃ´ng tin chÃ­nh xÃ¡c tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u.
ÄÃ¢y lÃ  má»™t cÃ¡ch tiáº¿p cáº­n hiá»‡u quáº£ Ä‘á»ƒ cáº£i thiá»‡n tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng vÃ  Ä‘áº£m báº£o cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c cho tá»«ng loáº¡i cÃ¢u há»i.

Copy
Retry


L
oke Ä‘Ãºng rá»“i báº¡n hiá»ƒu Ä‘Ãºng rá»“i Ä‘Ã³ bro. giá» chÃºng ta pháº£i xá»­ lÃ½ ra sao vÃ  nhÆ° tháº¿ nÃ o giá» rboooo


Hiá»ƒu rá»“i bro. Äá»ƒ xá»­ lÃ½ Semantic Router hiá»‡u quáº£, ta cÃ³ thá»ƒ lÃ m nhÆ° sau:

XÃ¢y dá»±ng bá»™ phÃ¢n loáº¡i:
Sá»­ dá»¥ng mÃ´ hÃ¬nh nháº¹ nhÆ° fastText hoáº·c BERT nhá» Ä‘á»ƒ phÃ¢n loáº¡i nhanh.
Huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u gá»“m cÃ¡c cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ£n (chitchat/product).
Táº¡o embedding:
Sá»­ dá»¥ng sentence-transformers Ä‘á»ƒ táº¡o embedding cho cÃ¢u há»i.
LÆ°u sáºµn embedding cá»§a má»™t sá»‘ cÃ¢u há»i máº«u cho má»—i loáº¡i.
Xá»­ lÃ½ cÃ¢u há»i:
Khi nháº­n cÃ¢u há»i má»›i, táº¡o embedding cho nÃ³.
So sÃ¡nh vá»›i cÃ¡c embedding máº«u báº±ng cosine similarity.
Náº¿u Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cao vá»›i cÃ¢u há»i chitchat -> chuyá»ƒn Ä‘áº¿n LLMs.
Náº¿u tÆ°Æ¡ng Ä‘á»“ng vá»›i cÃ¢u há»i sáº£n pháº©m -> chuyá»ƒn Ä‘áº¿n Reflection.
Tá»‘i Æ°u hÃ³a:
Sá»­ dá»¥ng caching Ä‘á»ƒ lÆ°u káº¿t quáº£ phÃ¢n loáº¡i trÆ°á»›c Ä‘Ã³.
Ãp dá»¥ng ká»¹ thuáº­t few-shot learning Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c.
Xá»­ lÃ½ trÆ°á»ng há»£p Ä‘áº·c biá»‡t:
Náº¿u khÃ´ng thá»ƒ phÃ¢n loáº¡i cháº¯c cháº¯n, cÃ³ thá»ƒ há»i láº¡i ngÆ°á»i dÃ¹ng hoáº·c chuyá»ƒn Ä‘áº¿n LLMs Ä‘á»ƒ xá»­ lÃ½.
Code vÃ­ dá»¥:

python

Copy
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

model = SentenceTransformer('distilbert-base-nli-mean-tokens')

chitchat_samples = ["HÃ´m nay thá»i tiáº¿t tháº¿ nÃ o?", "Báº¡n khá»e khÃ´ng?"]
product_samples = ["GiÃ¡ sáº£n pháº©m X lÃ  bao nhiÃªu?", "Sáº£n pháº©m Y cÃ²n hÃ ng khÃ´ng?"]

chitchat_embeddings = model.encode(chitchat_samples)
product_embeddings = model.encode(product_samples)

def classify_query(query):
    query_embedding = model.encode([query])
    
    chitchat_sim = cosine_similarity(query_embedding, chitchat_embeddings)
    product_sim = cosine_similarity(query_embedding, product_embeddings)
    
    if max(chitchat_sim[0]) > max(product_sim[0]):
        return "chitchat"
    else:
        return "product"

# Sá»­ dá»¥ng
query = "iPhone 13 giÃ¡ bao nhiÃªu?"
query_type = classify_query(query)
print(f"Query type: {query_type}")
Bro tháº¥y approach nÃ y tháº¿ nÃ o? CÃ³ cáº§n Ä‘iá»u chá»‰nh gÃ¬ khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
hmm Ä‘Ã©o á»•n láº¯m nhá»‰iii. cÃ³ cÃ¡ch nÃ o khÃ¡c khÃ´ng bro. sá»­ dá»¥ng consine hoáº·c llms cháº³ng háº¡n, cÃ³ cÃ¡ch nÃ o khÃ¡c biá»‡t, sÃ¡ng táº¡o nÃ o khÃ¡c khÃ´ng brooo


Hiá»ƒu rá»“i bro, báº¡n muá»‘n má»™t cÃ¡ch tiáº¿p cáº­n sÃ¡ng táº¡o vÃ  khÃ¡c biá»‡t hÆ¡n. ÄÃ¢y lÃ  má»™t Ã½ tÆ°á»Ÿng má»›i cÃ³ thá»ƒ phÃ¹ há»£p:

Sá»­ dá»¥ng Topic Modeling káº¿t há»£p vá»›i Rule-based system:
Ãp dá»¥ng LDA (Latent Dirichlet Allocation) Ä‘á»ƒ tÃ¬m ra cÃ¡c chá»§ Ä‘á» chÃ­nh trong cÃ¢u há»i.
XÃ¢y dá»±ng má»™t bá»™ quy táº¯c dá»±a trÃªn cÃ¡c tá»« khÃ³a vÃ  chá»§ Ä‘á» Ä‘á»ƒ phÃ¢n loáº¡i.
Káº¿t há»£p vá»›i Sentiment Analysis:
PhÃ¢n tÃ­ch cáº£m xÃºc trong cÃ¢u há»i cÃ³ thá»ƒ giÃºp phÃ¢n biá»‡t giá»¯a chitchat vÃ  product query.
Sá»­ dá»¥ng Graph Neural Networks:
XÃ¢y dá»±ng má»™t Ä‘á»“ thá»‹ tri thá»©c vá» sáº£n pháº©m vÃ  chá»§ Ä‘á» trÃ² chuyá»‡n.
Sá»­ dá»¥ng GNN Ä‘á»ƒ phÃ¢n loáº¡i cÃ¢u há»i dá»±a trÃªn vá»‹ trÃ­ cá»§a nÃ³ trong Ä‘á»“ thá»‹.
VÃ­ dá»¥ code (sá»­ dá»¥ng gensim cho LDA vÃ  TextBlob cho sentiment analysis):

python

Copy
from gensim import corpora
from gensim.models import LdaModel
from textblob import TextBlob
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

def preprocess(text):
    return [word for word in text.lower().split() if word not in stopwords.words('english')]

# Chuáº©n bá»‹ dá»¯ liá»‡u
texts = ["Sáº£n pháº©m nÃ y giÃ¡ bao nhiÃªu?", "Báº¡n khá»e khÃ´ng?", "iPhone cÃ³ mÃ u gÃ¬?"]
processed_texts = [preprocess(text) for text in texts]

dictionary = corpora.Dictionary(processed_texts)
corpus = [dictionary.doc2bow(text) for text in processed_texts]

# Ãp dá»¥ng LDA
lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=2)

def classify_query(query):
    processed_query = preprocess(query)
    bow = dictionary.doc2bow(processed_query)
    topics = lda_model.get_document_topics(bow)
    
    main_topic = max(topics, key=lambda x: x[1])[0]
    
    sentiment = TextBlob(query).sentiment.polarity
    
    if main_topic == 0 and "giÃ¡" in query.lower():
        return "product"
    elif main_topic == 1 or sentiment > 0.5:
        return "chitchat"
    else:
        return "undetermined"

# Sá»­ dá»¥ng
query = "iPhone 13 cÃ³ mÃ u xanh khÃ´ng?"
query_type = classify_query(query)
print(f"Query type: {query_type}")
CÃ¡ch tiáº¿p cáº­n nÃ y káº¿t há»£p machine learning (LDA) vá»›i rule-based system vÃ  sentiment analysis, táº¡o ra má»™t phÆ°Æ¡ng phÃ¡p Ä‘a chiá»u vÃ  linh hoáº¡t hÆ¡n. NÃ³ cÃ³ thá»ƒ xá»­ lÃ½ Ä‘Æ°á»£c nhiá»u loáº¡i cÃ¢u há»i khÃ¡c nhau vÃ  dá»… dÃ ng má»Ÿ rá»™ng báº±ng cÃ¡ch thÃªm cÃ¡c quy táº¯c hoáº·c chá»§ Ä‘á» má»›i.

Bro tháº¥y cÃ¡ch nÃ y tháº¿ nÃ o? CÃ³ phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a báº¡n khÃ´ng?

Copy
Retry




Claude does not have the ability to run the code it generates yet.
L
from flask import Flask, request, jsonify
from dotenv import load_dotenv
import os
import google.generativeai as genai
from flask_cors import CORS
from rag.core import RAG
from embeddings import OpenAIEmbedding
from semantic_router import SemanticRouter, Route
from semantic_router.samples import productsSample, chitchatSample
import google.generativeai as genai
import openai
from reflection import Reflection
# Load environment variables from .env file
load_dotenv()
# Access the key
MONGODB_URI = os.getenv('MONGODB_URI')
DB_NAME = os.getenv('DB_NAME')
DB_COLLECTION = os.getenv('DB_COLLECTION')
LLM_KEY = os.getenv('GEMINI_KEY')
EMBEDDING_MODEL = os.getenv('EMBEDDING_MODEL') or 'keepitreal/vietnamese-sbert'
OPEN_AI_KEY = os.getenv('OPEN_AI_KEY')
OPEN_AI_EMBEDDING_MODEL = os.getenv('OPEN_AI_EMBEDDING_MODEL') or 'text-embedding-3-small'
OpenAIEmbedding(OPEN_AI_KEY)
# --- Semantic Router Setup --- #
PRODUCT_ROUTE_NAME = 'products'
CHITCHAT_ROUTE_NAME = 'chitchat'
openAIEmbeding = OpenAIEmbedding(apiKey=OPEN_AI_KEY, dimensions=1024, name=OPEN_AI_EMBEDDING_MODEL)
productRoute = Route(name=PRODUCT_ROUTE_NAME, samples=productsSample)
chitchatRoute = Route(name=CHITCHAT_ROUTE_NAME, samples=chitchatSample)
semanticRouter = SemanticRouter(openAIEmbeding, routes=[productRoute, chitchatRoute])
# --- End Semantic Router Setup --- #
# --- Set up LLMs --- #
genai.configure(api_key=LLM_KEY)
llm = genai.GenerativeModel('gemini-1.5-pro')
# --- End Set up LLMs --- #
# --- Relection Setup --- #
gpt = openai.OpenAI(api_key=OPEN_AI_KEY)
reflection = Reflection(llm=gpt)
# --- End Reflection Setup --- #
app = Flask(name)
CORS(app)
# Initialize RAG
rag = RAG(
    mongodbUri=MONGODB_URI,
    dbName=DB_NAME,
    dbCollection=DB_COLLECTION,
    embeddingName='keepitreal/vietnamese-sbert',
    llm=llm,
)
def process_query(query):
    return query.lower()
@app.route('/api/search', methods=['POST'])
def handle_query():
    data = list(request.get_json())
    query = data[-1]["parts"][0]["text"]
    query = process_query(query)
    if not query:
        return jsonify({'error': 'No query provided'}), 400

    # get last message

    guidedRoute = semanticRouter.guide(query)[1]
    if guidedRoute == PRODUCT_ROUTE_NAME:
        # Decide to get new info or use previous info
        # Guide to RAG system
        print("Guide to RAGs")
        reflected_query = reflection(data)
        # print('====query', query)
        # print('reflected_query', reflected_query)
        query = reflected_query
        source_information = rag.enhance_prompt(query).replace('<br>', '\n')
        combined_information = f"HÃ£y trá»Ÿ thÃ nh chuyÃªn gia tÆ° váº¥n bÃ¡n hÃ ng cho má»™t cá»­a hÃ ng Ä‘iá»‡n thoáº¡i. CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: {query}\nTráº£ lá»i cÃ¢u há»i dá»±a vÃ o cÃ¡c thÃ´ng tin sáº£n pháº©m dÆ°á»›i Ä‘Ã¢y: {source_information}."
        data.append({
            "role": "user",
            "parts": [
                {
                    "text": combined_information,
                }
            ]
        })
        response = rag.generate_content(data)
    else:
        # Guide to LLMs
        print("Guide to LLMs")
        response = llm.generate_content(data)
    # print('====data', data)

    return jsonify({
        'parts': [
            {
            'text': response.text,
            }
        ],
        'role': 'model'
        })
if name == 'main':
    app.run(host='0.0.0.0', port=5002, debug=True) oke broo hÃ£y giáº£i thÃ­ch ngáº¯n gá»n qua sÆ¡ Ä‘á»“ hoáº·t Ä‘á»™ng cá»§a code nÃ y cho tÃ´i Ä‘i brooo


ÄÃ¢y lÃ  sÆ¡ Ä‘á»“ hoáº¡t Ä‘á»™ng ngáº¯n gá»n cá»§a code:

Khá»Ÿi táº¡o:
Load biáº¿n mÃ´i trÆ°á»ng
Thiáº¿t láº­p Semantic Router vá»›i 2 route: products vÃ  chitchat
Khá»Ÿi táº¡o mÃ´ hÃ¬nh LLM (Gemini) vÃ  RAG system
Xá»­ lÃ½ query:
Nháº­n query tá»« request POST
Tiá»n xá»­ lÃ½ query (chuyá»ƒn lowercase)
Semantic Routing:
Sá»­ dá»¥ng SemanticRouter Ä‘á»ƒ phÃ¢n loáº¡i query
Xá»­ lÃ½ dá»±a trÃªn route:
Náº¿u lÃ  product query:
Sá»­ dá»¥ng Reflection Ä‘á»ƒ lÃ m rÃµ query
TÃ¬m thÃ´ng tin liÃªn quan báº±ng RAG
Táº¡o prompt káº¿t há»£p
Gá»­i prompt Ä‘áº¿n LLM Ä‘á»ƒ táº¡o pháº£n há»“i
Náº¿u lÃ  chitchat query:
Gá»­i trá»±c tiáº¿p Ä‘áº¿n LLM Ä‘á»ƒ xá»­ lÃ½
Tráº£ vá» káº¿t quáº£:
Äá»‹nh dáº¡ng pháº£n há»“i dÆ°á»›i dáº¡ng JSON
Gá»­i láº¡i cho client
MÃ´ hÃ¬nh nÃ y káº¿t há»£p Semantic Routing, RAG, vÃ  LLM Ä‘á»ƒ xá»­ lÃ½ cÃ¡c loáº¡i query khÃ¡c nhau má»™t cÃ¡ch hiá»‡u quáº£.

Copy
Retry


L
Xá»­ lÃ½ dá»±a trÃªn route: 
* Náº¿u lÃ  product query:
   * Sá»­ dá»¥ng Reflection Ä‘á»ƒ lÃ m rÃµ query
   * TÃ¬m thÃ´ng tin liÃªn quan báº±ng RAG
   * Táº¡o prompt káº¿t há»£p
   * Gá»­i prompt Ä‘áº¿n LLM Ä‘á»ƒ táº¡o pháº£n há»“i
* Náº¿u lÃ  chitchat query:
   * Gá»­i trá»±c tiáº¿p Ä‘áº¿n LLM Ä‘á»ƒ xá»­ lÃ½ báº¡n chÃ³ thá»ƒ chá»‰ rÃµ rÃ ng ra Ä‘oáº¡n code Ä‘Ã³ lÃ  Ä‘oáº¡n nÃ o , xá»­ lÃ½ nhÆ° nÃ o k brooo


Cháº¯c cháº¯n rá»“i bro, tÃ´i sáº½ chá»‰ ra Ä‘oáº¡n code cá»¥ thá»ƒ cho tá»«ng pháº§n:

Xá»­ lÃ½ dá»±a trÃªn route:
python

Copy
guidedRoute = semanticRouter.guide(query)[1]
if guidedRoute == PRODUCT_ROUTE_NAME:
    # Xá»­ lÃ½ product query
    ...
else:
    # Xá»­ lÃ½ chitchat query
    ...
Náº¿u lÃ  product query:
python

Copy
if guidedRoute == PRODUCT_ROUTE_NAME:
    print("Guide to RAGs")
    # Sá»­ dá»¥ng Reflection Ä‘á»ƒ lÃ m rÃµ query
    reflected_query = reflection(data)
    query = reflected_query
    
    # TÃ¬m thÃ´ng tin liÃªn quan báº±ng RAG
    source_information = rag.enhance_prompt(query).replace('<br>', '\n')
    
    # Táº¡o prompt káº¿t há»£p
    combined_information = f"HÃ£y trá»Ÿ thÃ nh chuyÃªn gia tÆ° váº¥n bÃ¡n hÃ ng cho má»™t cá»­a hÃ ng Ä‘iá»‡n thoáº¡i. CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: {query}\nTráº£ lá»i cÃ¢u há»i dá»±a vÃ o cÃ¡c thÃ´ng tin sáº£n pháº©m dÆ°á»›i Ä‘Ã¢y: {source_information}."
    
    # Chuáº©n bá»‹ data Ä‘á»ƒ gá»­i Ä‘áº¿n LLM
    data.append({
        "role": "user",
        "parts": [
            {
                "text": combined_information,
            }
        ]
    })
    
    # Gá»­i prompt Ä‘áº¿n LLM Ä‘á»ƒ táº¡o pháº£n há»“i
    response = rag.generate_content(data)
Náº¿u lÃ  chitchat query:
python

Copy
else:
    print("Guide to LLMs")
    # Gá»­i trá»±c tiáº¿p Ä‘áº¿n LLM Ä‘á»ƒ xá»­ lÃ½
    response = llm.generate_content(data)
ÄÃ¢y lÃ  cÃ¡ch code xá»­ lÃ½ cÃ¡c loáº¡i query khÃ¡c nhau. Vá»›i product query, nÃ³ sá»­ dá»¥ng nhiá»u bÆ°á»›c phá»©c táº¡p hÆ¡n Ä‘á»ƒ tÃ¬m thÃ´ng tin liÃªn quan vÃ  táº¡o prompt chi tiáº¿t. Vá»›i chitchat query, nÃ³ chá»‰ Ä‘Æ¡n giáº£n chuyá»ƒn trá»±c tiáº¿p Ä‘áº¿n LLM Ä‘á»ƒ xá»­ lÃ½.

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
tÃ´i cá»© cÃ³ cáº£m giÃ¡c gÃ¬ Ä‘Ã³ cáº¥n cáº¥n. cÃ³ giáº£i phÃ¡p nÃ o okela hÆ¡n k brooo


TÃ´i hiá»ƒu cáº£m giÃ¡c cá»§a báº¡n. ÄÃºng lÃ  cÃ¡ch tiáº¿p cáº­n hiá»‡n táº¡i cÃ³ thá»ƒ chÆ°a tá»‘i Æ°u. HÃ£y xem xÃ©t má»™t sá»‘ giáº£i phÃ¡p cÃ³ thá»ƒ cáº£i thiá»‡n:

Sá»­ dá»¥ng mÃ´ hÃ¬nh phÃ¢n loáº¡i nháº¹:
Thay vÃ¬ dÃ¹ng embedding vÃ  cosine similarity, ta cÃ³ thá»ƒ dÃ¹ng má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i vÄƒn báº£n nháº¹ nhÆ° fastText hoáº·c má»™t mÃ´ hÃ¬nh BERT nhá» Ä‘Ã£ Ä‘Æ°á»£c fine-tune.
Äiá»u nÃ y cÃ³ thá»ƒ nhanh hÆ¡n vÃ  tiáº¿t kiá»‡m tÃ i nguyÃªn hÆ¡n.
Cáº£i thiá»‡n Semantic Router:
Thay vÃ¬ chá»‰ phÃ¢n loáº¡i thÃ nh product/chitchat, ta cÃ³ thá»ƒ phÃ¢n loáº¡i chi tiáº¿t hÆ¡n (vÃ­ dá»¥: product_info, product_comparison, product_recommendation, general_chat, etc.).
Äiá»u nÃ y sáº½ giÃºp Ä‘á»‹nh tuyáº¿n chÃ­nh xÃ¡c hÆ¡n vÃ  xá»­ lÃ½ tá»‘t hÆ¡n.
Sá»­ dá»¥ng cache thÃ´ng minh:
LÆ°u káº¿t quáº£ phÃ¢n loáº¡i vÃ  pháº£n há»“i cho cÃ¡c cÃ¢u há»i phá»• biáº¿n.
Sá»­ dá»¥ng fuzzy matching Ä‘á»ƒ tÃ¬m cÃ¢u há»i tÆ°Æ¡ng tá»± trong cache.
TÃ­ch há»£p xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP):
Sá»­ dá»¥ng NER (Named Entity Recognition) Ä‘á»ƒ nháº­n diá»‡n tÃªn sáº£n pháº©m, thuá»™c tÃ­nh.
Ãp dá»¥ng sentiment analysis Ä‘á»ƒ hiá»ƒu tÃ¢m tráº¡ng cá»§a ngÆ°á»i dÃ¹ng.
Sá»­ dá»¥ng há»‡ thá»‘ng rule-based káº¿t há»£p:
Táº¡o má»™t sá»‘ rule cÆ¡ báº£n Ä‘á»ƒ nhanh chÃ³ng phÃ¢n loáº¡i cÃ¡c cÃ¢u há»i Ä‘Æ¡n giáº£n.
Chá»‰ sá»­ dá»¥ng LLM cho cÃ¡c trÆ°á»ng há»£p phá»©c táº¡p.
VÃ­ dá»¥ code cho giáº£i phÃ¡p káº¿t há»£p:

python

Copy
import fasttext
from fuzzywuzzy import fuzz
import spacy

# Táº£i mÃ´ hÃ¬nh fastText Ä‘Ã£ Ä‘Æ°á»£c train trÆ°á»›c
classifier = fasttext.load_model('path_to_model.bin')

# Táº£i mÃ´ hÃ¬nh NLP
nlp = spacy.load("vi_core_news_lg")

# Cache Ä‘Æ¡n giáº£n
query_cache = {}

def classify_and_process_query(query):
    # Kiá»ƒm tra cache
    for cached_query, result in query_cache.items():
        if fuzz.ratio(query, cached_query) > 90:
            return result

    # PhÃ¢n loáº¡i báº±ng fastText
    classification = classifier.predict(query)[0][0]

    # Xá»­ lÃ½ NER
    doc = nlp(query)
    entities = [(ent.text, ent.label_) for ent in doc.ents]

    if classification == "product":
        if any(entity[1] == "PRODUCT" for entity in entities):
            # Xá»­ lÃ½ truy váº¥n sáº£n pháº©m cá»¥ thá»ƒ
            result = process_product_query(query, entities)
        else:
            # Xá»­ lÃ½ truy váº¥n sáº£n pháº©m chung
            result = process_general_product_query(query)
    else:
        # Xá»­ lÃ½ trÃ² chuyá»‡n thÃ´ng thÆ°á»ng
        result = process_chitchat(query)

    # LÆ°u vÃ o cache
    query_cache[query] = result
    return result

# CÃ¡c hÃ m xá»­ lÃ½ cá»¥ thá»ƒ
def process_product_query(query, entities):
    # Xá»­ lÃ½ truy váº¥n sáº£n pháº©m cá»¥ thá»ƒ
    pass

def process_general_product_query(query):
    # Xá»­ lÃ½ truy váº¥n sáº£n pháº©m chung
    pass

def process_chitchat(query):
    # Xá»­ lÃ½ trÃ² chuyá»‡n thÃ´ng thÆ°á»ng
    pass
CÃ¡ch tiáº¿p cáº­n nÃ y káº¿t há»£p nhiá»u ká»¹ thuáº­t Ä‘á»ƒ xá»­ lÃ½ query hiá»‡u quáº£ hÆ¡n, giáº£m phá»¥ thuá»™c vÃ o LLM cho má»i trÆ°á»ng há»£p. Báº¡n tháº¥y giáº£i phÃ¡p nÃ y tháº¿ nÃ o?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
#Báº¯t Ä‘áº§u cuá»™c trÃ² chuyá»‡n # while True: question = input("Báº¡n: ") template = """ You are a super clever and polite AI assistant for Metagent, an online men's fashion store from Vietnam. Metagent offers high-quality men's clothing fitting modern fashion trends and personal styles. All product information is available to you Your goal is helping customers find and buy products matching their tastes and needs. You can address inquiries about products, sizing, shipping, returns, etc. Use customer name and purchase history to give personalized recommendations. Stay courteous always, even if customers are frustrated. You can also suggest coordinated outfits for a complete look. Using Vietnamese in all conservation   Given the customer question: "{question}"   Initialize variables:   chatbot_state = None   chatbot_response = None   {context}    Decision Logic:      1. If the question is a general inquiry that the chatbot can handle:         - Examples include FAQs, simple queries about services, etc.         chatbot_state = "True"         Generate a chatbot response based on the following criteria:           - Accuracy of the information         Store the generated response in chatbot_response      2. If the question is complex, ambiguous, or requires human (admin) ():         - Examples include technical issues, personalized recommendations, etc.         chatbot_state = "False"         Generate a chatbot response based on the following criteria:           - If the customer mentions wanting to speak to human, indicate that they will be connected to an admin.           - If the customer uses impolite language, remind them to maintain a respectful tone while indicating that they will be transferred             to an agent.         Store the generated response in chatbot_response     Output Format:      Return the response in a structured string format that closely resembles JSON, with the following keys:       "chatbot_state": chatbot_state       "chatbot_response": chatbot_response""" QA_PROMPT = PromptTemplate(template=template, input_variables=["question","context"])   chain = get_custom_prompt_qa_chain1(QA_PROMPT) # result = chain({"question": question}, return_only_outputs=True) result = chain.run(question) a = result['answer'] output_dict = json.loads(a)  # Get chatbot_state chatbot_state = output_dict['chatbot_state'] # Get chatbot_response chatbot_response = output_dict['chatbot_response']  if chatbot_state == "True":   if 'http' in result['answer']:     # CÃ³ yÃªu cáº§u gá»­i áº£nh     img_url = chatbot_response.split('(')[1].split(')')[0]      html_str = '<img src="{url}" width={width} height={height}/>'      img_html = html_str.format(url=img_url, width=200, height=300)      from IPython.display import display, HTML     display(HTML(img_html))     # ThÃªm mÃ´ táº£ chi tiáº¿t sáº£n pháº©m     print("Bot:", chatbot_response)    else:     # Tráº£ lá»i bÃ¬nh thÆ°á»ng náº¿u khÃ´ng yÃªu cáº§u gá»­i áº£nh     print("Bot : ", chatbot_response)  if chatbot_state == "False":   print("Bot : ", chatbot_response)   answer = input("TÆ° váº¥n viÃªn nháº­p tin nháº¯n: ")   print("TÆ° váº¥n viÃªn: ", answer)     Ä‘Ã¢y nÃ y bro. tÃ´i muá»‘n cÃ³ 1 cÃ¡ch nÃ³ tÆ°Æ¡ng tá»± nhÆ° nÃ y nÃ y bro Æ¡iii


Hiá»ƒu rá»“i bro. Báº¡n muá»‘n má»™t cÃ¡ch tiáº¿p cáº­n tÆ°Æ¡ng tá»±, sá»­ dá»¥ng má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘á»ƒ phÃ¢n loáº¡i vÃ  xá»­ lÃ½ cÃ¡c cÃ¢u há»i. ÄÃ¢y lÃ  má»™t phiÃªn báº£n Ä‘Æ°á»£c Ä‘iá»u chá»‰nh dá»±a trÃªn code cá»§a báº¡n, tÃ­ch há»£p vá»›i setup hiá»‡n táº¡i cá»§a báº¡n:

python

Copy
from flask import Flask, request, jsonify
from dotenv import load_dotenv
import os
import json
from langchain.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
import google.generativeai as genai
from flask_cors import CORS
from rag.core import RAG
from reflection import Reflection

# Load environment variables and setup
load_dotenv()
MONGODB_URI = os.getenv('MONGODB_URI')
DB_NAME = os.getenv('DB_NAME')
DB_COLLECTION = os.getenv('DB_COLLECTION')
LLM_KEY = os.getenv('GEMINI_KEY')

# Setup LLM
genai.configure(api_key=LLM_KEY)
llm = genai.GenerativeModel('gemini-1.5-pro')

# Setup RAG and Reflection
rag = RAG(mongodbUri=MONGODB_URI, dbName=DB_NAME, dbCollection=DB_COLLECTION, embeddingName='keepitreal/vietnamese-sbert', llm=llm)
reflection = Reflection(llm=llm)

app = Flask(__name__)
CORS(app)

ROUTER_PROMPT = """
You are a super clever and polite AI assistant for an online fashion store from Vietnam. 
Your goal is helping customers find and buy products matching their tastes and needs. 

Given the customer question: "{question}"

Initialize variables:
chatbot_state = None
chatbot_response = None

{context}

Decision Logic:
1. If the question is a general inquiry or about products that the chatbot can handle:
   chatbot_state = "product"
   Generate a response based on product information and store it in chatbot_response

2. If the question is a simple chitchat that doesn't require product knowledge:
   chatbot_state = "chitchat"
   Generate a friendly, conversational response and store it in chatbot_response

3. If the question is complex, ambiguous, or requires human assistance:
   chatbot_state = "human"
   Generate a response indicating that a human will assist and store it in chatbot_response

Output Format:
Return the response in a structured string format that closely resembles JSON, with the following keys:
 "chatbot_state": chatbot_state
 "chatbot_response": chatbot_response
"""

ROUTER_PROMPT_TEMPLATE = PromptTemplate(template=ROUTER_PROMPT, input_variables=["question", "context"])

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.get_json()
    query = data['question']
    
    # Use RAG to get relevant context
    context = rag.enhance_prompt(query)
    
    # Use LLM to classify and generate initial response
    router_response = llm.generate_content(ROUTER_PROMPT_TEMPLATE.format(question=query, context=context))
    router_output = json.loads(router_response.text)
    
    chatbot_state = router_output['chatbot_state']
    chatbot_response = router_output['chatbot_response']
    
    if chatbot_state == "product":
        # Use reflection to improve product-related response
        reflected_query = reflection(query)
        enhanced_prompt = f"HÃ£y trá»Ÿ thÃ nh chuyÃªn gia tÆ° váº¥n bÃ¡n hÃ ng. CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: {reflected_query}\n{context}"
        final_response = rag.generate_content(enhanced_prompt)
        chatbot_response = final_response.text
    
    return jsonify({
        'state': chatbot_state,
        'response': chatbot_response
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5002, debug=True)
Giáº£i thÃ­ch:

ChÃºng ta sá»­ dá»¥ng má»™t prompt duy nháº¥t (ROUTER_PROMPT) Ä‘á»ƒ phÃ¢n loáº¡i cÃ¢u há»i vÃ  táº¡o pháº£n há»“i ban Ä‘áº§u.
LLM sáº½ phÃ¢n loáº¡i cÃ¢u há»i thÃ nh má»™t trong ba loáº¡i: product, chitchat, hoáº·c human.
Äá»‘i vá»›i cÃ¢u há»i vá» sáº£n pháº©m, chÃºng ta sá»­ dá»¥ng RAG vÃ  reflection Ä‘á»ƒ cáº£i thiá»‡n cÃ¢u tráº£ lá»i.
Äá»‘i vá»›i chitchat, chÃºng ta sá»­ dá»¥ng pháº£n há»“i trá»±c tiáº¿p tá»« LLM.
Äá»‘i vá»›i cÃ¢u há»i phá»©c táº¡p cáº§n sá»± há»— trá»£ cá»§a con ngÆ°á»i, chÃºng ta tráº£ vá» má»™t thÃ´ng bÃ¡o phÃ¹ há»£p.
CÃ¡ch tiáº¿p cáº­n nÃ y Ä‘Æ¡n giáº£n hÃ³a luá»“ng xá»­ lÃ½, sá»­ dá»¥ng sá»©c máº¡nh cá»§a LLM Ä‘á»ƒ phÃ¢n loáº¡i vÃ  xá»­ lÃ½ cÃ¡c loáº¡i cÃ¢u há»i khÃ¡c nhau, Ä‘á»“ng thá»i táº­n dá»¥ng RAG vÃ  reflection cho cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n sáº£n pháº©m.

Báº¡n tháº¥y cÃ¡ch nÃ y cÃ³ phÃ¹ há»£p vÃ  dá»… tÃ­ch há»£p vá»›i há»‡ thá»‘ng hiá»‡n táº¡i cá»§a báº¡n khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
prompt chÆ°a Ä‘Æ°á»£c cá»©ng láº¯m, pháº£i Ä‘áº£m báº£o lÃ  : from flask import Flask, request, jsonify
from dotenv import load_dotenv
import os
import json
from langchain.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
import google.generativeai as genai
from flask_cors import CORS
from rag.core import RAG
from reflection import Reflection
# Load environment variables and setup
load_dotenv()
MONGODB_URI = os.getenv('MONGODB_URI')
DB_NAME = os.getenv('DB_NAME')
DB_COLLECTION = os.getenv('DB_COLLECTION')
LLM_KEY = os.getenv('GEMINI_KEY')
# Setup LLM
genai.configure(api_key=LLM_KEY)
llm = genai.GenerativeModel('gemini-1.5-pro')
# Setup RAG and Reflection
rag = RAG(mongodbUri=MONGODB_URI, dbName=DB_NAME, dbCollection=DB_COLLECTION, embeddingName='keepitreal/vietnamese-sbert', llm=llm)
reflection = Reflection(llm=llm)
app = Flask(name)
CORS(app)
ROUTER_PROMPT = """
You are a super clever and polite AI assistant for an online fashion store from Vietnam. 
Your goal is helping customers find and buy products matching their tastes and needs. 
Given the customer question: "{question}"
Initialize variables:
chatbot_state = None
chatbot_response = None
{context}
Decision Logic:
1. If the question is a general inquiry or about products that the chatbot can handle:
   chatbot_state = "product"
   Generate a response based on product information and store it in chatbot_response
2. If the question is a simple chitchat that doesn't require product knowledge:
   chatbot_state = "chitchat"
   Generate a friendly, conversational response and store it in chatbot_response
3. If the question is complex, ambiguous, or requires human assistance:
   chatbot_state = "human"
   Generate a response indicating that a human will assist and store it in chatbot_response
Output Format:
Return the response in a structured string format that closely resembles JSON, with the following keys:
 "chatbot_state": chatbot_state
 "chatbot_response": chatbot_response
"""
ROUTER_PROMPT_TEMPLATE = PromptTemplate(template=ROUTER_PROMPT, input_variables=["question", "context"])
@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.get_json()
    query = data['question']

    # Use RAG to get relevant context
    context = rag.enhance_prompt(query)

    # Use LLM to classify and generate initial response
    router_response = llm.generate_content(ROUTER_PROMPT_TEMPLATE.format(question=query, context=context))
    router_output = json.loads(router_response.text)

    chatbot_state = router_output['chatbot_state']
    chatbot_response = router_output['chatbot_response']

    if chatbot_state == "product":
        # Use reflection to improve product-related response
        reflected_query = reflection(query)
        enhanced_prompt = f"HÃ£y trá»Ÿ thÃ nh chuyÃªn gia tÆ° váº¥n bÃ¡n hÃ ng. CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: {reflected_query}\n{context}"
        final_response = rag.generate_content(enhanced_prompt)
        chatbot_response = final_response.text

    return jsonify({
        'state': chatbot_state,
        'response': chatbot_response
    })
if name == 'main':
    app.run(host='0.0.0.0', port=5002, debug=True) . prompt chÆ°a Ä‘Æ°á»£c á»•n, thá»© 2 lÃ  pháº£i cÃ³ 1 cÃ¡i models Ä‘á»ƒ Ã©p format tráº£ vá» Ä‘Ãºng kiá»ƒu output LLMs, bro hiáº¿u Ã½ tÃ´i chá»©, náº¿u lÃ  chitchat thÃ¬ lÃ m tháº¿ nÃ o, náº¿u lÃ  products thÃ¬ lÃ m tháº¿ nÃ o,... cÃ²n náº¿u lÃ  lá»i requerst thÃ¬ lÃ m tháº¿ nÃ o. trÃ¬nh bÃ y cho tÃ´i Ã½ tÆ°á»Ÿng cá»¥ thá»ƒ chi tiáº¿t tá»« a-z. giao diá»‡n khi requerst hiá»ƒn thá»‹ nhÆ° nÃ o...... bro hiá»ƒu Ã½ tÃ´i chá»©. cá»© flask mÃ  triá»ƒn. code viáº¿t rÃµ rÃ ng Ä‘áº§y Ä‘á»§ Ä‘á»ƒ tÃ´i cÃ³ thá»ƒ copy vÃ  cháº¡y ngay láº­p tá»©cc


Hiá»ƒu rá»“i bro. TÃ´i sáº½ viáº¿t láº¡i code chi tiáº¿t hÆ¡n, bao gá»“m cáº£ mÃ´ hÃ¬nh Ä‘á»ƒ Ã©p format output vÃ  xá»­ lÃ½ cÃ¡c trÆ°á»ng há»£p khÃ¡c nhau. ÄÃ¢y lÃ  phiÃªn báº£n má»›i, chi tiáº¿t vÃ  cÃ³ thá»ƒ cháº¡y ngay:

python

Copy
from flask import Flask, request, jsonify, render_template
from dotenv import load_dotenv
import os
import json
from pydantic import BaseModel, Field
from typing import Literal
from langchain.prompts import PromptTemplate
import google.generativeai as genai
from flask_cors import CORS
from rag.core import RAG
from reflection import Reflection

# Load environment variables
load_dotenv()
MONGODB_URI = os.getenv('MONGODB_URI')
DB_NAME = os.getenv('DB_NAME')
DB_COLLECTION = os.getenv('DB_COLLECTION')
LLM_KEY = os.getenv('GEMINI_KEY')

# Setup LLM
genai.configure(api_key=LLM_KEY)
llm = genai.GenerativeModel('gemini-1.5-pro')

# Setup RAG and Reflection
rag = RAG(mongodbUri=MONGODB_URI, dbName=DB_NAME, dbCollection=DB_COLLECTION, embeddingName='keepitreal/vietnamese-sbert', llm=llm)
reflection = Reflection(llm=llm)

app = Flask(__name__)
CORS(app)

# Pydantic model for response format
class ChatbotResponse(BaseModel):
    chatbot_state: Literal["product", "chitchat", "human"]
    chatbot_response: str

ROUTER_PROMPT = """
Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh vÃ  lá»‹ch sá»± cho cá»­a hÃ ng thá»i trang trá»±c tuyáº¿n tá»« Viá»‡t Nam.
Má»¥c tiÃªu cá»§a báº¡n lÃ  giÃºp khÃ¡ch hÃ ng tÃ¬m vÃ  mua sáº£n pháº©m phÃ¹ há»£p vá»›i sá»Ÿ thÃ­ch vÃ  nhu cáº§u cá»§a há».

CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: "{question}"

ThÃ´ng tin sáº£n pháº©m:
{context}

Logic quyáº¿t Ä‘á»‹nh:
1. Náº¿u cÃ¢u há»i liÃªn quan Ä‘áº¿n sáº£n pháº©m hoáº·c lÃ  cÃ¢u há»i chung mÃ  chatbot cÃ³ thá»ƒ xá»­ lÃ½:
   chatbot_state = "product"
   Táº¡o cÃ¢u tráº£ lá»i dá»±a trÃªn thÃ´ng tin sáº£n pháº©m vÃ  lÆ°u vÃ o chatbot_response

2. Náº¿u cÃ¢u há»i lÃ  trÃ² chuyá»‡n Ä‘Æ¡n giáº£n khÃ´ng yÃªu cáº§u kiáº¿n thá»©c vá» sáº£n pháº©m:
   chatbot_state = "chitchat"
   Táº¡o cÃ¢u tráº£ lá»i thÃ¢n thiá»‡n, há»™i thoáº¡i vÃ  lÆ°u vÃ o chatbot_response

3. Náº¿u cÃ¢u há»i phá»©c táº¡p, khÃ´ng rÃµ rÃ ng hoáº·c cáº§n sá»± há»— trá»£ cá»§a con ngÆ°á»i:
   chatbot_state = "human"
   Táº¡o cÃ¢u tráº£ lá»i cho biáº¿t má»™t nhÃ¢n viÃªn sáº½ há»— trá»£ vÃ  lÆ°u vÃ o chatbot_response

Äá»‹nh dáº¡ng Ä‘áº§u ra:
Tráº£ vá» cÃ¢u tráº£ lá»i dÆ°á»›i dáº¡ng chuá»—i cÃ³ cáº¥u trÃºc giá»‘ng JSON, vá»›i cÃ¡c khÃ³a sau:
 "chatbot_state": chatbot_state
 "chatbot_response": chatbot_response

LÆ°u Ã½: Äáº£m báº£o ráº±ng Ä‘áº§u ra cá»§a báº¡n cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n tÃ­ch cÃº phÃ¡p bá»Ÿi json.loads() trong Python.
"""

ROUTER_PROMPT_TEMPLATE = PromptTemplate(template=ROUTER_PROMPT, input_variables=["question", "context"])

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.get_json()
    query = data['question']
    
    # Use RAG to get relevant context
    context = rag.enhance_prompt(query)
    
    # Use LLM to classify and generate initial response
    router_response = llm.generate_content(ROUTER_PROMPT_TEMPLATE.format(question=query, context=context))
    
    try:
        router_output = json.loads(router_response.text)
        response = ChatbotResponse(**router_output)
    except json.JSONDecodeError:
        return jsonify({"error": "Invalid response format from LLM"}), 500
    except ValueError:
        return jsonify({"error": "Response does not match expected schema"}), 500

    if response.chatbot_state == "product":
        # Use reflection to improve product-related response
        reflected_query = reflection(query)
        enhanced_prompt = f"""
        HÃ£y trá»Ÿ thÃ nh chuyÃªn gia tÆ° váº¥n bÃ¡n hÃ ng. 
        CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: {reflected_query}
        
        ThÃ´ng tin sáº£n pháº©m:
        {context}
        
        Tráº£ lá»i cÃ¢u há»i cá»§a khÃ¡ch hÃ ng má»™t cÃ¡ch chi tiáº¿t, Ä‘áº§y Ä‘á»§ vÃ  chuyÃªn nghiá»‡p.
        """
        final_response = llm.generate_content(enhanced_prompt)
        response.chatbot_response = final_response.text

    return jsonify(response.dict())

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5002, debug=True)
VÃ  Ä‘Ã¢y lÃ  má»™t máº«u HTML Ä‘Æ¡n giáº£n Ä‘á»ƒ hiá»ƒn thá»‹ giao diá»‡n (templates/index.html):

html

Copy
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fashion Store Chatbot</title>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <style>
        #chatbox {
            height: 300px;
            border: 1px solid #ddd;
            padding: 10px;
            overflow-y: scroll;
        }
    </style>
</head>
<body>
    <h1>Fashion Store Chatbot</h1>
    <div id="chatbox"></div>
    <input type="text" id="user-input" placeholder="Type your message...">
    <button onclick="sendMessage()">Send</button>

    <script>
        function sendMessage() {
            var userInput = $('#user-input').val();
            $('#chatbox').append('<p><strong>You:</strong> ' + userInput + '</p>');
            $('#user-input').val('');

            $.ajax({
                url: '/api/chat',
                type: 'POST',
                contentType: 'application/json',
                data: JSON.stringify({question: userInput}),
                success: function(response) {
                    var botResponse = '<p><strong>Bot ';
                    if (response.state === 'human') {
                        botResponse += '(Human Assistant)';
                    }
                    botResponse += ':</strong> ' + response.response + '</p>';
                    $('#chatbox').append(botResponse);
                    $('#chatbox').scrollTop($('#chatbox')[0].scrollHeight);
                }
            });
        }
    </script>
</body>
</html>
Giáº£i thÃ­ch:

Prompt Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘á»ƒ Ä‘áº£m báº£o output Ä‘Ãºng format JSON.
Sá»­ dá»¥ng Pydantic model (ChatbotResponse) Ä‘á»ƒ Ã©p format tráº£ vá».
Xá»­ lÃ½ cÃ¡c trÆ°á»ng há»£p khÃ¡c nhau:
Vá»›i "product", sá»­ dá»¥ng reflection vÃ  RAG Ä‘á»ƒ cáº£i thiá»‡n cÃ¢u tráº£ lá»i.
Vá»›i "chitchat", tráº£ vá» cÃ¢u tráº£ lá»i trá»±c tiáº¿p tá»« LLM.
Vá»›i "human", tráº£ vá» thÃ´ng bÃ¡o sáº½ cÃ³ nhÃ¢n viÃªn há»— trá»£.
Giao diá»‡n web Ä‘Æ¡n giáº£n Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i chatbot.
Xá»­ lÃ½ lá»—i khi LLM tráº£ vá» khÃ´ng Ä‘Ãºng format.
Äá»ƒ cháº¡y:

Äáº£m báº£o cÃ¡c biáº¿n mÃ´i trÆ°á»ng Ä‘Æ°á»£c set Ä‘Ãºng trong file .env
Táº¡o thÆ° má»¥c templates vÃ  Ä‘áº·t file index.html vÃ o Ä‘Ã³
Cháº¡y file Python
Báº¡n cÃ³ thá»ƒ copy code nÃ y vÃ  cháº¡y ngay láº­p tá»©c. NÃ³ sáº½ táº¡o má»™t server Flask vá»›i endpoint /api/chat Ä‘á»ƒ xá»­ lÃ½ cÃ¡c cÃ¢u há»i vÃ  má»™t giao diá»‡n web Ä‘Æ¡n giáº£n á»Ÿ route /. Bro tháº¥y version nÃ y cÃ³ á»•n hÆ¡n khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
tháº¿ cÃ²n giao diá»‡n admin náº¿u Ä‘Æ°á»£c yÃªu cáº§u chuyá»ƒn cho human Ä‘Ã¢u brooo


ÄÃºng rá»“i, tÃ´i Ä‘Ã£ bá» sÃ³t pháº§n giao diá»‡n admin. ÄÃ¢y lÃ  phiÃªn báº£n cáº­p nháº­t bao gá»“m cáº£ giao diá»‡n admin Ä‘á»ƒ xá»­ lÃ½ cÃ¡c yÃªu cáº§u chuyá»ƒn cho human:

python

Copy
from flask import Flask, request, jsonify, render_template
from flask_socketio import SocketIO, emit
from dotenv import load_dotenv
import os
import json
from pydantic import BaseModel, Field
from typing import Literal
from langchain.prompts import PromptTemplate
import google.generativeai as genai
from flask_cors import CORS
from rag.core import RAG
from reflection import Reflection

# Load environment variables
load_dotenv()
MONGODB_URI = os.getenv('MONGODB_URI')
DB_NAME = os.getenv('DB_NAME')
DB_COLLECTION = os.getenv('DB_COLLECTION')
LLM_KEY = os.getenv('GEMINI_KEY')

# Setup LLM
genai.configure(api_key=LLM_KEY)
llm = genai.GenerativeModel('gemini-1.5-pro')

# Setup RAG and Reflection
rag = RAG(mongodbUri=MONGODB_URI, dbName=DB_NAME, dbCollection=DB_COLLECTION, embeddingName='keepitreal/vietnamese-sbert', llm=llm)
reflection = Reflection(llm=llm)

app = Flask(__name__)
CORS(app)
socketio = SocketIO(app, cors_allowed_origins="*")

# Pydantic model for response format
class ChatbotResponse(BaseModel):
    chatbot_state: Literal["product", "chitchat", "human"]
    chatbot_response: str

ROUTER_PROMPT = """
Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh vÃ  lá»‹ch sá»± cho cá»­a hÃ ng thá»i trang trá»±c tuyáº¿n tá»« Viá»‡t Nam.
Má»¥c tiÃªu cá»§a báº¡n lÃ  giÃºp khÃ¡ch hÃ ng tÃ¬m vÃ  mua sáº£n pháº©m phÃ¹ há»£p vá»›i sá»Ÿ thÃ­ch vÃ  nhu cáº§u cá»§a há».

CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: "{question}"

ThÃ´ng tin sáº£n pháº©m:
{context}

Logic quyáº¿t Ä‘á»‹nh:
1. Náº¿u cÃ¢u há»i liÃªn quan Ä‘áº¿n sáº£n pháº©m hoáº·c lÃ  cÃ¢u há»i chung mÃ  chatbot cÃ³ thá»ƒ xá»­ lÃ½:
   chatbot_state = "product"
   Táº¡o cÃ¢u tráº£ lá»i dá»±a trÃªn thÃ´ng tin sáº£n pháº©m vÃ  lÆ°u vÃ o chatbot_response

2. Náº¿u cÃ¢u há»i lÃ  trÃ² chuyá»‡n Ä‘Æ¡n giáº£n khÃ´ng yÃªu cáº§u kiáº¿n thá»©c vá» sáº£n pháº©m:
   chatbot_state = "chitchat"
   Táº¡o cÃ¢u tráº£ lá»i thÃ¢n thiá»‡n, há»™i thoáº¡i vÃ  lÆ°u vÃ o chatbot_response

3. Náº¿u cÃ¢u há»i phá»©c táº¡p, khÃ´ng rÃµ rÃ ng hoáº·c cáº§n sá»± há»— trá»£ cá»§a con ngÆ°á»i:
   chatbot_state = "human"
   Táº¡o cÃ¢u tráº£ lá»i cho biáº¿t má»™t nhÃ¢n viÃªn sáº½ há»— trá»£ vÃ  lÆ°u vÃ o chatbot_response

Äá»‹nh dáº¡ng Ä‘áº§u ra:
Tráº£ vá» cÃ¢u tráº£ lá»i dÆ°á»›i dáº¡ng chuá»—i cÃ³ cáº¥u trÃºc giá»‘ng JSON, vá»›i cÃ¡c khÃ³a sau:
 "chatbot_state": chatbot_state
 "chatbot_response": chatbot_response

LÆ°u Ã½: Äáº£m báº£o ráº±ng Ä‘áº§u ra cá»§a báº¡n cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n tÃ­ch cÃº phÃ¡p bá»Ÿi json.loads() trong Python.
"""

ROUTER_PROMPT_TEMPLATE = PromptTemplate(template=ROUTER_PROMPT, input_variables=["question", "context"])

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/admin')
def admin():
    return render_template('admin.html')

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.get_json()
    query = data['question']
    
    # Use RAG to get relevant context
    context = rag.enhance_prompt(query)
    
    # Use LLM to classify and generate initial response
    router_response = llm.generate_content(ROUTER_PROMPT_TEMPLATE.format(question=query, context=context))
    
    try:
        router_output = json.loads(router_response.text)
        response = ChatbotResponse(**router_output)
    except json.JSONDecodeError:
        return jsonify({"error": "Invalid response format from LLM"}), 500
    except ValueError:
        return jsonify({"error": "Response does not match expected schema"}), 500

    if response.chatbot_state == "product":
        # Use reflection to improve product-related response
        reflected_query = reflection(query)
        enhanced_prompt = f"""
        HÃ£y trá»Ÿ thÃ nh chuyÃªn gia tÆ° váº¥n bÃ¡n hÃ ng. 
        CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: {reflected_query}
        
        ThÃ´ng tin sáº£n pháº©m:
        {context}
        
        Tráº£ lá»i cÃ¢u há»i cá»§a khÃ¡ch hÃ ng má»™t cÃ¡ch chi tiáº¿t, Ä‘áº§y Ä‘á»§ vÃ  chuyÃªn nghiá»‡p.
        """
        final_response = llm.generate_content(enhanced_prompt)
        response.chatbot_response = final_response.text
    elif response.chatbot_state == "human":
        # Emit a socket event to notify admin
        socketio.emit('new_human_request', {'question': query, 'response': response.chatbot_response})

    return jsonify(response.dict())

@socketio.on('admin_response')
def handle_admin_response(data):
    # Handle admin response and send it back to the user
    emit('chat_response', {'response': data['response'], 'is_admin': True}, broadcast=True)

if __name__ == '__main__':
    socketio.run(app, host='0.0.0.0', port=5002, debug=True)
VÃ  Ä‘Ã¢y lÃ  hai file HTML cho giao diá»‡n ngÆ°á»i dÃ¹ng vÃ  admin:

templates/index.html:

html

Copy
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fashion Store Chatbot</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <style>
        #chatbox {
            height: 300px;
            border: 1px solid #ddd;
            padding: 10px;
            overflow-y: scroll;
        }
    </style>
</head>
<body>
    <h1>Fashion Store Chatbot</h1>
    <div id="chatbox"></div>
    <input type="text" id="user-input" placeholder="Type your message...">
    <button onclick="sendMessage()">Send</button>

    <script>
        var socket = io();

        function sendMessage() {
            var userInput = $('#user-input').val();
            $('#chatbox').append('<p><strong>You:</strong> ' + userInput + '</p>');
            $('#user-input').val('');

            $.ajax({
                url: '/api/chat',
                type: 'POST',
                contentType: 'application/json',
                data: JSON.stringify({question: userInput}),
                success: function(response) {
                    var botResponse = '<p><strong>Bot';
                    if (response.chatbot_state === 'human') {
                        botResponse += ' (Human Assistant)';
                    }
                    botResponse += ':</strong> ' + response.chatbot_response + '</p>';
                    $('#chatbox').append(botResponse);
                    $('#chatbox').scrollTop($('#chatbox')[0].scrollHeight);
                }
            });
        }

        socket.on('chat_response', function(data) {
            var response = '<p><strong>' + (data.is_admin ? 'Admin' : 'Bot') + ':</strong> ' + data.response + '</p>';
            $('#chatbox').append(response);
            $('#chatbox').scrollTop($('#chatbox')[0].scrollHeight);
        });
    </script>
</body>
</html>
templates/admin.html:

html

Copy
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Admin Dashboard</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <style>
        #requests {
            height: 300px;
            border: 1px solid #ddd;
            padding: 10px;
            overflow-y: scroll;
        }
    </style>
</head>
<body>
    <h1>Admin Dashboard</h1>
    <div id="requests"></div>
    <input type="text" id="admin-input" placeholder="Type your response...">
    <button onclick="sendAdminResponse()">Send Response</button>

    <script>
        var socket = io();

        socket.on('new_human_request', function(data) {
            $('#requests').append('<p><strong>New Request:</strong> ' + data.question + '</p>');
            $('#requests').append('<p><strong>Bot Response:</strong> ' + data.response + '</p>');
            $('#requests').scrollTop($('#requests')[0].scrollHeight);
        });

        function sendAdminResponse() {
            var adminInput = $('#admin-input').val();
            socket.emit('admin_response', {response: adminInput});
            $('#admin-input').val('');
            $('#requests').append('<p><strong>Admin Response:</strong> ' + adminInput + '</p>');
            $('#requests').scrollTop($('#requests')[0].scrollHeight);
        }
    </script>
</body>
</html>
Giáº£i thÃ­ch cÃ¡c thay Ä‘á»•i:

ThÃªm SocketIO Ä‘á»ƒ xá»­ lÃ½ real-time communication giá»¯a user, admin, vÃ  server.
Táº¡o route /admin cho giao diá»‡n admin.
Trong hÃ m chat(), náº¿u chatbot_state lÃ  "human", emit má»™t sá»± kiá»‡n socket Ä‘á»ƒ thÃ´ng bÃ¡o cho admin.
ThÃªm hÃ m handle_admin_response() Ä‘á»ƒ xá»­ lÃ½ pháº£n há»“i tá»« admin vÃ  gá»­i láº¡i cho user.
Cáº­p nháº­t giao diá»‡n ngÆ°á»i dÃ¹ng Ä‘á»ƒ hiá»ƒn thá»‹ pháº£n há»“i tá»« admin.
Táº¡o giao diá»‡n admin Ä‘á»ƒ xem cÃ¡c yÃªu cáº§u má»›i vÃ  gá»­i pháº£n há»“i.
Äá»ƒ cháº¡y:

Äáº£m báº£o Ä‘Ã£ cÃ i Ä‘áº·t Flask-SocketIO: pip install flask-socketio
Cháº¡y file Python
Truy cáº­p http://localhost:5002 Ä‘á»ƒ xem giao diá»‡n ngÆ°á»i dÃ¹ng
Truy cáº­p http://localhost:5002/admin Ä‘á»ƒ xem giao diá»‡n admin
Khi cÃ³ yÃªu cáº§u chuyá»ƒn cho human, admin sáº½ nháº­n Ä‘Æ°á»£c thÃ´ng bÃ¡o trong giao diá»‡n admin vÃ  cÃ³ thá»ƒ gá»­i pháº£n há»“i trá»±c tiáº¿p Ä‘áº¿n ngÆ°á»i dÃ¹ng.

Bro tháº¥y version nÃ y Ä‘Ã£ Ä‘áº§y Ä‘á»§ chÆ°a?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
hmm thÃ´i tÃ´i nghÄ© lÃ  bá» fontend broo áº¡ bá»Ÿi vÃ¬ tÃ´i pháº£i lÃ m demo nhanh thá»­ nghiá»‡m Ã½ tÆ°á»Ÿng nÃªn tÃ´i k cÃ³ thá»i gian lÃ m fontend broo aajaaaaaa. chÃºng ta sáº½ táº­p trung vÃ o logic backend nhÃ© brooo


Hiá»ƒu rá»“i bro. Váº­y chÃºng ta sáº½ táº­p trung vÃ o logic backend vÃ  sá»­ dá»¥ng API Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c. ÄÃ¢y lÃ  phiÃªn báº£n Ä‘Ã£ Ä‘Æ°á»£c tinh gá»n, chá»‰ táº­p trung vÃ o backend:

python

Copy
from flask import Flask, request, jsonify
from dotenv import load_dotenv
import os
import json
from pydantic import BaseModel
from typing import Literal
from langchain.prompts import PromptTemplate
import google.generativeai as genai
from flask_cors import CORS
from rag.core import RAG
from reflection import Reflection

# Load environment variables
load_dotenv()
MONGODB_URI = os.getenv('MONGODB_URI')
DB_NAME = os.getenv('DB_NAME')
DB_COLLECTION = os.getenv('DB_COLLECTION')
LLM_KEY = os.getenv('GEMINI_KEY')

# Setup LLM
genai.configure(api_key=LLM_KEY)
llm = genai.GenerativeModel('gemini-1.5-pro')

# Setup RAG and Reflection
rag = RAG(mongodbUri=MONGODB_URI, dbName=DB_NAME, dbCollection=DB_COLLECTION, embeddingName='keepitreal/vietnamese-sbert', llm=llm)
reflection = Reflection(llm=llm)

app = Flask(__name__)
CORS(app)

# Pydantic model for response format
class ChatbotResponse(BaseModel):
    chatbot_state: Literal["product", "chitchat", "human"]
    chatbot_response: str

ROUTER_PROMPT = """
Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh vÃ  lá»‹ch sá»± cho cá»­a hÃ ng thá»i trang trá»±c tuyáº¿n tá»« Viá»‡t Nam.
Má»¥c tiÃªu cá»§a báº¡n lÃ  giÃºp khÃ¡ch hÃ ng tÃ¬m vÃ  mua sáº£n pháº©m phÃ¹ há»£p vá»›i sá»Ÿ thÃ­ch vÃ  nhu cáº§u cá»§a há».

CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: "{question}"

ThÃ´ng tin sáº£n pháº©m:
{context}

Logic quyáº¿t Ä‘á»‹nh:
1. Náº¿u cÃ¢u há»i liÃªn quan Ä‘áº¿n sáº£n pháº©m hoáº·c lÃ  cÃ¢u há»i chung mÃ  chatbot cÃ³ thá»ƒ xá»­ lÃ½:
   chatbot_state = "product"
   Táº¡o cÃ¢u tráº£ lá»i dá»±a trÃªn thÃ´ng tin sáº£n pháº©m vÃ  lÆ°u vÃ o chatbot_response

2. Náº¿u cÃ¢u há»i lÃ  trÃ² chuyá»‡n Ä‘Æ¡n giáº£n khÃ´ng yÃªu cáº§u kiáº¿n thá»©c vá» sáº£n pháº©m:
   chatbot_state = "chitchat"
   Táº¡o cÃ¢u tráº£ lá»i thÃ¢n thiá»‡n, há»™i thoáº¡i vÃ  lÆ°u vÃ o chatbot_response

3. Náº¿u cÃ¢u há»i phá»©c táº¡p, khÃ´ng rÃµ rÃ ng hoáº·c cáº§n sá»± há»— trá»£ cá»§a con ngÆ°á»i:
   chatbot_state = "human"
   Táº¡o cÃ¢u tráº£ lá»i cho biáº¿t má»™t nhÃ¢n viÃªn sáº½ há»— trá»£ vÃ  lÆ°u vÃ o chatbot_response

Äá»‹nh dáº¡ng Ä‘áº§u ra:
Tráº£ vá» cÃ¢u tráº£ lá»i dÆ°á»›i dáº¡ng chuá»—i cÃ³ cáº¥u trÃºc giá»‘ng JSON, vá»›i cÃ¡c khÃ³a sau:
 "chatbot_state": chatbot_state
 "chatbot_response": chatbot_response

LÆ°u Ã½: Äáº£m báº£o ráº±ng Ä‘áº§u ra cá»§a báº¡n cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n tÃ­ch cÃº phÃ¡p bá»Ÿi json.loads() trong Python.
"""

ROUTER_PROMPT_TEMPLATE = PromptTemplate(template=ROUTER_PROMPT, input_variables=["question", "context"])

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.get_json()
    query = data['question']
    
    # Use RAG to get relevant context
    context = rag.enhance_prompt(query)
    
    # Use LLM to classify and generate initial response
    router_response = llm.generate_content(ROUTER_PROMPT_TEMPLATE.format(question=query, context=context))
    
    try:
        router_output = json.loads(router_response.text)
        response = ChatbotResponse(**router_output)
    except json.JSONDecodeError:
        return jsonify({"error": "Invalid response format from LLM"}), 500
    except ValueError:
        return jsonify({"error": "Response does not match expected schema"}), 500

    if response.chatbot_state == "product":
        # Use reflection to improve product-related response
        reflected_query = reflection(query)
        enhanced_prompt = f"""
        HÃ£y trá»Ÿ thÃ nh chuyÃªn gia tÆ° váº¥n bÃ¡n hÃ ng. 
        CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: {reflected_query}
        
        ThÃ´ng tin sáº£n pháº©m:
        {context}
        
        Tráº£ lá»i cÃ¢u há»i cá»§a khÃ¡ch hÃ ng má»™t cÃ¡ch chi tiáº¿t, Ä‘áº§y Ä‘á»§ vÃ  chuyÃªn nghiá»‡p.
        """
        final_response = llm.generate_content(enhanced_prompt)
        response.chatbot_response = final_response.text

    return jsonify(response.dict())

@app.route('/api/admin/respond', methods=['POST'])
def admin_respond():
    data = request.get_json()
    admin_response = data['response']
    question_id = data['question_id']  # Giáº£ sá»­ má»—i cÃ¢u há»i cÃ³ má»™t ID
    
    # á» Ä‘Ã¢y báº¡n cÃ³ thá»ƒ thÃªm logic Ä‘á»ƒ lÆ°u pháº£n há»“i cá»§a admin vÃ o database
    # vÃ  cáº­p nháº­t tráº¡ng thÃ¡i cá»§a cÃ¢u há»i
    
    return jsonify({"status": "success", "message": "Admin response recorded"})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5002, debug=True)
Giáº£i thÃ­ch cÃ¡c thay Ä‘á»•i vÃ  cÃ¡ch sá»­ dá»¥ng:

Bá» háº¿t pháº§n frontend, chá»‰ giá»¯ láº¡i cÃ¡c route API.
/api/chat endpoint:
Input: JSON vá»›i key "question"
Output: JSON vá»›i "chatbot_state" vÃ  "chatbot_response"
Xá»­ lÃ½ logic phÃ¢n loáº¡i cÃ¢u há»i vÃ  tráº£ lá»i
/api/admin/respond endpoint:
Cho phÃ©p admin tráº£ lá»i cÃ¡c cÃ¢u há»i yÃªu cáº§u sá»± há»— trá»£ cá»§a con ngÆ°á»i
Input: JSON vá»›i "response" (cÃ¢u tráº£ lá»i cá»§a admin) vÃ  "question_id" (ID cá»§a cÃ¢u há»i)
Output: ThÃ´ng bÃ¡o xÃ¡c nháº­n Ä‘Ã£ ghi nháº­n pháº£n há»“i cá»§a admin
CÃ¡c chá»©c nÄƒng chÃ­nh váº«n Ä‘Æ°á»£c giá»¯ nguyÃªn:
Sá»­ dá»¥ng RAG Ä‘á»ƒ láº¥y context
DÃ¹ng LLM Ä‘á»ƒ phÃ¢n loáº¡i cÃ¢u há»i
Sá»­ dá»¥ng reflection cho cÃ¢u há»i liÃªn quan Ä‘áº¿n sáº£n pháº©m
Äá»ƒ test API, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ´ng cá»¥ nhÆ° Postman hoáº·c curl. VÃ­ dá»¥ vá»›i curl:

bash

Copy
curl -X POST http://localhost:5002/api/chat \
     -H "Content-Type: application/json" \
     -d '{"question": "CÃ³ Ã¡o sÆ¡ mi tráº¯ng size L khÃ´ng?"}'
Äá»ƒ pháº£n há»“i tá»« admin:

bash

Copy
curl -X POST http://localhost:5002/api/admin/respond \
     -H "Content-Type: application/json" \
     -d '{"response": "ChÃºng tÃ´i cÃ³ Ã¡o sÆ¡ mi tráº¯ng size L, giÃ¡ 350,000 VND", "question_id": "123"}'
Bro cÃ³ thá»ƒ dá»… dÃ ng tÃ­ch há»£p API nÃ y vÃ o báº¥t ká»³ frontend nÃ o sau nÃ y. Bro tháº¥y version nÃ y Ä‘Ã£ Ä‘á»§ cho viá»‡c demo vÃ  thá»­ nghiá»‡m Ã½ tÆ°á»Ÿng chÆ°a?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
háº£ broo, Ã½ tÃ´i lÃ  khÃ´ng dÃ¹ng flash ná»¯a mÃ  broo. táº­p trung lÃ m logic backend thÃ´i. bro hiá»ƒu Ã½ tÃ´i chá»©


Ah, xin lá»—i bro, tÃ´i Ä‘Ã£ hiá»ƒu nháº§m. Báº¡n muá»‘n táº­p trung hoÃ n toÃ n vÃ o logic xá»­ lÃ½ mÃ  khÃ´ng cáº§n Flask hay báº¥t ká»³ web framework nÃ o. ÄÃºng rá»“i, Ä‘Ã¢y lÃ  má»™t cÃ¡ch tiáº¿p cáº­n tá»‘t Ä‘á»ƒ thá»­ nghiá»‡m Ã½ tÆ°á»Ÿng nhanh chÃ³ng. HÃ£y xem phiÃªn báº£n chá»‰ cÃ³ logic backend:

python

Copy
import os
from dotenv import load_dotenv
import json
from pydantic import BaseModel
from typing import Literal
from langchain.prompts import PromptTemplate
import google.generativeai as genai
from rag.core import RAG
from reflection import Reflection

# Load environment variables
load_dotenv()
MONGODB_URI = os.getenv('MONGODB_URI')
DB_NAME = os.getenv('DB_NAME')
DB_COLLECTION = os.getenv('DB_COLLECTION')
LLM_KEY = os.getenv('GEMINI_KEY')

# Setup LLM
genai.configure(api_key=LLM_KEY)
llm = genai.GenerativeModel('gemini-1.5-pro')

# Setup RAG and Reflection
rag = RAG(mongodbUri=MONGODB_URI, dbName=DB_NAME, dbCollection=DB_COLLECTION, embeddingName='keepitreal/vietnamese-sbert', llm=llm)
reflection = Reflection(llm=llm)

# Pydantic model for response format
class ChatbotResponse(BaseModel):
    chatbot_state: Literal["product", "chitchat", "human"]
    chatbot_response: str

ROUTER_PROMPT = """
Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh vÃ  lá»‹ch sá»± cho cá»­a hÃ ng thá»i trang trá»±c tuyáº¿n tá»« Viá»‡t Nam.
Má»¥c tiÃªu cá»§a báº¡n lÃ  giÃºp khÃ¡ch hÃ ng tÃ¬m vÃ  mua sáº£n pháº©m phÃ¹ há»£p vá»›i sá»Ÿ thÃ­ch vÃ  nhu cáº§u cá»§a há».

CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: "{question}"

ThÃ´ng tin sáº£n pháº©m:
{context}

Logic quyáº¿t Ä‘á»‹nh:
1. Náº¿u cÃ¢u há»i liÃªn quan Ä‘áº¿n sáº£n pháº©m hoáº·c lÃ  cÃ¢u há»i chung mÃ  chatbot cÃ³ thá»ƒ xá»­ lÃ½:
   chatbot_state = "product"
   Táº¡o cÃ¢u tráº£ lá»i dá»±a trÃªn thÃ´ng tin sáº£n pháº©m vÃ  lÆ°u vÃ o chatbot_response

2. Náº¿u cÃ¢u há»i lÃ  trÃ² chuyá»‡n Ä‘Æ¡n giáº£n khÃ´ng yÃªu cáº§u kiáº¿n thá»©c vá» sáº£n pháº©m:
   chatbot_state = "chitchat"
   Táº¡o cÃ¢u tráº£ lá»i thÃ¢n thiá»‡n, há»™i thoáº¡i vÃ  lÆ°u vÃ o chatbot_response

3. Náº¿u cÃ¢u há»i phá»©c táº¡p, khÃ´ng rÃµ rÃ ng hoáº·c cáº§n sá»± há»— trá»£ cá»§a con ngÆ°á»i:
   chatbot_state = "human"
   Táº¡o cÃ¢u tráº£ lá»i cho biáº¿t má»™t nhÃ¢n viÃªn sáº½ há»— trá»£ vÃ  lÆ°u vÃ o chatbot_response

Äá»‹nh dáº¡ng Ä‘áº§u ra:
Tráº£ vá» cÃ¢u tráº£ lá»i dÆ°á»›i dáº¡ng chuá»—i cÃ³ cáº¥u trÃºc giá»‘ng JSON, vá»›i cÃ¡c khÃ³a sau:
 "chatbot_state": chatbot_state
 "chatbot_response": chatbot_response

LÆ°u Ã½: Äáº£m báº£o ráº±ng Ä‘áº§u ra cá»§a báº¡n cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n tÃ­ch cÃº phÃ¡p bá»Ÿi json.loads() trong Python.
"""

ROUTER_PROMPT_TEMPLATE = PromptTemplate(template=ROUTER_PROMPT, input_variables=["question", "context"])

def chat(query: str):
    # Use RAG to get relevant context
    context = rag.enhance_prompt(query)
    
    # Use LLM to classify and generate initial response
    router_response = llm.generate_content(ROUTER_PROMPT_TEMPLATE.format(question=query, context=context))
    
    try:
        router_output = json.loads(router_response.text)
        response = ChatbotResponse(**router_output)
    except json.JSONDecodeError:
        return {"error": "Invalid response format from LLM"}
    except ValueError:
        return {"error": "Response does not match expected schema"}

    if response.chatbot_state == "product":
        # Use reflection to improve product-related response
        reflected_query = reflection(query)
        enhanced_prompt = f"""
        HÃ£y trá»Ÿ thÃ nh chuyÃªn gia tÆ° váº¥n bÃ¡n hÃ ng. 
        CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: {reflected_query}
        
        ThÃ´ng tin sáº£n pháº©m:
        {context}
        
        Tráº£ lá»i cÃ¢u há»i cá»§a khÃ¡ch hÃ ng má»™t cÃ¡ch chi tiáº¿t, Ä‘áº§y Ä‘á»§ vÃ  chuyÃªn nghiá»‡p.
        """
        final_response = llm.generate_content(enhanced_prompt)
        response.chatbot_response = final_response.text

    return response.dict()

def admin_respond(admin_response: str, question_id: str):
    # á» Ä‘Ã¢y báº¡n cÃ³ thá»ƒ thÃªm logic Ä‘á»ƒ lÆ°u pháº£n há»“i cá»§a admin vÃ o database
    # vÃ  cáº­p nháº­t tráº¡ng thÃ¡i cá»§a cÃ¢u há»i
    return {"status": "success", "message": "Admin response recorded"}

if __name__ == '__main__':
    # Test the chat function
    question = "CÃ³ Ã¡o sÆ¡ mi tráº¯ng size L khÃ´ng?"
    result = chat(question)
    print(json.dumps(result, ensure_ascii=False, indent=2))

    # Test the admin respond function
    admin_result = admin_respond("ChÃºng tÃ´i cÃ³ Ã¡o sÆ¡ mi tráº¯ng size L, giÃ¡ 350,000 VND", "123")
    print(json.dumps(admin_result, ensure_ascii=False, indent=2))
Giáº£i thÃ­ch:

ÄÃ£ loáº¡i bá» hoÃ n toÃ n Flask vÃ  cÃ¡c route API.
Logic xá»­ lÃ½ Ä‘Æ°á»£c Ä‘áº·t trong hÃ m chat(query):
Nháº­n input lÃ  cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
Xá»­ lÃ½ theo quy trÃ¬nh: RAG -> LLM Classification -> Reflection (náº¿u cáº§n)
Tráº£ vá» káº¿t quáº£ dÆ°á»›i dáº¡ng dictionary
HÃ m admin_respond(admin_response, question_id) Ä‘á»ƒ xá»­ lÃ½ pháº£n há»“i cá»§a admin:
Hiá»‡n táº¡i chá»‰ lÃ  placeholder, báº¡n cÃ³ thá»ƒ thÃªm logic lÆ°u trá»¯ vÃ o Ä‘Ã¢y sau nÃ y
Trong pháº§n if __name__ == '__main__':
CÃ³ vÃ­ dá»¥ test cho cáº£ hÃ m chat() vÃ  admin_respond()
Káº¿t quáº£ Ä‘Æ°á»£c in ra console
Äá»ƒ sá»­ dá»¥ng vÃ  test:

Cháº¡y script Python
Káº¿t quáº£ sáº½ Ä‘Æ°á»£c in ra console
Báº¡n cÃ³ thá»ƒ dá»… dÃ ng sá»­a Ä‘á»•i cÃ¢u há»i test trong pháº§n if __name__ == '__main__'
Æ¯u Ä‘iá»ƒm cá»§a cÃ¡ch nÃ y:

Táº­p trung hoÃ n toÃ n vÃ o logic xá»­ lÃ½
Dá»… dÃ ng test vÃ  debug
CÃ³ thá»ƒ nhanh chÃ³ng tÃ­ch há»£p vÃ o báº¥t ká»³ frontend hoáº·c framework nÃ o sau nÃ y
Bro tháº¥y version nÃ y Ä‘Ã£ Ä‘Ãºng Ã½ cá»§a báº¡n chÆ°a? NÃ³ táº­p trung hoÃ n toÃ n vÃ o logic backend vÃ  cho phÃ©p báº¡n nhanh chÃ³ng thá»­ nghiá»‡m Ã½ tÆ°á»Ÿng.

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
tá»« tá»« nhÃ© brooo. giá» code tÃ´i viáº¿t khÃ¡c rá»“i bro áº¡ from langchain.prompts import PromptTemplate   ROUTER_PROMPT = """ You are a smart and polite AI assistant for an online fashion store from Vietnam.  Your goal is to help customers find and purchase products that match their preferences and needs.  Customer question: "{question}"  Product information: {context}  Decision logic:  1. If the question is simple chitchat that doesn't require product knowledge:      chatbot_state = "chitchat"    Generate a friendly, conversational response and store it in chatbot_response         2. If the question is about products or a general inquiry that the chatbot can handle:    chatbot_state = "product"    Generate a response based on product information and store it in chatbot_response  3. If the question is complex, ambiguous, or requires human assistance:    chatbot_state = "human"     Generate a response indicating a staff member will assist and store it in chatbot_response  Output format: Return the response in a JSON string format with the following keys:  "chatbot_state": chatbot_state  "chatbot_response": chatbot_response  Example outputs: {"chatbot_state":"product","chatbot_response":"The Nike Air Max 90 is available in sizes 7 to 12. It comes in three colors - white, black, and red. The price is $120."} {"chatbot_state":"chitchat","chatbot_response":"I'm doing great, thanks for asking! How can I assist you with your fashion needs today?"}   {"chatbot_state":"human","chatbot_response":"I apologize, I'm not quite sure how to best answer your question. Let me connect you with one of our fashion experts who can provide more detailed assistance."}  Ensure your output can be parsed by json.loads() in Python. """  ROUTER_PROMPT_TEMPLATE = PromptTemplate(template=ROUTER_PROMPT, input_variables=["question", "context"])  trÆ°á»›c háº¿t Ä‘Ã¢y lÃ  prompt cá»§a tÃ´i. bro hÃ£y viáº¿t cho tÃ´i 1 con AI class Router Ä‘i broooo, sau Ä‘Ã³ sáº½ phÃ¢n tÃ­ch chuá»—i json vÃ  tráº£ ra state. bro hiá»ƒu Ã½ tÃ´i chá»©. hÃ£y viáº¿t hoÃ n chá»‰nh code Ä‘á»ƒ tÃ´i Ä‘i copy nhÃ© brooo


Hiá»ƒu rá»“i bro, tÃ´i sáº½ viáº¿t má»™t class Router hoÃ n chá»‰nh dá»±a trÃªn prompt cá»§a báº¡n. ÄÃ¢y lÃ  code:

python

Copy
import json
from typing import Dict, Any
from langchain.prompts import PromptTemplate
from pydantic import BaseModel, Field

class RouterResponse(BaseModel):
    chatbot_state: str = Field(..., description="State of the chatbot: 'chitchat', 'product', or 'human'")
    chatbot_response: str = Field(..., description="Response generated by the chatbot")

class Router:
    def __init__(self, llm):
        self.llm = llm
        self.prompt_template = PromptTemplate(
            template=ROUTER_PROMPT,
            input_variables=["question", "context"]
        )

    def route(self, question: str, context: str) -> Dict[str, Any]:
        prompt = self.prompt_template.format(question=question, context=context)
        response = self.llm.generate_content(prompt)
        
        try:
            parsed_response = json.loads(response.text)
            validated_response = RouterResponse(**parsed_response)
            return validated_response.dict()
        except json.JSONDecodeError:
            return {"error": "Invalid JSON response from LLM"}
        except ValueError as e:
            return {"error": f"Validation error: {str(e)}"}

ROUTER_PROMPT = """
You are a smart and polite AI assistant for an online fashion store from Vietnam. 
Your goal is to help customers find and purchase products that match their preferences and needs.

Customer question: "{question}"

Product information: {context}

Decision logic:

1. If the question is simple chitchat that doesn't require product knowledge:
    chatbot_state = "chitchat"
    Generate a friendly, conversational response and store it in chatbot_response
    
2. If the question is about products or a general inquiry that the chatbot can handle:
    chatbot_state = "product"
    Generate a response based on product information and store it in chatbot_response

3. If the question is complex, ambiguous, or requires human assistance:
    chatbot_state = "human" 
    Generate a response indicating a staff member will assist and store it in chatbot_response

Output format: Return the response in a JSON string format with the following keys:
"chatbot_state": chatbot_state
"chatbot_response": chatbot_response

Example outputs:
{"chatbot_state":"product","chatbot_response":"The Nike Air Max 90 is available in sizes 7 to 12. It comes in three colors - white, black, and red. The price is $120."}
{"chatbot_state":"chitchat","chatbot_response":"I'm doing great, thanks for asking! How can I assist you with your fashion needs today?"}
{"chatbot_state":"human","chatbot_response":"I apologize, I'm not quite sure how to best answer your question. Let me connect you with one of our fashion experts who can provide more detailed assistance."}

Ensure your output can be parsed by json.loads() in Python.
"""

# Example usage:
if __name__ == "__main__":
    import google.generativeai as genai
    
    # Setup LLM (replace with your actual setup)
    genai.configure(api_key="YOUR_GEMINI_API_KEY")
    llm = genai.GenerativeModel('gemini-1.5-pro')
    
    router = Router(llm)
    
    # Test with a sample question
    question = "Do you have any red dresses?"
    context = "We have several red dresses in stock, including a silk cocktail dress and a cotton sundress."
    
    result = router.route(question, context)
    print(json.dumps(result, indent=2))
Giáº£i thÃ­ch:

RouterResponse class: Sá»­ dá»¥ng Pydantic Ä‘á»ƒ Ä‘á»‹nh nghÄ©a cáº¥u trÃºc vÃ  validate response tá»« LLM.
Router class:
__init__: Khá»Ÿi táº¡o vá»›i má»™t LLM vÃ  táº¡o prompt template.
route: PhÆ°Æ¡ng thá»©c chÃ­nh Ä‘á»ƒ xá»­ lÃ½ cÃ¢u há»i:
Táº¡o prompt tá»« template
Gá»i LLM Ä‘á»ƒ generate content
Parse vÃ  validate JSON response
Tráº£ vá» káº¿t quáº£ dÆ°á»›i dáº¡ng dictionary
ROUTER_PROMPT: Prompt template nhÆ° báº¡n Ä‘Ã£ Ä‘á»‹nh nghÄ©a.
Pháº§n example usage: Minh há»a cÃ¡ch sá»­ dá»¥ng Router class vá»›i Google's Gemini model.
Äá»ƒ sá»­ dá»¥ng:

Thay "YOUR_GEMINI_API_KEY" báº±ng API key thá»±c cá»§a báº¡n.
Cháº¡y script, nÃ³ sáº½ in ra káº¿t quáº£ cho cÃ¢u há»i máº«u.
Báº¡n cÃ³ thá»ƒ dá»… dÃ ng tÃ­ch há»£p class nÃ y vÃ o há»‡ thá»‘ng lá»›n hÆ¡n cá»§a mÃ¬nh. NÃ³ sáº½ handle viá»‡c routing, parsing JSON, vÃ  validation response.

Bro tháº¥y code nÃ y á»•n chÆ°a? CÃ³ cáº§n Ä‘iá»u chá»‰nh gÃ¬ khÃ´ng?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
dÃ¹ng langchain há»™ tÃ´i cÃ¡i broooimport json
from typing import Dict, Any
from langchain.prompts import PromptTemplate
from pydantic import BaseModel, Field
class RouterResponse(BaseModel):
    chatbot_state: str = Field(..., description="State of the chatbot: 'chitchat', 'product', or 'human'")
    chatbot_response: str = Field(..., description="Response generated by the chatbot")
class Router:
    def init(self, llm):
        self.llm = llm
        self.prompt_template = PromptTemplate(
            template=ROUTER_PROMPT,
            input_variables=["question", "context"]
        )
    def route(self, question: str, context: str) -> Dict[str, Any]:
        prompt = self.prompt_template.format(question=question, context=context)
        response = self.llm.generate_content(prompt)

        try:
            parsed_response = json.loads(response.text)
            validated_response = RouterResponse(**parsed_response)
            return validated_response.dict()
        except json.JSONDecodeError:
            return {"error": "Invalid JSON response from LLM"}
        except ValueError as e:
            return {"error": f"Validation error: {str(e)}"}
ROUTER_PROMPT = """
You are a smart and polite AI assistant for an online fashion store from Vietnam. 
Your goal is to help customers find and purchase products that match their preferences and needs.
Customer question: "{question}"
Product information: {context}
Decision logic:
1. If the question is simple chitchat that doesn't require product knowledge:
    chatbot_state = "chitchat"
    Generate a friendly, conversational response and store it in chatbot_response

If the question is about products or a general inquiry that the chatbot can handle: chatbot_state = "product" Generate a response based on product information and store it in chatbot_response
If the question is complex, ambiguous, or requires human assistance: chatbot_state = "human" Generate a response indicating a staff member will assist and store it in chatbot_response Output format: Return the response in a JSON string format with the following keys: "chatbot_state": chatbot_state "chatbot_response": chatbot_response Example outputs: {"chatbot_state":"product","chatbot_response":"The Nike Air Max 90 is available in sizes 7 to 12. It comes in three colors - white, black, and red. The price is $120."} {"chatbot_state":"chitchat","chatbot_response":"I'm doing great, thanks for asking! How can I assist you with your fashion needs today?"} {"chatbot_state":"human","chatbot_response":"I apologize, I'm not quite sure how to best answer your question. Let me connect you with one of our fashion experts who can provide more detailed assistance."} Ensure your output can be parsed by json.loads() in Python. """ # Example usage: if name == "main": import google.generativeai as genai # Setup LLM (replace with your actual setup) genai.configure(api_key="YOUR_GEMINI_API_KEY") llm = genai.GenerativeModel('gemini-1.5-pro') router = Router(llm) # Test with a sample question question = "Do you have any red dresses?" context = "We have several red dresses in stock, including a silk cocktail dress and a cotton sundress." result = router.route(question, context) print(json.dumps(result, indent=2))

ÄÆ°á»£c rá»“i bro, tÃ´i sáº½ chuyá»ƒn Ä‘á»•i code nÃ y Ä‘á»ƒ sá»­ dá»¥ng LangChain nhiá»u hÆ¡n. ÄÃ¢y lÃ  phiÃªn báº£n cáº­p nháº­t:

python

Copy
from typing import Dict, Any
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_google_genai import ChatGoogleGenerativeAI

class RouterResponse(BaseModel):
    chatbot_state: str = Field(..., description="State of the chatbot: 'chitchat', 'product', or 'human'")
    chatbot_response: str = Field(..., description="Response generated by the chatbot")

class Router:
    def __init__(self, llm):
        self.prompt_template = PromptTemplate(
            template=ROUTER_PROMPT,
            input_variables=["question", "context"]
        )
        self.output_parser = JsonOutputParser(pydantic_object=RouterResponse)
        self.chain = LLMChain(
            llm=llm,
            prompt=self.prompt_template,
            output_parser=self.output_parser
        )

    def route(self, question: str, context: str) -> Dict[str, Any]:
        try:
            response = self.chain.run(question=question, context=context)
            return response
        except ValueError as e:
            return {"error": f"Validation error: {str(e)}"}

ROUTER_PROMPT = """
You are a smart and polite AI assistant for an online fashion store from Vietnam. 
Your goal is to help customers find and purchase products that match their preferences and needs.

Customer question: "{question}"

Product information: {context}

Decision logic:

1. If the question is simple chitchat that doesn't require product knowledge:
    chatbot_state = "chitchat"
    Generate a friendly, conversational response and store it in chatbot_response
    
2. If the question is about products or a general inquiry that the chatbot can handle:
    chatbot_state = "product"
    Generate a response based on product information and store it in chatbot_response

3. If the question is complex, ambiguous, or requires human assistance:
    chatbot_state = "human" 
    Generate a response indicating a staff member will assist and store it in chatbot_response

Output format: Return the response in a JSON string format with the following keys:
"chatbot_state": chatbot_state
"chatbot_response": chatbot_response

Example outputs:
{"chatbot_state":"product","chatbot_response":"The Nike Air Max 90 is available in sizes 7 to 12. It comes in three colors - white, black, and red. The price is $120."}
{"chatbot_state":"chitchat","chatbot_response":"I'm doing great, thanks for asking! How can I assist you with your fashion needs today?"}
{"chatbot_state":"human","chatbot_response":"I apologize, I'm not quite sure how to best answer your question. Let me connect you with one of our fashion experts who can provide more detailed assistance."}

Ensure your output can be parsed by json.loads() in Python.
"""

# Example usage:
if __name__ == "__main__":
    import os
    from dotenv import load_dotenv
    import json

    # Load environment variables
    load_dotenv()

    # Setup LLM
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro", google_api_key=os.getenv("GOOGLE_API_KEY"))
    
    router = Router(llm)
    
    # Test with a sample question
    question = "Do you have any red dresses?"
    context = "We have several red dresses in stock, including a silk cocktail dress and a cotton sundress."
    
    result = router.route(question, context)
    print(json.dumps(result, indent=2))
Nhá»¯ng thay Ä‘á»•i chÃ­nh:

Sá»­ dá»¥ng LLMChain tá»« LangChain Ä‘á»ƒ táº¡o chuá»—i xá»­ lÃ½.
Sá»­ dá»¥ng JsonOutputParser Ä‘á»ƒ parse output JSON tá»± Ä‘á»™ng.
Sá»­ dá»¥ng ChatGoogleGenerativeAI tá»« langchain_google_genai thay vÃ¬ sá»­ dá»¥ng API Google trá»±c tiáº¿p.
ÄÆ¡n giáº£n hÃ³a phÆ°Æ¡ng thá»©c route vÃ¬ LangChain sáº½ xá»­ lÃ½ pháº§n lá»›n logic.
Sá»­ dá»¥ng dotenv Ä‘á»ƒ load biáº¿n mÃ´i trÆ°á»ng an toÃ n hÆ¡n.
Äá»ƒ sá»­ dá»¥ng code nÃ y:

Äáº£m báº£o báº¡n Ä‘Ã£ cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t:

Copy
pip install langchain langchain_google_genai python-dotenv
Táº¡o file .env trong cÃ¹ng thÆ° má»¥c vá»›i script vÃ  thÃªm API key cá»§a báº¡n:

Copy
GOOGLE_API_KEY=your_api_key_here
Cháº¡y script vÃ  nÃ³ sáº½ in ra káº¿t quáº£ cho cÃ¢u há»i máº«u.
PhiÃªn báº£n nÃ y táº­n dá»¥ng nhiá»u tÃ­nh nÄƒng cá»§a LangChain hÆ¡n, giÃºp code ngáº¯n gá»n vÃ  dá»… má»Ÿ rá»™ng hÆ¡n. Bro tháº¥y version nÃ y tháº¿ nÃ o?

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
from langchain.prompts import PromptTemplate   ROUTER_PROMPT = """ You are a smart and polite AI assistant for an online fashion store from Vietnam.  Your goal is to help customers find and purchase products that match their preferences and needs.  Customer question: "{question}"  Decision logic:  1. If the question is simple chitchat that doesn't require product knowledge:      chatbot_state = "chitchat"    Generate a friendly, conversational response and store it in chatbot_response         2. If the question is about products or a general inquiry that the chatbot can handle:    chatbot_state = "product"    Generate a response based on product information and store it in chatbot_response  3. If the question is complex, ambiguous, or requires human assistance:    chatbot_state = "human"     Generate a response indicating a staff member will assist and store it in chatbot_response  Output format: Return the response in a JSON string format with the following keys:  "chatbot_state": chatbot_state  "chatbot_response": chatbot_response  Example outputs: {"chatbot_state":"product","chatbot_response":"The Nike Air Max 90 is available in sizes 7 to 12. It comes in three colors - white, black, and red. The price is $120."} {"chatbot_state":"chitchat","chatbot_response":"I'm doing great, thanks for asking! How can I assist you with your fashion needs today?"}   {"chatbot_state":"human","chatbot_response":"I apologize, I'm not quite sure how to best answer your question. Let me connect you with one of our fashion experts who can provide more detailed assistance."}  Ensure your output can be parsed by json.loads() in Python. """  ROUTER_PROMPT_TEMPLATE = PromptTemplate(template=ROUTER_PROMPT, input_variables=["question"])  hey broo, Ä‘Ã¢y lÃ  prompt má»›i cá»§a tÃ´i vÃ  tÃ´i sá»­a code nhÆ° nÃ y cÃ³ á»•n k bro nhá»‰ import json
from typing import Dict, Any
from langchain.prompts import PromptTemplate
from pydantic import BaseModel, Field

from shoppinggpt.router.prompt import ROUTER_PROMPT_TEMPLATE

class RouterResponse(BaseModel):
    chatbot_state: str = Field(..., description="State of the chatbot: 'chitchat', 'product', or 'human'")
    chatbot_response: str = Field(..., description="Response generated by the chatbot")

class Router:
    def init(self, llm):
        self.llm = llm
        self.prompt_template = ROUTER_PROMPT_TEMPLATE

    def route(self, question: str) -> Dict[str, Any]:
        prompt = self.prompt_template.format(question=question)
        response = prompt | self.llm

        try:
            parsed_response = json.loads(response.text)
            validated_response = RouterResponse(**parsed_response)
            return validated_response.dict()
        except json.JSONDecodeError:
            return {"error": "Invalid JSON response from LLM"}
        except ValueError as e:
            return {"error": f"Validation error: {str(e)}"}


Hiá»ƒu rá»“i bro, code cá»§a báº¡n Ä‘Ã£ Ä‘Æ°á»£c cáº£i thiá»‡n vÃ  trÃ´ng khÃ¡ tá»‘t. Tuy nhiÃªn, tÃ´i cÃ³ má»™t vÃ i gá»£i Ã½ nhá» Ä‘á»ƒ lÃ m cho nÃ³ hoÃ n thiá»‡n hÆ¡n vÃ  táº­n dá»¥ng tá»‘t hÆ¡n cÃ¡c tÃ­nh nÄƒng cá»§a LangChain:

python

Copy
import json
from typing import Dict, Any
from langchain.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
from langchain.chains import LLMChain

from shoppinggpt.router.prompt import ROUTER_PROMPT_TEMPLATE

class RouterResponse(BaseModel):
    chatbot_state: str = Field(..., description="State of the chatbot: 'chitchat', 'product', or 'human'")
    chatbot_response: str = Field(..., description="Response generated by the chatbot")

class Router:
    def __init__(self, llm):
        self.llm = llm
        self.output_parser = PydanticOutputParser(pydantic_object=RouterResponse)
        self.prompt_template = PromptTemplate(
            template=ROUTER_PROMPT_TEMPLATE.template + "\n{format_instructions}",
            input_variables=["question"],
            partial_variables={"format_instructions": self.output_parser.get_format_instructions()}
        )
        self.chain = LLMChain(llm=self.llm, prompt=self.prompt_template, output_key="response")

    def route(self, question: str) -> Dict[str, Any]:
        try:
            response = self.chain.run(question=question)
            parsed_response = self.output_parser.parse(response)
            return parsed_response.dict()
        except json.JSONDecodeError:
            return {"error": "Invalid JSON response from LLM"}
        except ValueError as e:
            return {"error": f"Validation error: {str(e)}"}

# Example usage
if __name__ == "__main__":
    from langchain_google_genai import ChatGoogleGenerativeAI
    import os
    
    os.environ["GOOGLE_API_KEY"] = "your_api_key_here"
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro")
    
    router = Router(llm)
    result = router.route("Do you have any red dresses?")
    print(json.dumps(result, indent=2))
Nhá»¯ng cáº£i tiáº¿n vÃ  lÃ½ do:

Sá»­ dá»¥ng PydanticOutputParser: GiÃºp parse output cá»§a LLM trá»±c tiáº¿p thÃ nh Ä‘á»‘i tÆ°á»£ng Pydantic, giáº£m thiá»ƒu viá»‡c xá»­ lÃ½ lá»—i thá»§ cÃ´ng.
ThÃªm format instructions vÃ o prompt: GiÃºp LLM hiá»ƒu rÃµ hÆ¡n vá» cáº¥u trÃºc output mong muá»‘n.
Sá»­ dá»¥ng LLMChain: Táº¡o má»™t chain hoÃ n chá»‰nh, giÃºp quáº£n lÃ½ luá»“ng dá»¯ liá»‡u tá»‘t hÆ¡n vÃ  dá»… má»Ÿ rá»™ng trong tÆ°Æ¡ng lai.
Sá»­ dá»¥ng self.chain.run() thay vÃ¬ prompt | self.llm: CÃ¡ch nÃ y nháº¥t quÃ¡n hÆ¡n vá»›i cÃ¡ch sá»­ dá»¥ng LangChain vÃ  dá»… debug hÆ¡n.
Xá»­ lÃ½ lá»—i: Váº«n giá»¯ xá»­ lÃ½ lá»—i cho JSONDecodeError vÃ  ValueError Ä‘á»ƒ Ä‘áº£m báº£o robustness.
Nhá»¯ng thay Ä‘á»•i nÃ y giÃºp code cá»§a báº¡n táº­n dá»¥ng tá»‘t hÆ¡n cÃ¡c tÃ­nh nÄƒng cá»§a LangChain, Ä‘á»“ng thá»i váº«n giá»¯ Ä‘Æ°á»£c cáº¥u trÃºc vÃ  logic cÆ¡ báº£n mÃ  báº¡n Ä‘Ã£ Ä‘á»‹nh nghÄ©a.

Bro tháº¥y version nÃ y cÃ³ á»•n hÆ¡n khÃ´ng? Náº¿u cáº§n Ä‘iá»u chá»‰nh gÃ¬ thÃªm, cá»© nÃ³i nhÃ©!

Copy
Retry


Claude does not have the ability to run the code it generates yet.
L
báº¡n code kiá»ƒu Ä‘Ã©o gÃ¬ tháº¿, nta toÃ n dÃ¹ng langchain lecl rá»“i ; from typing import Dict, Any
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_google_genai import ChatGoogleGenerativeAI
class RouterResponse(BaseModel):
    chatbot_state: str = Field(..., description="State of the chatbot: 'chitchat', 'product', or 'human'")
    chatbot_response: str = Field(..., description="Response generated by the chatbot")
class Router:
    def init(self, llm):
        self.prompt_template = PromptTemplate(
            template=ROUTER_PROMPT,
            input_variables=["question", "context"]
        )
        self.output_parser = JsonOutputParser(pydantic_object=RouterResponse)
        self.chain = LLMChain(
            llm=llm,
            prompt=self.prompt_template,
            output_parser=self.output_parser
        )
    def route(self, question: str, context: str) -> Dict[str, Any]:
        try:
            response = self.chain.run(question=question, context=context)
            return response
        except ValueError as e:
            return {"error": f"Validation error: {str(e)}"}
ROUTER_PROMPT = """
You are a smart and polite AI assistant for an online fashion store from Vietnam. 
Your goal is to help customers find and purchase products that match their preferences and needs.
Customer question: "{question}"
Product information: {context}
Decision logic:
1. If the question is simple chitchat that doesn't require product knowledge:
    chatbot_state = "chitchat"
    Generate a friendly, conversational response and store it in chatbot_response

If the question is about products or a general inquiry that the chatbot can handle: chatbot_state = "product" Generate a response based on product information and store it in chatbot_response
If the question is complex, ambiguous, or requires human assistance: chatbot_state = "human" Generate a response indicating a staff member will assist and store it in chatbot_response Output format: Return the response in a JSON string format with the following keys: "chatbot_state": chatbot_state "chatbot_response": chatbot_response Example outputs: {"chatbot_state":"product","chatbot_response":"The Nike Air Max 90 is available in sizes 7 to 12. It comes in three colors - white, black, and red. The price is $120."} {"chatbot_state":"chitchat","chatbot_response":"I'm doing great, thanks for asking! How can I assist you with your fashion needs today?"} {"chatbot_state":"human","chatbot_response":"I apologize, I'm not quite sure how to best answer your question. Let me connect you with one of our fashion experts who can provide more detailed assistance."} Ensure your output can be parsed by json.loads() in Python. """ # Example usage: if name == "main": import os from dotenv import load_dotenv import json # Load environment variables load_dotenv() # Setup LLM llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro", google_api_key=os.getenv("GOOGLE_API_KEY")) router = Router(llm) # Test with a sample question question = "Do you have any red dresses?" context = "We have several red dresses in stock, including a silk cocktail dress and a cotton sundress." result = router.route(question, context) print(json.dumps(result, indent=2)) vá»›i cáº£ lÃ  from shoppinggpt.router.prompt import ROUTER_PROMPT_TEMPL ATE Ä‘Ã¢y lÃ  module cá»§a tao vá» prompt cá»§a tao. mÃ y Ä‘á»«ng cÃ³ xÃ³a. viáº¿t láº¡i code cho tao Ä‘i

Xin lá»—i bro, tÃ´i Ä‘Ã£ hiá»ƒu nháº§m. Cáº£m Æ¡n báº¡n Ä‘Ã£ chá»‰ ra. TÃ´i sáº½ viáº¿t láº¡i code dá»±a trÃªn yÃªu cáº§u cá»§a báº¡n vÃ  giá»¯ nguyÃªn cáº¥u trÃºc LCEL (LangChain Expression Language) cÅ©ng nhÆ° module prompt cá»§a báº¡n. ÄÃ¢y lÃ  phiÃªn báº£n Ä‘Ã£ Ä‘Æ°á»£c chá»‰nh sá»­a:

python

Copy
from typing import Dict, Any
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field

from shoppinggpt.router.prompt import ROUTER_PROMPT_TEMPLATE

class RouterResponse(BaseModel):
    chatbot_state: str = Field(..., description="State of the chatbot: 'chitchat', 'product', or 'human'")
    chatbot_response: str = Field(..., description="Response generated by the chatbot")

class Router:
    def __init__(self, llm):
        self.llm = llm
        self.output_parser = JsonOutputParser(pydantic_object=RouterResponse)
        self.chain = ROUTER_PROMPT_TEMPLATE | self.llm | self.output_parser

    def route(self, question: str) -> Dict[str, Any]:
        try:
            response = self.chain.invoke({"question": question})
            return response
        except ValueError as e:
            return {"error": f"Validation error: {str(e)}"}

# Example usage:
if __name__ == "__main__":
    import os
    from dotenv import load_dotenv
    import json
    from langchain_google_genai import ChatGoogleGenerativeAI

    # Load environment variables
    load_dotenv()

    # Setup LLM
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro", google_api_key=os.getenv("GOOGLE_API_KEY"))
    
    router = Router(llm)
    
    # Test with a sample question
    question = "Do you have any red dresses?"
    
    result = router.route(question)
    print(json.dumps(result, indent=2))
Nhá»¯ng thay Ä‘á»•i chÃ­nh:

Sá»­ dá»¥ng ROUTER_PROMPT_TEMPLATE tá»« module cá»§a báº¡n.
Sá»­ dá»¥ng LCEL syntax (|) Ä‘á»ƒ táº¡o chain thay vÃ¬ LLMChain.
Loáº¡i bá» pháº§n context vÃ¬ nÃ³ khÃ´ng cÃ³ trong prompt template cá»§a báº¡n.
Sá»­ dá»¥ng invoke thay vÃ¬ run Ä‘á»ƒ phÃ¹ há»£p vá»›i LCEL.
Mong ráº±ng phiÃªn báº£n nÃ y Ä‘Ã¡p á»©ng Ä‘Ãºng yÃªu cáº§u cá»§a báº¡n. Náº¿u cáº§n Ä‘iá»u chá»‰nh gÃ¬ thÃªm, cá»© nÃ³i nhÃ© bro!

Copy
Retry


Claude does not have the ability to run the code it generates yet.
Claude can make mistakes. Please double-check responses.



No file chosen


3.5 Sonnet
9 messages remaining until 11 PM
